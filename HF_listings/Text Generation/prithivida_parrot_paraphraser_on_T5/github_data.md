# GitHub Data for prithivida_parrot_paraphraser_on_T5

**Task Category:** Text Generation

## Repository 1: PrithivirajDamodaran/Parrot_Paraphraser.git

# GitHub Data Extraction Error

Error: 404 {"message": "Not Found", "documentation_url": "https://docs.github.com/rest/repos/repos#get-a-repository", "status": "404"}

Repository: https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git

---

## Repository 2: PrithivirajDamodaran/Parrot

# GitHub Repository Data

**Repository:** [PrithivirajDamodaran/Parrot_Paraphraser](https://github.com/PrithivirajDamodaran/Parrot_Paraphraser)

## Basic Information

- **Description:** A practical and feature-rich paraphrasing framework to augment human intents in text form to build robust NLU models for conversational engines. Created by Prithiviraj Damodaran. Open to pull requests and other forms of collaboration.
- **Created:** 2021-04-26T06:48:19+00:00
- **Last Updated:** 2025-06-20T06:28:22+00:00
- **Last Pushed:** 2024-01-07T04:42:16+00:00
- **Default Branch:** main
- **Size:** 830 KB

## Statistics

- **Stars:** 897
- **Forks:** 150
- **Watchers:** 897
- **Open Issues:** 18
- **Total Issues:** 0
- **Pull Requests:** 16

## License

- **Type:** Apache License 2.0
- **SPDX ID:** Apache-2.0
- **URL:** [License](https://github.com/PrithivirajDamodaran/Parrot_Paraphraser/blob/main/LICENSE)

## Languages

- **Python:** 13,162 bytes

## Topics

- `paraphrase-generation`
- `paraphrase`
- `paraphrased-data`
- `nlu`
- `slot-filling`
- `rasa-nlu`
- `intents`

## Top Contributors

1. **PrithivirajDamodaran** - 26 contributions
2. **pontuscode** - 5 contributions
3. **yedpodtrzitko** - 1 contributions
4. **smyja** - 1 contributions

## File Structure (Sample of 10 files)

Total files: 20

- `LICENSE` (blob)
- `README.md` (blob)
- `images` (tree)
- `images/ATIS_chart.png` (blob)
- `images/AU_chart.png` (blob)
- `images/Augmentor UI.png` (blob)
- `images/CB_chart.png` (blob)
- `images/CLINC_chart.png` (blob)
- `images/Logo.png` (blob)
- `images/NLU Flow.png` (blob)

## Recent Issues

- 游릭 **#63** Unable to connect offline (open)
- 游댮 **#62** Language support (closed)
- 游댮 **#61** Details of fine-tuning (closed)
- 游릭 **#60** How to generate in batches? (open)
- 游댮 **#59** Deprecated .egg files when running the install command (closed)

## Recent Pull Requests

- 游댮 **#58** Add install intructions for ROCm platform (closed)
- 游댮 **#48** Fixed typos in README.md (closed)
- 游댮 **#42** fix: add missing dependencies into requirements.txt (closed)
- 游릭 **#37** added use auth token according to new hugging face (open)
- 游릭 **#36** Update README.md (open)

## Recent Commits

- **03084c54** Merge pull request #58 from pontuscode/add-instructions-for-amd-rocm - Prithivida (2024-01-07T04:42:16+00:00)
- **59b1c068** Change style from bold to italic - Pontus Jarnemyr (2024-01-03T17:10:26+00:00)
- **371d3afc** Move ROCm installation instructions - Pontus Jarnemyr (2024-01-03T17:06:50+00:00)
- **0805d791** Fix typo - Pontus Jarnemyr (2024-01-03T16:47:22+00:00)
- **d4696dc6** Rename requirements file - Pontus Jarnemyr (2024-01-03T16:41:07+00:00)
- **fcd847f3** Add installation instructions for AMD ROCm - Pontus Jarnemyr (2024-01-03T16:08:28+00:00)
- **720a87a1** Update README.md - Prithivida (2022-12-27T17:03:32+00:00)
- **5a1dc7f0** Update README.md - Prithivida (2022-12-27T16:41:18+00:00)
- **251d49c0** Merge pull request #42 from yedpodtrzitko/main - Prithivida (2022-12-10T08:12:30+00:00)
- **bca75268** Update README.md - Prithivida (2022-12-06T11:45:23+00:00)

## External Links Found in README

- https://github.com/PrithivirajDamodaran/Parrot/blob/main/LICENSE
- https://huggingface.co/models?pipeline_tag=text2text-generation&search=paraphrase
- https://img.shields.io/hexpm/l/plug
- https://colab.research.google.com/drive/1oHwF5sXxLGH8i6M0YGwGP0RstwZQDuGW?usp=sharing
- https://rapidapi.com/search/paraphrase?section=apis&page=1
- https://github.com/ROCm/ROCm/issues/1698
- https://github.com/google-research-datasets/paws
- https://github.com/wasiahmad/paraphrase_identification
- https://www.microsoft.com/en-us/research/project/frames-dataset/
- https://www.sbert.net/examples/applications/paraphrase-mining/README.html
- http://paraphrase.org/#/download
- https://github.com/makcedward/nlpaug
- https://www.aclweb.org/anthology/D10-1090.pdf
- https://visitor-badge.glitch.me/badge?page_id=Parrot_Paraphraser.count_visitors
- https://github.com/jwieting/para-nmt-50m#readme
- https://visitor-badge.glitch.me
- https://data.world/socialmediadata/quora-question-pairs
- https://colab.research.google.com/assets/colab-badge.svg
- https://github.com/sz128/slot_filling_and_intent_detection_of_SLU
- https://forum.rasa.com/t/paraphrasing-for-nlu-data-augmentation-experimental/27744

## Raw Data

<details>
<summary>Click to expand raw JSON data</summary>

```json
{
  "id": 361646405,
  "name": "Parrot_Paraphraser",
  "full_name": "PrithivirajDamodaran/Parrot_Paraphraser",
  "description": "A practical and feature-rich paraphrasing framework to augment human intents in text form to build robust NLU models for conversational engines. Created by Prithiviraj Damodaran. Open to pull requests and other forms of collaboration.",
  "html_url": "https://github.com/PrithivirajDamodaran/Parrot_Paraphraser",
  "clone_url": "https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git",
  "ssh_url": "git@github.com:PrithivirajDamodaran/Parrot_Paraphraser.git",
  "homepage": "",
  "topics": [
    "paraphrase-generation",
    "paraphrase",
    "paraphrased-data",
    "nlu",
    "slot-filling",
    "rasa-nlu",
    "intents"
  ],
  "default_branch": "main",
  "created_at": "2021-04-26T06:48:19+00:00",
  "updated_at": "2025-06-20T06:28:22+00:00",
  "pushed_at": "2024-01-07T04:42:16+00:00",
  "size_kb": 830,
  "watchers_count": 897,
  "stargazers_count": 897,
  "forks_count": 150,
  "open_issues_count": 18,
  "license": {
    "key": "apache-2.0",
    "name": "Apache License 2.0",
    "spdx_id": "Apache-2.0",
    "url": "https://github.com/PrithivirajDamodaran/Parrot_Paraphraser/blob/main/LICENSE"
  },
  "languages": {
    "Python": 13162
  },
  "top_contributors": [
    {
      "login": "PrithivirajDamodaran",
      "contributions": 26
    },
    {
      "login": "pontuscode",
      "contributions": 5
    },
    {
      "login": "yedpodtrzitko",
      "contributions": 1
    },
    {
      "login": "smyja",
      "contributions": 1
    }
  ],
  "file_tree_count": 20,
  "file_tree_sample": [
    {
      "path": "LICENSE",
      "type": "blob"
    },
    {
      "path": "README.md",
      "type": "blob"
    },
    {
      "path": "images",
      "type": "tree"
    },
    {
      "path": "images/ATIS_chart.png",
      "type": "blob"
    },
    {
      "path": "images/AU_chart.png",
      "type": "blob"
    },
    {
      "path": "images/Augmentor UI.png",
      "type": "blob"
    },
    {
      "path": "images/CB_chart.png",
      "type": "blob"
    },
    {
      "path": "images/CLINC_chart.png",
      "type": "blob"
    },
    {
      "path": "images/Logo.png",
      "type": "blob"
    },
    {
      "path": "images/NLU Flow.png",
      "type": "blob"
    }
  ],
  "issues_count": 0,
  "pulls_count": 16,
  "recent_issues": [
    {
      "number": 63,
      "title": "Unable to connect offline",
      "state": "open"
    },
    {
      "number": 62,
      "title": "Language support",
      "state": "closed"
    },
    {
      "number": 61,
      "title": "Details of fine-tuning",
      "state": "closed"
    },
    {
      "number": 60,
      "title": "How to generate in batches?",
      "state": "open"
    },
    {
      "number": 59,
      "title": "Deprecated .egg files when running the install command",
      "state": "closed"
    }
  ],
  "recent_pulls": [
    {
      "number": 58,
      "title": "Add install intructions for ROCm platform",
      "state": "closed"
    },
    {
      "number": 48,
      "title": "Fixed typos in README.md",
      "state": "closed"
    },
    {
      "number": 42,
      "title": "fix: add missing dependencies into requirements.txt",
      "state": "closed"
    },
    {
      "number": 37,
      "title": "added use auth token according to new hugging face",
      "state": "open"
    },
    {
      "number": 36,
      "title": "Update README.md",
      "state": "open"
    }
  ],
  "recent_commits": [
    {
      "sha": "03084c54b64019ba5fa0b620b9c70ad81123e458",
      "author": "Prithivida",
      "date": "2024-01-07T04:42:16+00:00",
      "message": "Merge pull request #58 from pontuscode/add-instructions-for-amd-rocm"
    },
    {
      "sha": "59b1c0687f916899382ce5f04ec4e8a79b4641f8",
      "author": "Pontus Jarnemyr",
      "date": "2024-01-03T17:10:26+00:00",
      "message": "Change style from bold to italic"
    },
    {
      "sha": "371d3afc282dcb6ecb985865f00c583270b6cb94",
      "author": "Pontus Jarnemyr",
      "date": "2024-01-03T17:06:50+00:00",
      "message": "Move ROCm installation instructions"
    },
    {
      "sha": "0805d79119b5dc308fb9b75606fedd1ba1d83880",
      "author": "Pontus Jarnemyr",
      "date": "2024-01-03T16:47:22+00:00",
      "message": "Fix typo"
    },
    {
      "sha": "d4696dc6001452e38e6436d97b341acb836271f8",
      "author": "Pontus Jarnemyr",
      "date": "2024-01-03T16:41:07+00:00",
      "message": "Rename requirements file"
    },
    {
      "sha": "fcd847f366ff60a304033e836de0be1ad7e0f362",
      "author": "Pontus Jarnemyr",
      "date": "2024-01-03T16:08:28+00:00",
      "message": "Add installation instructions for AMD ROCm"
    },
    {
      "sha": "720a87a1ee557d8ed8d9a021adbdd1dd5616c5f9",
      "author": "Prithivida",
      "date": "2022-12-27T17:03:32+00:00",
      "message": "Update README.md"
    },
    {
      "sha": "5a1dc7f0ccdf2ac54d300d9a451c13129056d1e3",
      "author": "Prithivida",
      "date": "2022-12-27T16:41:18+00:00",
      "message": "Update README.md"
    },
    {
      "sha": "251d49c0a24499c827956ffbf298c3a4ce07ea3f",
      "author": "Prithivida",
      "date": "2022-12-10T08:12:30+00:00",
      "message": "Merge pull request #42 from yedpodtrzitko/main"
    },
    {
      "sha": "bca7526834bf83bf55e1ebf3f7c87fd9fbb713a6",
      "author": "Prithivida",
      "date": "2022-12-06T11:45:23+00:00",
      "message": "Update README.md"
    },
    {
      "sha": "04a4556cc243a40e1dc5bb823063b1387dc5694e",
      "author": "Prithivida",
      "date": "2022-12-06T11:39:01+00:00",
      "message": "set auth_token to False as default"
    },
    {
      "sha": "1b80dafda583fdfa71d651cf548832af20ae8aa3",
      "author": "Jiri Suchan",
      "date": "2022-10-22T04:47:32+00:00",
      "message": "fix: add missing dependencies into requirements.txt"
    },
    {
      "sha": "8143c649a0d0e80b24c908747b4954974e04377f",
      "author": "Prithivida",
      "date": "2022-10-09T09:05:13+00:00",
      "message": "Update README.md"
    },
    {
      "sha": "2bef500ede9860d9f3aa8f25637fa75df83ba652",
      "author": "Prithivida",
      "date": "2022-10-09T08:56:09+00:00",
      "message": "Added use_auth_token support"
    },
    {
      "sha": "2cffbe911341e52dc73b77f9b0154c18d570603f",
      "author": "Prithivida",
      "date": "2022-07-29T04:50:25+00:00",
      "message": "Merge pull request #27 from Smyja/patch-1"
    },
    {
      "sha": "0fd74d05a2fb591580e77ae2e4d0ca10c1cbc60c",
      "author": "Smyja",
      "date": "2022-07-20T16:50:46+00:00",
      "message": "Typo fix"
    },
    {
      "sha": "3bc88f0efde65da558a1e6b2b6625761e0fba3c4",
      "author": "Prithivida",
      "date": "2022-07-05T10:39:42+00:00",
      "message": "Update demo.py"
    },
    {
      "sha": "51b7c9e2ba0543dc6b50bdc9506efcb05c8e7fb8",
      "author": "Prithivida",
      "date": "2022-07-05T10:38:33+00:00",
      "message": "Merge pull request #24 from PrithivirajDamodaran/paraphrases-need-not-printed-in-a-loop"
    },
    {
      "sha": "e5169fe70e701d9eca88c974c791652cc85304cb",
      "author": "Prithivida",
      "date": "2022-07-05T10:38:22+00:00",
      "message": "paraphrases need not printed in a loop"
    },
    {
      "sha": "768341fd45af2a41b5114b65e7e3899264837b62",
      "author": "Prithivida",
      "date": "2022-07-05T10:21:14+00:00",
      "message": "Merge pull request #23 from PrithivirajDamodaran/Move-inputids-to-GPU"
    }
  ],
  "readme_text": "[![PyPI - License](https://img.shields.io/hexpm/l/plug)](https://github.com/PrithivirajDamodaran/Parrot/blob/main/LICENSE)\n[![visitors](https://visitor-badge.glitch.me/badge?page_id=Parrot_Paraphraser.count_visitors)](https://visitor-badge.glitch.me)\n\n# Parrot\nParrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. A paraphrase framework is more than just a paraphrasing model.\n\n<img src=\"images/Logo.png\" width=\"35%\" height=\"35%\" align=\"right\" />\n\n## Table of contents\n- [Why Parrot?](#why-parrot-)\n- [Getting started](#getting-started)\n  * [Install](#install)\n  * [Quickstart](#quickstart)\n  * [Getting syntactic and phrasal diversity/variety in your paraphrases ?](#getting-syntactic-and-phrasal-diversity-variety-in-your-paraphrases--)\n  * [Other Knobs](#other-knobs)\n- [Scope](#scope)\n- [What makes a paraphraser a good augmentor for NLU? (Details)](#what-makes-a-paraphraser-a-good-augmentor-for-nlu---details-)\n  * [Sample NLU data (Rasa format)](#sample-nlu-data--rasa-format-)\n- [Power of Augmentation - Metrics and Comparison](#power-of-augmentation---metrics-and-comparison)\n- [Current Features](#current-features)\n- [Roadmap](#roadmap)\n- [Current Limitations/Known issues](#current-limitations-known-issues)\n- [References](#references)\n- [Citation](#citation)\n\n\n\n## Why Parrot?\n**Huggingface** lists [16 paraphrase generation models,](https://huggingface.co/models?pipeline_tag=text2text-generation&search=paraphrase) (as of this writing)  **RapidAPI** lists 7 fremium and commercial paraphrasers like [QuillBot](https://rapidapi.com/search/paraphrase?section=apis&page=1), Rasa has discussed an experimental paraphraser for augmenting text data [here](https://forum.rasa.com/t/paraphrasing-for-nlu-data-augmentation-experimental/27744), Sentence-transfomers offers a [paraphrase mining utility](https://www.sbert.net/examples/applications/paraphrase-mining/README.html) and [NLPAug](https://github.com/makcedward/nlpaug) offers word level augmentation with a [PPDB](http://paraphrase.org/#/download) (a multi-million paraphrase database). While these attempts at paraphrasing are great, there are still some gaps and paraphrasing is NOT yet a mainstream option for text augmentation in building NLU models....Parrot is a humble attempt to fill some of these gaps.\n\n**What is a good paraphrase?** Almost all conditioned text generation models are validated  on 2 factors, (1) if the generated text conveys the same meaning as the original context (Adequacy) (2) if the text is fluent / grammatically correct english (Fluency). For instance Neural Machine Translation outputs are tested for Adequacy and Fluency. But [a good paraphrase](https://www.aclweb.org/anthology/D10-1090.pdf) should be adequate and fluent while being as different as possible on the surface lexical form. With respect to this definition, the  **3 key metrics** that measures the quality of paraphrases are:\n - **Adequacy** (Is the meaning preserved adequately?) \n - **Fluency** (Is the paraphrase fluent English?) \n - **Diversity (Lexical / Phrasal / Syntactical)** (How much has the paraphrase changed the original sentence?)\n\n*Parrot offers knobs to control Adequacy, Fluency and Diversity as per your needs.*\n\n**What makes a paraphraser a good augmentor?** For training a NLU model we just don't need a lot of utterances but utterances with intents and slots/entities annotated. Typical flow would be:\n- Given an **input utterance  + input annotations** a good augmentor spits out N **output paraphrases** while preserving the intent and slots. \n - The output paraphrases are then converted into annotated data using the input annotations that we got in step 1.\n - The annotated data created out of the output paraphrases then makes the training dataset for your NLU model.\n\nBut in general being a generative model paraphrasers doesn't guarantee to preserve the slots/entities. So the ability to generate high quality paraphrases in a constrained fashion without trading off the intents and slots for lexical dissimilarity makes a paraphraser a good augmentor. *More on this in section 3 below*\n\n## Getting started\n### Install\n```python\npip install git+https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git\n```\n\n[*Trying to install for AMD GPUs?*](README.md#installation-for-amd-gpus)\n\n### Demo notebook\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1oHwF5sXxLGH8i6M0YGwGP0RstwZQDuGW?usp=sharing) Demo notebook\n\n### Quickstart\n```python\n\n\nfrom parrot import Parrot\nimport torch\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n''' \nuncomment to get reproducable paraphrase generations\ndef random_state(seed):\n  torch.manual_seed(seed)\n  if torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)\n\nrandom_state(1234)\n'''\n\n#Init models (make sure you init ONLY once if you integrate this to your code)\nparrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\")\n\nphrases = [\"Can you recommend some upscale restaurants in Newyork?\",\n           \"What are the famous places we should not miss in Russia?\"\n]\n\nfor phrase in phrases:\n  print(\"-\"*100)\n  print(\"Input_phrase: \", phrase)\n  print(\"-\"*100)\n  para_phrases = parrot.augment(input_phrase=phrase, use_gpu=False)\n  for para_phrase in para_phrases:\n   print(para_phrase)\n```\n\n```\n----------------------------------------------------------------------\nInput_phrase: Can you recommed some upscale restaurants in Newyork?\n----------------------------------------------------------------------\nlist some excellent restaurants to visit in new york city?\nwhat upscale restaurants do you recommend in new york?\ni want to try some upscale restaurants in new york?\nrecommend some upscale restaurants in newyork?\ncan you recommend some high end restaurants in newyork?\ncan you recommend some upscale restaurants in new york?\ncan you recommend some upscale restaurants in newyork?\n----------------------------------------------------------------------\nInput_phrase: What are the famous places we should not miss in Russia\n----------------------------------------------------------------------\nwhat should we not miss when visiting russia?\nrecommend some of the best places to visit in russia?\nlist some of the best places to visit in russia?\ncan you list the top places to visit in russia?\nshow the places that we should not miss in russia?\nlist some famous places which we should not miss in russia?\n```\n### Getting syntactic and phrasal diversity/variety in your paraphrases ?\n\nYou can play with the do_diverse knob (checkout the next section for more knobs). \nConsider this example: **do_diverse = False (default)***\n```\n------------------------------------------------------------------------------\nInput_phrase: How are the new Macbook Pros with M1 chips?\n------------------------------------------------------------------------------\n'how do you rate the new macbook pros? '\n'how are the new macbook pros? '\n'how is the new macbook pro doing with new chips? '\n'how do you like the new macbook pro m1 chip? '\n'what is the use of the new macbook pro m1 chips? '\n```\n**do_diverse = True**\n```\n------------------------------------------------------------------------------\nInput_phrase: How are the new Macbook Pros with M1 chips?\n------------------------------------------------------------------------------\n'what do you think about the new macbook pro m1? '\n'how is the new macbook pro m1? '\n'how are the new macbook pros? '\n'what do you think about the new macbook pro m1 chips? '\n'how good is the new macbook pro m1 chips? '\n'how is the new macbook pro m1 chip? '\n'do you like the new macbook pro m1 chips? '\n'how are the new macbook pros with m1 chips? '\n```\n\n### Other Knobs\n```python\n\n para_phrases = parrot.augment(input_phrase=phrase,\n                               use_gpu=False,\n                               diversity_ranker=\"levenshtein\",\n                               do_diverse=False, \n                               max_return_phrases = 10, \n                               max_length=32, \n                               adequacy_threshold = 0.99, \n                               fluency_threshold = 0.90)\n\n```\n\n## Scope\n\nIn the space of conversational engines, knowledge bots are to which **we ask questions** like *\"when was the Berlin wall teared down?\"*, transactional bots are to which **we give commands** like *\"Turn on the music please\"* and voice assistants are the ones which can do both answer questions and action our commands. Parrot mainly foucses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models. (*So usually people neither type out or yell out long paragraphs to conversational interfaces. Hence the pre-trained model is trained  on text samples of maximum length of 32.*)\n\n*While Parrot predominantly aims to be a text augmentor for building good NLU models, it can also be used as a pure-play paraphraser.*\n\n\n## What makes a paraphraser a good augmentor for NLU? (Details)\n\nTo enable automatic training data generation, a paraphraser needs to keep the slots in intact. So the end to end process can take input utternaces, augment and convert them into NLU training format goo et al or rasa format (as shown below). The data generation process needs to look for the same slots in the output paraphrases to derive the start and end positions.(as shown in the json below)\n\n<img src=\"./images/NLU Flow.png\" alt=\"\" title=\"\" width=\"550\" height=\"100\" /> \n\nIdeally the above process needs an UI like below to collect to input utternaces along with annotations (Intents, Slots and slot types) which then can be agumented and converted to training data.\n\n<img src=\"./images/Augmentor UI.png\" alt=\"\" title=\"\" width=\"550\" height=\"100\" /> \n\n\n### Sample NLU data (Rasa format)\n\n```json\n{\n    \"rasa_nlu_data\": {\n        \"common_examples\": [\n            {\n                \"text\": \"i would like to find a flight from charlotte to las vegas that makes a stop in st. louis\",\n                \"intent\": \"flight\",\n                \"entities\": [\n                    {\n                        \"start\": 35,\n                        \"end\": 44,\n                        \"value\": \"charlotte\",\n                        \"entity\": \"fromloc.city_name\"\n                    },\n                    {\n                        \"start\": 48,\n                        \"end\": 57,\n                        \"value\": \"las vegas\",\n                        \"entity\": \"toloc.city_name\"\n                    },\n                    {\n                        \"start\": 79,\n                        \"end\": 88,\n                        \"value\": \"st. louis\",\n                        \"entity\": \"stoploc.city_name\"\n                    }\n                ]\n            },\n            ...\n        ]\n    }\n}\n```\n\n - **Original**:  I would like a list of round trip flights between indianapolis and orlando florida for the 27th\n - **Paraphrase useful for augmenting**: what are the round trip flights between indianapolis and orlando for the 27th\n - **Paraphrase not-so-useful for augmenting**: what are the round trip flights between chicago and orlando for the 27th.\n\n## Dataset for paraphrase model\nTHe following datasets where analysed, but the paraphrase generation model prithivida/parrot_paraphraser_on_T5 has been fine-tuned on some of them\n\n- [MSRP Paraphrase](https://github.com/wasiahmad/paraphrase_identification)\n- [Google PAWS](https://github.com/google-research-datasets/paws)\n- [ParaNMT](https://github.com/jwieting/para-nmt-50m#readme)\n- [Quora question pairs.](https://data.world/socialmediadata/quora-question-pairs)\n- [SNIPS commands](https://github.com/sz128/slot_filling_and_intent_detection_of_SLU)\n- [MSRP Frames](https://www.microsoft.com/en-us/research/project/frames-dataset/)\n\n## Power of Augmentation - Metrics and Comparison\n\n### Intent Classification task: \n\nExperimental setup: From each dataset increasing number of random utternaces per intent were taken to form the raw training data. The same data was then \naugmented with parrot paraphraser for Nx times(where N =10 or 15 depending the dataset) to form the augmented training data. Now models are trained on both raw data and augmented data to compare the performance. Being a multiclass classification model weighted F1 was used as a metric. The experiment was repeated 4 times for each number of utterance and F1 has been averaged to remove randomness in the trend. I have used 6 prominent NLU datasets from across domains. Below charts reveal that with a **\"very modest number\"** utterances and paraphrase augmentation we can achieve good classfication performance on day 1. \"Very modest\" varies between 4 to 6 utterances per intent in some datasets and 5 to 7 for some datasets.\n\n<p align=\"left\"><img src=\"images/ATIS_chart.png\" width=\"70%\" height=\"65%\"/></p>\n<p align=\"left\"><img src=\"images/SNIPS_chart.png\" width=\"70%\" height=\"65%\"/></p>\n<p align=\"left\"><img src=\"images/CLINC_chart.png\" width=\"70%\" height=\"65%\"/></p>\n<p align=\"left\"><img src=\"images/WA_chart.png\" width=\"70%\" height=\"65%\"/></p>\n<p align=\"left\"><img src=\"images/CB_chart.png\" width=\"70%\" height=\"65%\"/></p>\n<p align=\"left\"><img src=\"images/AU_chart.png\" width=\"70%\" height=\"65%\"/></p>\n\n### Semantic slot-filling task: \nTBD\n\n## Current Features\nTBD\n\n## Roadmap\nTBD\n\n## Current Limitations/Known issues\n<ul>\n <li> The diversity scores are not normalised each of the diversity rankers scores paraphrases differently </li>\n <li> Some command style input phrases generate less adequate paraphrases</li>\n</ul>\n\n## Installation for AMD GPUs\n\nIf you're using an AMD GPU and want to use the AMD ROCm Platform, follow the steps below. Note that as of writing, ROCm is only available for Linux users! The steps are tested and verified on Ubuntu 22.04 using a Radeon RX 6650 XT GPU.\n\nInstall the dependencies:\n```sh\ngit clone https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git\ncd Parrot_Paraphraser\npip install -r requirements-rocm.txt\n```\n\nAfter the installation is finished, you can verify your installation by running the following:\n\n```sh\npython3 -c 'import torch; print(torch.cuda.is_available())' # should print 'True'\n```\n\nIf the output of the above command is `False`, you can try \"fooling\" the ROCm driver by setting the environment variable `HSA_OVERRIDE_GFX_VERSION` (as per  [this issue](https://github.com/ROCm/ROCm/issues/1698)):\n\n```sh\nHSA_OVERRIDE_GFX_VERSION=10.3.0 python3 -c 'import torch; print(torch.cuda.is_available())' # should print 'True'\n# OR \nexport HSA_OVERRIDE_GFX_VERSION=10.3.0\npython3 -c 'import torch; print(torch.cuda.is_available())' # should print 'True'\n```\n\n## References\nTBD\n\n## Citation\n\nTo cite Parrot in your work, please use the following bibtex reference:\n\n```bibtex\n@misc{prithivida2021parrot,\n  author       = {Prithiviraj Damodaran},\n  title        = {Parrot: Paraphrase generation for NLU.},\n  year         = 2021,\n  version      = {v1.0}\n}\n```\n",
  "external_links_in_readme": [
    "https://github.com/PrithivirajDamodaran/Parrot/blob/main/LICENSE",
    "https://huggingface.co/models?pipeline_tag=text2text-generation&search=paraphrase",
    "https://img.shields.io/hexpm/l/plug",
    "https://colab.research.google.com/drive/1oHwF5sXxLGH8i6M0YGwGP0RstwZQDuGW?usp=sharing",
    "https://rapidapi.com/search/paraphrase?section=apis&page=1",
    "https://github.com/ROCm/ROCm/issues/1698",
    "https://github.com/google-research-datasets/paws",
    "https://github.com/wasiahmad/paraphrase_identification",
    "https://www.microsoft.com/en-us/research/project/frames-dataset/",
    "https://www.sbert.net/examples/applications/paraphrase-mining/README.html",
    "http://paraphrase.org/#/download",
    "https://github.com/makcedward/nlpaug",
    "https://www.aclweb.org/anthology/D10-1090.pdf",
    "https://visitor-badge.glitch.me/badge?page_id=Parrot_Paraphraser.count_visitors",
    "https://github.com/jwieting/para-nmt-50m#readme",
    "https://visitor-badge.glitch.me",
    "https://data.world/socialmediadata/quora-question-pairs",
    "https://colab.research.google.com/assets/colab-badge.svg",
    "https://github.com/sz128/slot_filling_and_intent_detection_of_SLU",
    "https://forum.rasa.com/t/paraphrasing-for-nlu-data-augmentation-experimental/27744",
    "https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git"
  ]
}
```

</details>


---

## Repository 3: makcedward/nlpaug

# GitHub Repository Data

**Repository:** [makcedward/nlpaug](https://github.com/makcedward/nlpaug)

## Basic Information

- **Description:** Data augmentation for NLP 
- **Created:** 2019-03-21T03:00:17+00:00
- **Last Updated:** 2025-06-18T16:23:01+00:00
- **Last Pushed:** 2024-06-24T09:15:15+00:00
- **Default Branch:** master
- **Size:** 3365 KB

## Statistics

- **Stars:** 4,580
- **Forks:** 468
- **Watchers:** 4,580
- **Open Issues:** 80
- **Total Issues:** 0
- **Pull Requests:** 128

## License

- **Type:** MIT License
- **SPDX ID:** MIT
- **URL:** [License](https://github.com/makcedward/nlpaug/blob/master/LICENSE)

## Languages

- **Jupyter Notebook:** 777,279 bytes
- **Python:** 512,156 bytes
- **Shell:** 2,004 bytes

## Topics

- `nlp`
- `augmentation`
- `machine-learning`
- `artificial-intelligence`
- `data-science`
- `natural-language-processing`
- `adversarial-attacks`
- `adversarial-example`
- `ai`
- `ml`

## Top Contributors

1. **makcedward** - 688 contributions
2. **chiragjn** - 9 contributions
3. **bdalal** - 4 contributions
4. **ricardopieper** - 3 contributions
5. **avostryakov** - 2 contributions
6. **DrMatters** - 2 contributions
7. **JohnGiorgi** - 2 contributions
8. **sami-bg** - 2 contributions
9. **amitness** - 1 contributions
10. **baskrahmer** - 1 contributions

## File Structure (Sample of 10 files)

Total files: 372

- `.codacy.yml` (blob)
- `.gitattributes` (blob)
- `.github` (tree)
- `.github/FUNDING.yml` (blob)
- `.gitignore` (blob)
- `.readthedocs.yml` (blob)
- `.travis.yml` (blob)
- `CHANGE.md` (blob)
- `CITED.md` (blob)
- `LICENSE` (blob)

## Recent Issues

- 游릭 **#352** FileNotFoundError (open)
- 游릭 **#351** Fix SyntaxWarning: use raw strings for regex in context_word_embs.py (open)
- 游릭 **#350** SyntaxWarning from invalid escape sequences in regex patterns (Python 3.12+) (open)
- 游릭 **#349** Fix LookupError from nltk.pos_tag in Wordnet model (open)
- 游릭 **#348** Fix script indentation (open)

## Recent Pull Requests

- 游릭 **#351** Fix SyntaxWarning: use raw strings for regex in context_word_embs.py (open)
- 游릭 **#349** Fix LookupError from nltk.pos_tag in Wordnet model (open)
- 游릭 **#348** Fix script indentation (open)
- 游릭 **#347** Added the Persian mapping (open)
- 游릭 **#331** Removed 'num_workers' parameter as it gives error while running the lambada model (open)

## Recent Commits

- **23800cbb** Merge pull request #306 from makcedward/dev - Edward Ma (2022-07-07T05:16:43+00:00)
- **d44804d7** release 1.1.11 - Edward Ma (2022-07-07T05:12:38+00:00)
- **00df5952** [#289] Add language pack reference link - Edward Ma (2022-07-07T04:24:16+00:00)
- **872133ac** [#295] fix incorrect lambda label - Edward Ma (2022-07-07T04:06:43+00:00)
- **6f6e044d** Fix #302. Return list of data - Edward Ma (2022-07-05T05:49:51+00:00)
- **ae9f78a4** fix obsoleted librosa API - Edward Ma (2022-07-01T05:25:50+00:00)
- **487d9c89** Merge pull request #294 from phunc20/fix/typo_candidiate - Edward Ma (2022-07-01T04:36:19+00:00)
- **14cf9628** Merge pull request #298 from JohnGiorgi/patch-1 - Edward Ma (2022-07-01T04:35:51+00:00)
- **38a74264** Merge pull request #300 from MarkusSagen/master - Edward Ma (2022-07-01T04:35:32+00:00)
- **46d80a07** Merge pull request #303 from Logigo/master - Edward Ma (2022-07-01T04:35:08+00:00)

## External Links Found in README

- https://arxiv.org/pdf/2110.07280.pdf
- https://github.com/makcedward/nlpaug/blob/master/example/textual_augmenter.ipynb
- https://travis-ci.org/makcedward/nlpaug">
- https://towardsdatascience.com/data-augmentation-for-audio-76912b01fdf6
- https://www.torontomachinelearning.com/
- https://books.google.com/books?hl=en&lr=lang_en&id=0rYREAAAQBAJ&oi=fnd&pg=PR7&dq=nlpaug&ots=88bPp5rhnY&sig=C2ue8Xxbu09l59nAMOcVxWYvvWM#v=onepage&q=nlpaug&f=false
- https://github.com/makcedward/nlpaug/blob/master/res/logo_small.png"/>
- https://avatars.githubusercontent.com/u/3478378?s=400&v=4"
- https://github.com/makcedward/nlpaug/issues/301
- https://medium.com/towards-artificial-intelligence/how-does-data-noising-help-to-improve-your-nlp-model-480619f9fb10
- https://github.com/makcedward/nlpaug/blob/master/example/tfidf-train_model.ipynb
- https://nlpaug.readthedocs.io/en/latest/
- https://avatars.githubusercontent.com/u/20845117?v=4"
- https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28
- http://paraphrase.org/#/download
- https://towardsdatascience.com/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a
- https://towardsdatascience.com/data-augmentation-library-for-text-9661736b13ff
- https://github.com/emrecncelik"><img
- https://github.com/makcedward/nlpaug/blob/master/res/audio_example.png"/></p>
- https://github.com/makcedward/nlpaug/blob/master/example/textual_language_augmenter.ipynb

## Raw Data

<details>
<summary>Click to expand raw JSON data</summary>

```json
{
  "id": 176858880,
  "name": "nlpaug",
  "full_name": "makcedward/nlpaug",
  "description": "Data augmentation for NLP ",
  "html_url": "https://github.com/makcedward/nlpaug",
  "clone_url": "https://github.com/makcedward/nlpaug.git",
  "ssh_url": "git@github.com:makcedward/nlpaug.git",
  "homepage": "https://makcedward.github.io/",
  "topics": [
    "nlp",
    "augmentation",
    "machine-learning",
    "artificial-intelligence",
    "data-science",
    "natural-language-processing",
    "adversarial-attacks",
    "adversarial-example",
    "ai",
    "ml"
  ],
  "default_branch": "master",
  "created_at": "2019-03-21T03:00:17+00:00",
  "updated_at": "2025-06-18T16:23:01+00:00",
  "pushed_at": "2024-06-24T09:15:15+00:00",
  "size_kb": 3365,
  "watchers_count": 4580,
  "stargazers_count": 4580,
  "forks_count": 468,
  "open_issues_count": 80,
  "license": {
    "key": "mit",
    "name": "MIT License",
    "spdx_id": "MIT",
    "url": "https://github.com/makcedward/nlpaug/blob/master/LICENSE"
  },
  "languages": {
    "Jupyter Notebook": 777279,
    "Python": 512156,
    "Shell": 2004
  },
  "top_contributors": [
    {
      "login": "makcedward",
      "contributions": 688
    },
    {
      "login": "chiragjn",
      "contributions": 9
    },
    {
      "login": "bdalal",
      "contributions": 4
    },
    {
      "login": "ricardopieper",
      "contributions": 3
    },
    {
      "login": "avostryakov",
      "contributions": 2
    },
    {
      "login": "DrMatters",
      "contributions": 2
    },
    {
      "login": "JohnGiorgi",
      "contributions": 2
    },
    {
      "login": "sami-bg",
      "contributions": 2
    },
    {
      "login": "amitness",
      "contributions": 1
    },
    {
      "login": "baskrahmer",
      "contributions": 1
    },
    {
      "login": "bp-high",
      "contributions": 1
    },
    {
      "login": "chandan047",
      "contributions": 1
    },
    {
      "login": "hwchase17",
      "contributions": 1
    },
    {
      "login": "Sorrow321",
      "contributions": 1
    },
    {
      "login": "abcp4",
      "contributions": 1
    },
    {
      "login": "jessicasousa",
      "contributions": 1
    },
    {
      "login": "jbitton",
      "contributions": 1
    },
    {
      "login": "joaoantonioverdade",
      "contributions": 1
    },
    {
      "login": "MarkusSagen",
      "contributions": 1
    },
    {
      "login": "narayanacharya6",
      "contributions": 1
    }
  ],
  "file_tree_count": 372,
  "file_tree_sample": [
    {
      "path": ".codacy.yml",
      "type": "blob"
    },
    {
      "path": ".gitattributes",
      "type": "blob"
    },
    {
      "path": ".github",
      "type": "tree"
    },
    {
      "path": ".github/FUNDING.yml",
      "type": "blob"
    },
    {
      "path": ".gitignore",
      "type": "blob"
    },
    {
      "path": ".readthedocs.yml",
      "type": "blob"
    },
    {
      "path": ".travis.yml",
      "type": "blob"
    },
    {
      "path": "CHANGE.md",
      "type": "blob"
    },
    {
      "path": "CITED.md",
      "type": "blob"
    },
    {
      "path": "LICENSE",
      "type": "blob"
    }
  ],
  "issues_count": 0,
  "pulls_count": 128,
  "recent_issues": [
    {
      "number": 352,
      "title": "FileNotFoundError",
      "state": "open"
    },
    {
      "number": 351,
      "title": "Fix SyntaxWarning: use raw strings for regex in context_word_embs.py",
      "state": "open"
    },
    {
      "number": 350,
      "title": "SyntaxWarning from invalid escape sequences in regex patterns (Python 3.12+)",
      "state": "open"
    },
    {
      "number": 349,
      "title": "Fix LookupError from nltk.pos_tag in Wordnet model",
      "state": "open"
    },
    {
      "number": 348,
      "title": "Fix script indentation",
      "state": "open"
    }
  ],
  "recent_pulls": [
    {
      "number": 351,
      "title": "Fix SyntaxWarning: use raw strings for regex in context_word_embs.py",
      "state": "open"
    },
    {
      "number": 349,
      "title": "Fix LookupError from nltk.pos_tag in Wordnet model",
      "state": "open"
    },
    {
      "number": 348,
      "title": "Fix script indentation",
      "state": "open"
    },
    {
      "number": 347,
      "title": "Added the Persian mapping",
      "state": "open"
    },
    {
      "number": 331,
      "title": "Removed 'num_workers' parameter as it gives error while running the lambada model",
      "state": "open"
    }
  ],
  "recent_commits": [
    {
      "sha": "23800cbb9632c7fc8c4a88d46f9c4ecf68a96299",
      "author": "Edward Ma",
      "date": "2022-07-07T05:16:43+00:00",
      "message": "Merge pull request #306 from makcedward/dev"
    },
    {
      "sha": "d44804d736a2d73cca27df2bfd09673ee8c41cea",
      "author": "Edward Ma",
      "date": "2022-07-07T05:12:38+00:00",
      "message": "release 1.1.11"
    },
    {
      "sha": "00df595252da92958ef8afd3a6298cbce387ce9a",
      "author": "Edward Ma",
      "date": "2022-07-07T04:24:16+00:00",
      "message": "[#289] Add language pack reference link"
    },
    {
      "sha": "872133ac485cb1a6fab1ee8fac1b59ba16e861f8",
      "author": "Edward Ma",
      "date": "2022-07-07T04:06:43+00:00",
      "message": "[#295] fix incorrect lambda label"
    },
    {
      "sha": "6f6e044dfc49b155b2642767428d7532d4a1f0e9",
      "author": "Edward Ma",
      "date": "2022-07-05T05:49:51+00:00",
      "message": "Fix #302. Return list of data"
    },
    {
      "sha": "ae9f78a4745fa1d93fa7afd403a150220aa64ecf",
      "author": "Edward Ma",
      "date": "2022-07-01T05:25:50+00:00",
      "message": "fix obsoleted librosa API"
    },
    {
      "sha": "487d9c8903ba7e624652a9a09d7b4374196dbf28",
      "author": "Edward Ma",
      "date": "2022-07-01T04:36:19+00:00",
      "message": "Merge pull request #294 from phunc20/fix/typo_candidiate"
    },
    {
      "sha": "14cf962871781e5474e1013d39135b9c1fb7c160",
      "author": "Edward Ma",
      "date": "2022-07-01T04:35:51+00:00",
      "message": "Merge pull request #298 from JohnGiorgi/patch-1"
    },
    {
      "sha": "38a74264637a04eba49a078b208184f4d664b9c2",
      "author": "Edward Ma",
      "date": "2022-07-01T04:35:32+00:00",
      "message": "Merge pull request #300 from MarkusSagen/master"
    },
    {
      "sha": "46d80a07fd7dce7eed252138f7f78f853fa920c3",
      "author": "Edward Ma",
      "date": "2022-07-01T04:35:08+00:00",
      "message": "Merge pull request #303 from Logigo/master"
    },
    {
      "sha": "47973b7b453cfe2da4951ab222f57a2f5588ca40",
      "author": "Edward Ma",
      "date": "2022-07-01T04:34:47+00:00",
      "message": "Merge pull request #304 from JohnGiorgi/patch-2"
    },
    {
      "sha": "38647224f3882ed5fb04cc00a1905eee7f13cddb",
      "author": "John Giorgi",
      "date": "2022-06-25T23:17:46+00:00",
      "message": "Truncate to model max length in back translation"
    },
    {
      "sha": "16ce768749c2e02bfbe62fb6173a0673d522a739",
      "author": "logigo",
      "date": "2022-06-24T06:18:03+00:00",
      "message": "Change WordAugmenter clean type-checking to catch all list-comprehensible types"
    },
    {
      "sha": "28db07f68c962d9e58ece629ed1d88aa06fc1fe8",
      "author": "MarkusSagen",
      "date": "2022-06-17T17:00:23+00:00",
      "message": "Update Drive download and word2vec weights"
    },
    {
      "sha": "b5ae79e642f5a029e2a1502637ce45db08718aca",
      "author": "John Giorgi",
      "date": "2022-06-15T16:30:37+00:00",
      "message": "Fix typos in back_translation module"
    },
    {
      "sha": "66899326e51ad5c44e5b93307f94d4944f789a23",
      "author": "phunc20",
      "date": "2022-05-15T08:39:25+00:00",
      "message": "possible typo: candidate => candidiate"
    },
    {
      "sha": "40794970124c26ce2e587e567738247bf20ebcad",
      "author": "Edward Ma",
      "date": "2022-04-03T20:16:49+00:00",
      "message": "Merge pull request #276 from baskrahmer/patch-1"
    },
    {
      "sha": "4f19c30f0044b443525fa53029d5deeccff9412a",
      "author": "Edward Ma",
      "date": "2022-04-03T20:15:58+00:00",
      "message": "Merge pull request #277 from litanlitudan/tanl/update-readme-book-reference"
    },
    {
      "sha": "ac2fa651936cb8bb0734fb447cbcf293422a7e52",
      "author": "Edward Ma",
      "date": "2022-04-03T20:14:37+00:00",
      "message": "Merge pull request #281 from bp-high/patch-1"
    },
    {
      "sha": "9546b50702d178b070393507ce32351a76894897",
      "author": "Edward Ma",
      "date": "2022-04-03T20:13:15+00:00",
      "message": "Merge pull request #282 from Logigo/master"
    }
  ],
  "readme_text": "<p align=\"center\">\n    <br>\n    <img src=\"https://github.com/makcedward/nlpaug/blob/master/res/logo_small.png\"/>\n    <br>\n<p>\n<p align=\"center\">\n    <a href=\"https://travis-ci.org/makcedward/nlpaug\">\n        <img alt=\"Build\" src=\"https://travis-ci.org/makcedward/nlpaug.svg?branch=master\">\n    </a>\n    <a href=\"https://www.codacy.com/app/makcedward/nlpaug?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=makcedward/nlpaug&amp;utm_campaign=Badge_Grade\">\n        <img alt=\"Code Quality\" src=\"https://api.codacy.com/project/badge/Grade/2d6d1d08016a4f78818161a89a2dfbfb\">\n    </a>\n    <a href=\"https://pepy.tech/badge/nlpaug\">\n        <img alt=\"Downloads\" src=\"https://pepy.tech/badge/nlpaug\">\n    </a>\n</p>\n\n# nlpaug\n\nThis python library helps you with augmenting nlp for your machine learning projects. Visit this introduction to understand about [Data Augmentation in NLP](https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28). `Augmenter` is the basic element of augmentation while `Flow` is a pipeline to orchestra multi augmenter together.\n\n## Features\n*   Generate synthetic data for improving model performance without manual effort\n*   Simple, easy-to-use and lightweight library. Augment data in 3 lines of code\n*   Plug and play to any machine leanring/ neural network frameworks (e.g. scikit-learn, PyTorch, TensorFlow)\n*   Support textual and audio input\n\n<h3 align=\"center\">Textual Data Augmentation Example</h3>\n<br><p align=\"center\"><img src=\"https://github.com/makcedward/nlpaug/blob/master/res/textual_example.png\"/></p>\n<h3 align=\"center\">Acoustic Data Augmentation Example</h3>\n<br><p align=\"center\"><img src=\"https://github.com/makcedward/nlpaug/blob/master/res/audio_example.png\"/></p>\n\n| Section | Description |\n|:---:|:---:|\n| [Quick Demo](https://github.com/makcedward/nlpaug#quick-demo) | How to use this library |\n| [Augmenter](https://github.com/makcedward/nlpaug#augmenter) | Introduce all available augmentation methods |\n| [Installation](https://github.com/makcedward/nlpaug#installation) | How to install this library |\n| [Recent Changes](https://github.com/makcedward/nlpaug#recent-changes) | Latest enhancement |\n| [Extension Reading](https://github.com/makcedward/nlpaug#extension-reading) | More real life examples or researchs |\n| [Reference](https://github.com/makcedward/nlpaug#reference) | Reference of external resources such as data or model |\n\n## Quick Demo\n*   [Quick Example](https://github.com/makcedward/nlpaug/blob/master/example/quick_example.ipynb)\n*   [Example of Augmentation for Textual Inputs](https://github.com/makcedward/nlpaug/blob/master/example/textual_augmenter.ipynb)\n*   [Example of Augmentation for Multilingual Textual Inputs ](https://github.com/makcedward/nlpaug/blob/master/example/textual_language_augmenter.ipynb)\n*   [Example of Augmentation for Spectrogram Inputs](https://github.com/makcedward/nlpaug/blob/master/example/spectrogram_augmenter.ipynb)\n*   [Example of Augmentation for Audio Inputs](https://github.com/makcedward/nlpaug/blob/master/example/audio_augmenter.ipynb)\n*   [Example of Orchestra Multiple Augmenters](https://github.com/makcedward/nlpaug/blob/master/example/flow.ipynb)\n*   [Example of Showing Augmentation History](https://github.com/makcedward/nlpaug/blob/master/example/change_log.ipynb)\n*   How to train [TF-IDF model](https://github.com/makcedward/nlpaug/blob/master/example/tfidf-train_model.ipynb)\n*   How to train [LAMBADA model](https://github.com/makcedward/nlpaug/blob/master/example/lambada-train_model.ipynb)\n*   How to create [custom augmentation](https://github.com/makcedward/nlpaug/blob/master/example/custom_augmenter.ipynb)\n*   [API Documentation](https://nlpaug.readthedocs.io/en/latest/)\n\n## Augmenter\n| Augmenter | Target | Augmenter | Action | Description |\n|:---:|:---:|:---:|:---:|:---:|\n|Textual| Character | KeyboardAug | substitute | Simulate keyboard distance error |\n|Textual| | OcrAug | substitute | Simulate OCR engine error |\n|Textual| | [RandomAug](https://medium.com/hackernoon/does-your-nlp-model-able-to-prevent-adversarial-attack-45b5ab75129c) | insert, substitute, swap, delete | Apply augmentation randomly |\n|Textual| Word | AntonymAug | substitute | Substitute opposite meaning word according to WordNet antonym|\n|Textual| | ContextualWordEmbsAug | insert, substitute | Feeding surroundings word to [BERT](https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb), DistilBERT, [RoBERTa](https://medium.com/towards-artificial-intelligence/a-robustly-optimized-bert-pretraining-approach-f6b6e537e6a6) or [XLNet](https://medium.com/dataseries/why-does-xlnet-outperform-bert-da98a8503d5b) language model to find out the most suitlabe word for augmentation|\n|Textual| | RandomWordAug | swap, crop, delete | Apply augmentation randomly |\n|Textual| | SpellingAug | substitute | Substitute word according to spelling mistake dictionary |\n|Textual| | SplitAug | split | Split one word to two words randomly|\n|Textual| | SynonymAug | substitute | Substitute similar word according to WordNet/ PPDB synonym |\n|Textual| | [TfIdfAug](https://medium.com/towards-artificial-intelligence/unsupervised-data-augmentation-6760456db143) | insert, substitute | Use TF-IDF to find out how word should be augmented |\n|Textual| | WordEmbsAug | insert, substitute | Leverage  [word2vec](https://towardsdatascience.com/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a), [GloVe](https://towardsdatascience.com/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a) or [fasttext](https://towardsdatascience.com/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a) embeddings to apply augmentation|\n|Textual| | [BackTranslationAug](https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28) | substitute | Leverage two translation models for augmentation |\n|Textual| | ReservedAug | substitute | Replace reserved words |\n|Textual| Sentence | ContextualWordEmbsForSentenceAug | insert | Insert sentence according to [XLNet](https://medium.com/dataseries/why-does-xlnet-outperform-bert-da98a8503d5b), [GPT2](https://towardsdatascience.com/too-powerful-nlp-model-generative-pre-training-2-4cc6afb6655) or DistilGPT2 prediction |\n|Textual| | AbstSummAug | substitute | Summarize article by abstractive summarization method |\n|Textual| | LambadaAug | substitute | Using language model to generate text and then using classification model to retain high quality results |\n|Signal| Audio | CropAug | delete | Delete audio's segment |\n|Signal| | LoudnessAug|substitute | Adjust audio's volume |\n|Signal| | MaskAug | substitute | Mask audio's segment |\n|Signal| | NoiseAug | substitute | Inject noise |\n|Signal| | PitchAug | substitute | Adjust audio's pitch |\n|Signal| | ShiftAug | substitute | Shift time dimension forward/ backward |\n|Signal| | SpeedAug | substitute | Adjust audio's speed |\n|Signal| | VtlpAug | substitute | Change vocal tract |\n|Signal| | NormalizeAug | substitute | Normalize audio |\n|Signal| | PolarityInverseAug | substitute | Swap positive and negative for audio |\n|Signal| Spectrogram | FrequencyMaskingAug | substitute | Set block of values to zero according to frequency dimension |\n|Signal| | TimeMaskingAug | substitute | Set block of values to zero according to time dimension |\n|Signal| | LoudnessAug | substitute | Adjust volume |\n\n## Flow\n| Augmenter | Augmenter | Description |\n|:---:|:---:|:---:|\n|Pipeline| Sequential | Apply list of augmentation functions sequentially |\n|Pipeline| Sometimes | Apply some augmentation functions randomly |\n\n## Installation\nThe library supports python 3.5+ in linux and window platform.\n\nTo install the library:\n```bash\npip install numpy requests nlpaug\n```\nor install the latest version (include BETA features) from github directly\n```bash\npip install numpy git+https://github.com/makcedward/nlpaug.git\n```\nor install over conda\n```bash\nconda install -c makcedward nlpaug\n```\n\nIf you use BackTranslationAug, ContextualWordEmbsAug, ContextualWordEmbsForSentenceAug and AbstSummAug, installing the following dependencies as well\n```bash\npip install torch>=1.6.0 transformers>=4.11.3 sentencepiece\n```\n\nIf you use LambadaAug, installing the following dependencies as well\n```bash\npip install simpletransformers>=0.61.10\n```\n\nIf you use AntonymAug, SynonymAug, installing the following dependencies as well\n```bash\npip install nltk>=3.4.5\n```\n\nIf you use WordEmbsAug (word2vec, glove or fasttext), downloading pre-trained model first and installing the following dependencies as well\n```bash\nfrom nlpaug.util.file.download import DownloadUtil\nDownloadUtil.download_word2vec(dest_dir='.') # Download word2vec model\nDownloadUtil.download_glove(model_name='glove.6B', dest_dir='.') # Download GloVe model\nDownloadUtil.download_fasttext(model_name='wiki-news-300d-1M', dest_dir='.') # Download fasttext model\n\npip install gensim>=4.1.2\n```\n\nIf you use SynonymAug (PPDB), downloading file from the following URI. You may not able to run the augmenter if you get PPDB file from other website\n```bash\nhttp://paraphrase.org/#/download\n```\n\nIf you use PitchAug, SpeedAug and VtlpAug, installing the following dependencies as well\n```bash\npip install librosa>=0.9.1 matplotlib\n```\n\n## Recent Changes\n\n### 1.1.11 Jul 6, 2022\n*   [Return list of output](https://github.com/makcedward/nlpaug/issues/302)\n*   [Fix download util](https://github.com/makcedward/nlpaug/issues/301)\n*   [Fix lambda label misalignment](https://github.com/makcedward/nlpaug/issues/295)\n*   [Add language pack reference link for SynonymAug](https://github.com/makcedward/nlpaug/issues/289)\n\n\nSee [changelog](https://github.com/makcedward/nlpaug/blob/master/CHANGE.md) for more details.\n\n## Extension Reading\n*   [Data Augmentation library for Text](https://towardsdatascience.com/data-augmentation-library-for-text-9661736b13ff)\n*   [Does your NLP model able to prevent adversarial attack?](https://medium.com/hackernoon/does-your-nlp-model-able-to-prevent-adversarial-attack-45b5ab75129c)\n*   [How does Data Noising Help to Improve your NLP Model?](https://medium.com/towards-artificial-intelligence/how-does-data-noising-help-to-improve-your-nlp-model-480619f9fb10)\n*   [Data Augmentation library for Speech Recognition](https://towardsdatascience.com/data-augmentation-for-speech-recognition-e7c607482e78)\n*   [Data Augmentation library for Audio](https://towardsdatascience.com/data-augmentation-for-audio-76912b01fdf6)\n*   [Unsupervied Data Augmentation](https://medium.com/towards-artificial-intelligence/unsupervised-data-augmentation-6760456db143)\n*   [A Visual Survey of Data Augmentation in NLP](https://amitness.com/2020/05/data-augmentation-for-nlp/)\n\n## Reference\nThis library uses data (e.g. capturing from internet), research (e.g. following augmenter idea), model (e.g. using pre-trained model) See [data source](https://github.com/makcedward/nlpaug/blob/master/SOURCE.md) for more details.\n\n## Citation\n\n```latex\n@misc{ma2019nlpaug,\n  title={NLP Augmentation},\n  author={Edward Ma},\n  howpublished={https://github.com/makcedward/nlpaug},\n  year={2019}\n}\n```\n\nThis package is cited by many books, workshop and academic research papers (70+). Here are some of examples and you may visit [here](https://github.com/makcedward/nlpaug/blob/master/CITED.md) to get the full list.\n\n### Workshops cited nlpaug\n*   S. Vajjala. [NLP without a readymade labeled dataset](https://rpubs.com/vbsowmya/tmls2021) at [Toronto Machine Learning Summit, 2021](https://www.torontomachinelearning.com/). 2021\n\n### Book cited nlpaug\n*   S. Vajjala, B. Majumder, A. Gupta and H. Surana. [Practical Natural Language Processing: A Comprehensive Guide to Building Real-World NLP Systems](https://www.amazon.com/Practical-Natural-Language-Processing-Pragmatic/dp/1492054054). 2020\n*   A. Bartoli and A. Fusiello. [Computer Vision\u2013ECCV 2020 Workshops](https://books.google.com/books?hl=en&lr=lang_en&id=0rYREAAAQBAJ&oi=fnd&pg=PR7&dq=nlpaug&ots=88bPp5rhnY&sig=C2ue8Xxbu09l59nAMOcVxWYvvWM#v=onepage&q=nlpaug&f=false). 2020\n*   L. Werra, L. Tunstall, and T. Wolf [Natural Language Processing with Transformers](https://www.amazon.com/Natural-Language-Processing-Transformers-Applications/dp/1098103246/ref=sr_1_3?crid=2CWBPA8QG0TRU&keywords=Natural+Language+Processing+with+Transformers&qid=1645646312&sprefix=natural+language+processing+with+transformers%2Caps%2C111&sr=8-3). 2022\n\n### Research paper cited nlpaug\n*   Google: M. Raghu and  E. Schmidt. [A Survey of Deep Learning for Scientific Discovery](https://arxiv.org/pdf/2003.11755.pdf). 2020\n*   Sirius XM: E. Jing, K. Schneck, D. Egan and S. A. Waterman. [Identifying Introductions in Podcast Episodes from Automatically Generated Transcripts](https://arxiv.org/pdf/2110.07096.pdf). 2021\n*   Salesforce Research: B. Newman, P. K. Choubey and N. Rajani. [P-adapters: Robustly Extracting Factual Information from Language Modesl with Diverse Prompts](https://arxiv.org/pdf/2110.07280.pdf). 2021\n*   Salesforce Research: L. Xue, M. Gao, Z. Chen, C. Xiong and R. Xu. [Robustness Evaluation of Transformer-based Form Field Extractors via Form Attacks](https://arxiv.org/pdf/2110.04413.pdf). 2021\n\n\n## Contributions\n<table>\n  <tr>\n    <td align=\"center\"><a href=\"https://github.com/sakares\"><img src=\"https://avatars.githubusercontent.com/u/1306031\" width=\"100px;\" alt=\"\"/><br /><sub><b>sakares saengkaew</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/bdalal\"><img src=\"https://avatars.githubusercontent.com/u/3478378?s=400&v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Binoy Dalal</b></sub></a><br /></td>\n    <td align=\"center\"><a href=\"https://github.com/emrecncelik\"><img src=\"https://avatars.githubusercontent.com/u/20845117?v=4\" width=\"100px;\" alt=\"\"/><br /><sub><b>Emrecan \u00c7elik</b></sub></a><br /></td>\n  </tr>\n</table>",
  "external_links_in_readme": [
    "https://arxiv.org/pdf/2110.07280.pdf",
    "https://github.com/makcedward/nlpaug/blob/master/example/textual_augmenter.ipynb",
    "https://travis-ci.org/makcedward/nlpaug\">",
    "https://towardsdatascience.com/data-augmentation-for-audio-76912b01fdf6",
    "https://www.torontomachinelearning.com/",
    "https://books.google.com/books?hl=en&lr=lang_en&id=0rYREAAAQBAJ&oi=fnd&pg=PR7&dq=nlpaug&ots=88bPp5rhnY&sig=C2ue8Xxbu09l59nAMOcVxWYvvWM#v=onepage&q=nlpaug&f=false",
    "https://github.com/makcedward/nlpaug/blob/master/res/logo_small.png\"/>",
    "https://avatars.githubusercontent.com/u/3478378?s=400&v=4\"",
    "https://github.com/makcedward/nlpaug/issues/301",
    "https://medium.com/towards-artificial-intelligence/how-does-data-noising-help-to-improve-your-nlp-model-480619f9fb10",
    "https://github.com/makcedward/nlpaug/blob/master/example/tfidf-train_model.ipynb",
    "https://nlpaug.readthedocs.io/en/latest/",
    "https://avatars.githubusercontent.com/u/20845117?v=4\"",
    "https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28",
    "http://paraphrase.org/#/download",
    "https://towardsdatascience.com/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a",
    "https://towardsdatascience.com/data-augmentation-library-for-text-9661736b13ff",
    "https://github.com/emrecncelik\"><img",
    "https://github.com/makcedward/nlpaug/blob/master/res/audio_example.png\"/></p>",
    "https://github.com/makcedward/nlpaug/blob/master/example/textual_language_augmenter.ipynb",
    "https://towardsdatascience.com/too-powerful-nlp-model-generative-pre-training-2-4cc6afb6655",
    "https://github.com/makcedward/nlpaug/blob/master/example/audio_augmenter.ipynb",
    "https://github.com/makcedward/nlpaug/blob/master/example/custom_augmenter.ipynb",
    "https://github.com/makcedward/nlpaug#reference",
    "https://www.amazon.com/Natural-Language-Processing-Transformers-Applications/dp/1098103246/ref=sr_1_3?crid=2CWBPA8QG0TRU&keywords=Natural+Language+Processing+with+Transformers&qid=1645646312&sprefix=natural+language+processing+with+transformers%2Caps%2C111&sr=8-3",
    "https://github.com/makcedward/nlpaug.git",
    "https://avatars.githubusercontent.com/u/1306031\"",
    "https://github.com/makcedward/nlpaug/issues/289",
    "https://github.com/makcedward/nlpaug/blob/master/example/change_log.ipynb",
    "https://medium.com/towards-artificial-intelligence/unsupervised-data-augmentation-6760456db143",
    "https://github.com/sakares\"><img",
    "https://github.com/makcedward/nlpaug/issues/302",
    "https://github.com/makcedward/nlpaug/issues/295",
    "https://github.com/makcedward/nlpaug#augmenter",
    "https://github.com/bdalal\"><img",
    "https://github.com/makcedward/nlpaug/blob/master/SOURCE.md",
    "https://travis-ci.org/makcedward/nlpaug.svg?branch=master\">",
    "https://arxiv.org/pdf/2110.04413.pdf",
    "https://github.com/makcedward/nlpaug#recent-changes",
    "https://rpubs.com/vbsowmya/tmls2021",
    "https://www.amazon.com/Practical-Natural-Language-Processing-Pragmatic/dp/1492054054",
    "https://arxiv.org/pdf/2110.07096.pdf",
    "https://github.com/makcedward/nlpaug#extension-reading",
    "https://github.com/makcedward/nlpaug/blob/master/res/textual_example.png\"/></p>",
    "https://medium.com/hackernoon/does-your-nlp-model-able-to-prevent-adversarial-attack-45b5ab75129c",
    "https://medium.com/towards-artificial-intelligence/a-robustly-optimized-bert-pretraining-approach-f6b6e537e6a6",
    "https://github.com/makcedward/nlpaug/blob/master/CHANGE.md",
    "https://amitness.com/2020/05/data-augmentation-for-nlp/",
    "https://github.com/makcedward/nlpaug#quick-demo",
    "https://pepy.tech/badge/nlpaug\">",
    "https://github.com/makcedward/nlpaug/blob/master/example/quick_example.ipynb",
    "https://arxiv.org/pdf/2003.11755.pdf",
    "https://github.com/makcedward/nlpaug/blob/master/example/lambada-train_model.ipynb",
    "https://www.codacy.com/app/makcedward/nlpaug?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=makcedward/nlpaug&amp;utm_campaign=Badge_Grade\">",
    "https://github.com/makcedward/nlpaug/blob/master/example/spectrogram_augmenter.ipynb",
    "https://medium.com/dataseries/why-does-xlnet-outperform-bert-da98a8503d5b",
    "https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb",
    "https://github.com/makcedward/nlpaug/blob/master/CITED.md",
    "https://github.com/makcedward/nlpaug/blob/master/example/flow.ipynb",
    "https://github.com/makcedward/nlpaug},",
    "https://towardsdatascience.com/data-augmentation-for-speech-recognition-e7c607482e78",
    "https://api.codacy.com/project/badge/Grade/2d6d1d08016a4f78818161a89a2dfbfb\">",
    "https://github.com/makcedward/nlpaug#installation"
  ]
}
```

</details>


---

