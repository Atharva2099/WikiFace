# GitHub Data for CIDAS_clipseg-rd64-refined

**Task Category:** Image Segmentation

## Repository 1: timojl/clipseg

# GitHub Repository Data

**Repository:** [timojl/clipseg](https://github.com/timojl/clipseg)

## Basic Information

- **Description:** This repository contains the code of the CVPR 2022 paper "Image Segmentation Using Text and Image Prompts".
- **Created:** 2021-11-22T13:31:13+00:00
- **Last Updated:** 2025-06-20T09:48:24+00:00
- **Last Pushed:** 2024-01-05T10:36:22+00:00
- **Default Branch:** master
- **Size:** 1415 KB

## Statistics

- **Stars:** 1,242
- **Forks:** 111
- **Watchers:** 1,242
- **Open Issues:** 4
- **Total Issues:** 0
- **Pull Requests:** 3

## License

- **Type:** Other
- **SPDX ID:** NOASSERTION
- **URL:** [License](https://github.com/timojl/clipseg/blob/master/LICENSE)

## Languages

- **Python:** 118,511 bytes
- **Jupyter Notebook:** 27,261 bytes

## Top Contributors

1. **timojl** - 51 contributions
2. **stephenbach** - 3 contributions
3. **mikljohansson** - 1 contributions

## File Structure (Sample of 10 files)

Total files: 37

- `.gitattributes` (blob)
- `.gitignore` (blob)
- `LICENSE` (blob)
- `Quickstart.ipynb` (blob)
- `README.md` (blob)
- `Tables.ipynb` (blob)
- `Visual_Feature_Engineering.ipynb` (blob)
- `__init__.py` (blob)
- `clip_masking_lvis_image_ids.yml` (blob)
- `datasets` (tree)

## Recent Issues

- 游릭 **#60** ModuleNotFoundError - CLIP (open)
- 游릭 **#59** precomputed_prompt_vectors.pickle File Not Found (open)
- 游릭 **#58** Does it support converting models to onnx or tensorrt? (open)
- 游릭 **#55** Executing training.py gets error regards clip package. (open)
- 游댮 **#54** FileNotFoundError: [Errno 2] No such file or directory: '~/datasets/COCO-20i/annotations/train2014/COCO_train2014_000000236141.png' (closed)

## Recent Pull Requests

- 游댮 **#31** Update environment.yml (closed)
- 游댮 **#11** Fixed pip install failing due to missing README.md (closed)
- 游댮 **#7** Add setup.py and .gitignore. (closed)

## Recent Commits

- **77c4e2dc** added __init__ to root folder - timo (2024-01-05T10:35:59+00:00)
- **8921374d** Create clip_masking_lvis_image_ids.yml - Timo L칲ddecke (2023-07-13T18:18:43+00:00)
- **bbc86cfb** Create pascal_0shot.yaml - Timo L칲ddecke (2023-03-19T12:34:36+00:00)
- **7874def3** Merge pull request #31 from timojl/timojl-patch-env - Timo L칲ddecke (2023-03-19T10:21:22+00:00)
- **a0e14de6** Update environment.yml - Timo L칲ddecke (2023-03-19T10:14:13+00:00)
- **c72775ec** Update Tables.ipynb - Timo L칲ddecke (2023-03-09T16:35:10+00:00)
- **95ee271d** Update phrasecut.yaml - Timo L칲ddecke (2023-02-27T07:57:58+00:00)
- **a5dc13f3** Update pfe_dataset.py - Timo L칲ddecke (2022-11-28T08:24:34+00:00)
- **656e0c66** Update README.md - Timo L칲ddecke (2022-11-09T15:49:50+00:00)
- **0d6ea76e** Update phrasecut.py - Timo L칲ddecke (2022-11-09T15:26:37+00:00)

## External Links Found in README

- https://github.com/ChenyunWu/PhraseCutDataset.git
- https://github.com/cvlab-yonsei/JoEm
- https://github.com/NielsRogge
- https://mybinder.org/v2/gh/timojl/clipseg/HEAD?labpath=Quickstart.ipynb
- https://github.com/openai/CLIP.git`
- https://github.com/Jia-Research-Lab/PFENet.git
- https://owncloud.gwdg.de/index.php/s/ioHbRzFx6th32hn/download
- https://github.com/juhongm999/hsnet.git
- https://huggingface.co/docs/transformers/main/en/model_doc/clipseg
- https://arxiv.org/abs/2112.10003

## Raw Data

<details>
<summary>Click to expand raw JSON data</summary>

```json
{
  "id": 430718886,
  "name": "clipseg",
  "full_name": "timojl/clipseg",
  "description": "This repository contains the code of the CVPR 2022 paper \"Image Segmentation Using Text and Image Prompts\".",
  "html_url": "https://github.com/timojl/clipseg",
  "clone_url": "https://github.com/timojl/clipseg.git",
  "ssh_url": "git@github.com:timojl/clipseg.git",
  "homepage": "",
  "topics": [],
  "default_branch": "master",
  "created_at": "2021-11-22T13:31:13+00:00",
  "updated_at": "2025-06-20T09:48:24+00:00",
  "pushed_at": "2024-01-05T10:36:22+00:00",
  "size_kb": 1415,
  "watchers_count": 1242,
  "stargazers_count": 1242,
  "forks_count": 111,
  "open_issues_count": 4,
  "license": {
    "key": "other",
    "name": "Other",
    "spdx_id": "NOASSERTION",
    "url": "https://github.com/timojl/clipseg/blob/master/LICENSE"
  },
  "languages": {
    "Python": 118511,
    "Jupyter Notebook": 27261
  },
  "top_contributors": [
    {
      "login": "timojl",
      "contributions": 51
    },
    {
      "login": "stephenbach",
      "contributions": 3
    },
    {
      "login": "mikljohansson",
      "contributions": 1
    }
  ],
  "file_tree_count": 37,
  "file_tree_sample": [
    {
      "path": ".gitattributes",
      "type": "blob"
    },
    {
      "path": ".gitignore",
      "type": "blob"
    },
    {
      "path": "LICENSE",
      "type": "blob"
    },
    {
      "path": "Quickstart.ipynb",
      "type": "blob"
    },
    {
      "path": "README.md",
      "type": "blob"
    },
    {
      "path": "Tables.ipynb",
      "type": "blob"
    },
    {
      "path": "Visual_Feature_Engineering.ipynb",
      "type": "blob"
    },
    {
      "path": "__init__.py",
      "type": "blob"
    },
    {
      "path": "clip_masking_lvis_image_ids.yml",
      "type": "blob"
    },
    {
      "path": "datasets",
      "type": "tree"
    }
  ],
  "issues_count": 0,
  "pulls_count": 3,
  "recent_issues": [
    {
      "number": 60,
      "title": "ModuleNotFoundError - CLIP",
      "state": "open"
    },
    {
      "number": 59,
      "title": "precomputed_prompt_vectors.pickle File Not Found",
      "state": "open"
    },
    {
      "number": 58,
      "title": "Does it support converting models to onnx or tensorrt?",
      "state": "open"
    },
    {
      "number": 55,
      "title": "Executing training.py gets error regards clip package.",
      "state": "open"
    },
    {
      "number": 54,
      "title": "FileNotFoundError: [Errno 2] No such file or directory: '~/datasets/COCO-20i/annotations/train2014/COCO_train2014_000000236141.png'",
      "state": "closed"
    }
  ],
  "recent_pulls": [
    {
      "number": 31,
      "title": "Update environment.yml",
      "state": "closed"
    },
    {
      "number": 11,
      "title": "Fixed pip install failing due to missing README.md",
      "state": "closed"
    },
    {
      "number": 7,
      "title": "Add setup.py and .gitignore.",
      "state": "closed"
    }
  ],
  "recent_commits": [
    {
      "sha": "77c4e2dc853880df46413d4a870a725e961f2f73",
      "author": "timo",
      "date": "2024-01-05T10:35:59+00:00",
      "message": "added __init__ to root folder"
    },
    {
      "sha": "8921374d38ce394e94c71fd7757ba8c652527bab",
      "author": "Timo L\u00fcddecke",
      "date": "2023-07-13T18:18:43+00:00",
      "message": "Create clip_masking_lvis_image_ids.yml"
    },
    {
      "sha": "bbc86cfbb7e6a47fb6dae47ba01d3e1c2d6158b0",
      "author": "Timo L\u00fcddecke",
      "date": "2023-03-19T12:34:36+00:00",
      "message": "Create pascal_0shot.yaml"
    },
    {
      "sha": "7874def36593ea3cb847df6604aa098cc035a669",
      "author": "Timo L\u00fcddecke",
      "date": "2023-03-19T10:21:22+00:00",
      "message": "Merge pull request #31 from timojl/timojl-patch-env"
    },
    {
      "sha": "a0e14de65ce6c1baf6f411439cc1346a36374759",
      "author": "Timo L\u00fcddecke",
      "date": "2023-03-19T10:14:13+00:00",
      "message": "Update environment.yml"
    },
    {
      "sha": "c72775ec4b4032b0d598932149313e40e0096f39",
      "author": "Timo L\u00fcddecke",
      "date": "2023-03-09T16:35:10+00:00",
      "message": "Update Tables.ipynb"
    },
    {
      "sha": "95ee271d8d4d75fc7e13bdd04dac4a907402662b",
      "author": "Timo L\u00fcddecke",
      "date": "2023-02-27T07:57:58+00:00",
      "message": "Update phrasecut.yaml"
    },
    {
      "sha": "a5dc13f3649ce67d58505401ce7a7dd25601ffba",
      "author": "Timo L\u00fcddecke",
      "date": "2022-11-28T08:24:34+00:00",
      "message": "Update pfe_dataset.py"
    },
    {
      "sha": "656e0c662bd1c9a5ae511011642da5b7d8503312",
      "author": "Timo L\u00fcddecke",
      "date": "2022-11-09T15:49:50+00:00",
      "message": "Update README.md"
    },
    {
      "sha": "0d6ea76ede489efa63c4ede8ad1816f2eb899d59",
      "author": "Timo L\u00fcddecke",
      "date": "2022-11-09T15:26:37+00:00",
      "message": "Update phrasecut.py"
    },
    {
      "sha": "a55510bc60aac9454a23fc417c7033de2f56c543",
      "author": "Timo L\u00fcddecke",
      "date": "2022-10-25T14:42:21+00:00",
      "message": "Update clipseg.py"
    },
    {
      "sha": "ac8f4d03229c6b55fe54cfe04f84a9e895933740",
      "author": "Timo L\u00fcddecke",
      "date": "2022-10-24T14:54:44+00:00",
      "message": "removed legacy code"
    },
    {
      "sha": "41d9ba2ab85009105ab3fe92064dea029b99c712",
      "author": "Timo L\u00fcddecke",
      "date": "2022-10-12T07:34:55+00:00",
      "message": "Merge pull request #11 from mikljohansson/fix_pip_install"
    },
    {
      "sha": "414bd83cd9b344df5219af2ba239540b020adcc1",
      "author": "Mikael Johansson",
      "date": "2022-10-03T13:15:20+00:00",
      "message": "Fixed pip install failing due to missing README.md"
    },
    {
      "sha": "515ca6ec2d066d447240c1dd79f3bbbee685bd29",
      "author": "timo",
      "date": "2022-09-27T08:03:44+00:00",
      "message": "added samples for fine-grained weights"
    },
    {
      "sha": "d46e9e0e87e7996a25c7597f0f9625fb4cc926d5",
      "author": "timo",
      "date": "2022-09-27T07:16:13+00:00",
      "message": "Merge branch 'master' of github.com:timojl/clipseg"
    },
    {
      "sha": "ea54753df1e444c4445bac6e023546b6a41951d8",
      "author": "timo",
      "date": "2022-09-27T07:14:45+00:00",
      "message": "added complex token -> patch transformation"
    },
    {
      "sha": "20528872e2a439ee720d645c391a30f70508c327",
      "author": "Timo L\u00fcddecke",
      "date": "2022-09-23T07:36:38+00:00",
      "message": "Update Quickstart.ipynb"
    },
    {
      "sha": "fd4ab46dd236868b9eefad7ae836f247a9c26373",
      "author": "Timo L\u00fcddecke",
      "date": "2022-09-23T07:34:38+00:00",
      "message": "Delete weights directory"
    },
    {
      "sha": "6cc455990dcd9a94ef3d3f173e6322dd80411b48",
      "author": "Timo L\u00fcddecke",
      "date": "2022-09-23T07:33:38+00:00",
      "message": "Update Readme.md"
    }
  ],
  "readme_text": "# Image Segmentation Using Text and Image Prompts\nThis repository contains the code used in the paper [\"Image Segmentation Using Text and Image Prompts\"](https://arxiv.org/abs/2112.10003).\n\n**November 2022:** CLIPSeg has been integrated into the [HuggingFace Transformers library](https://huggingface.co/docs/transformers/main/en/model_doc/clipseg). Thank you, [NielsRogge](https://github.com/NielsRogge)!  \n**September 2022:** We released new weights for fine-grained predictions (see below for details).  \n**March 2022:** The Paper has been accepted to CVPR 2022!\n\n\n<img src=\"overview.png\" alt=\"drawing\" height=\"200em\"/>\n\nThe systems allows to create segmentation models without training based on:\n- An arbitrary text query\n- Or an image with a mask highlighting stuff or an object.\n\n### Quick Start\n\nIn the `Quickstart.ipynb` notebook we provide the code for using a pre-trained CLIPSeg model. If you run the notebook locally, make sure you downloaded the `rd64-uni.pth` weights, either manually or via git lfs extension.\nIt can also be used interactively using [MyBinder](https://mybinder.org/v2/gh/timojl/clipseg/HEAD?labpath=Quickstart.ipynb)\n(please note that the VM does not use a GPU, thus inference takes a few seconds).\n\n\n### Dependencies\nThis code base depends on pytorch, torchvision and clip (`pip install git+https://github.com/openai/CLIP.git`).\nAdditional dependencies are hidden for double blind review.\n\n\n### Datasets\n\n* `PhraseCut` and `PhraseCutPlus`: Referring expression dataset\n* `PFEPascalWrapper`: Wrapper class for PFENet's Pascal-5i implementation\n* `PascalZeroShot`: Wrapper class for PascalZeroShot\n* `COCOWrapper`: Wrapper class for COCO.\n\n### Models\n\n* `CLIPDensePredT`: CLIPSeg model with transformer-based decoder.\n* `ViTDensePredT`: CLIPSeg model with transformer-based decoder.\n\n### Third Party Dependencies\nFor some of the datasets third party dependencies are required. Run the following commands in the `third_party` folder.  \n```bash\ngit clone https://github.com/cvlab-yonsei/JoEm\ngit clone https://github.com/Jia-Research-Lab/PFENet.git\ngit clone https://github.com/ChenyunWu/PhraseCutDataset.git\ngit clone https://github.com/juhongm999/hsnet.git\n```\n\n### Weights\n\nThe MIT license does not apply to these weights. \n\nWe provide three model weights, for D=64 (2x, ~4MB each) and D=16 (~1MB).\n```\nwget https://owncloud.gwdg.de/index.php/s/ioHbRzFx6th32hn/download -O weights.zip\nunzip -d weights -j weights.zip\n```\n\n#### New Fine-grained Weights\nWe introduced a more complex module for transforming tokens into predictions that allow for more refined predictions (in contrast to the square-like predictions of other weights). Corresponding weights are available in the weight download above called `rd64-uni-refined.pth`.\nThey can be loaded by:\n```python\nmodel = CLIPDensePredT(version='ViT-B/16', reduce_dim=64, complex_trans_conv=True)\nmodel.load_state_dict(torch.load('weights/rd64-uni-refined.pth'), strict=False)\n```\n\nSee below for a direct comparison of the new fine-grained weights (top) and the old weights (below).  \n<img src=\"sample_rd64_refined.png\" alt=\"drawing\" height=\"80em\"/>  \n<img src=\"sample_rd64.png\" alt=\"drawing\" height=\"80em\"/>\n\n\n\n### Training and Evaluation\n\nTo train use the `training.py` script with experiment file and experiment id parameters. E.g. `python training.py phrasecut.yaml 0` will train the first phrasecut experiment which is defined by the `configuration` and first `individual_configurations` parameters. Model weights will be written in `logs/`.\n\nFor evaluation use `score.py`. E.g. `python score.py phrasecut.yaml 0 0` will train the first phrasecut experiment of `test_configuration` and the first configuration in `individual_configurations`.\n\n\n### Usage of PFENet Wrappers\n\nIn order to use the dataset and model wrappers for PFENet, the PFENet repository needs to be cloned to the root folder.\n`git clone https://github.com/Jia-Research-Lab/PFENet.git `\n\n\n### License\n\nThe source code files in this repository (excluding model weights) are released under MIT license.\n\n### Citation\n```\n@InProceedings{lueddecke22_cvpr,\n    author    = {L\\\"uddecke, Timo and Ecker, Alexander},\n    title     = {Image Segmentation Using Text and Image Prompts},\n    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n    month     = {June},\n    year      = {2022},\n    pages     = {7086-7096}\n}\n\n```\n",
  "external_links_in_readme": [
    "https://github.com/ChenyunWu/PhraseCutDataset.git",
    "https://github.com/cvlab-yonsei/JoEm",
    "https://github.com/NielsRogge",
    "https://mybinder.org/v2/gh/timojl/clipseg/HEAD?labpath=Quickstart.ipynb",
    "https://github.com/openai/CLIP.git`",
    "https://github.com/Jia-Research-Lab/PFENet.git",
    "https://owncloud.gwdg.de/index.php/s/ioHbRzFx6th32hn/download",
    "https://github.com/juhongm999/hsnet.git",
    "https://huggingface.co/docs/transformers/main/en/model_doc/clipseg",
    "https://arxiv.org/abs/2112.10003"
  ]
}
```

</details>


---

