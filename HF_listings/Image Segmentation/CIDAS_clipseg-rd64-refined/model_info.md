# CIDAS/clipseg-rd64-refined

## Model Information

- **Model ID**: CIDAS/clipseg-rd64-refined
- **Author**: CIDAS
- **Last Updated**: 2024-12-11 09:46:10+00:00
- **Repository**: https://huggingface.co/CIDAS/clipseg-rd64-refined

## Tags

transformers, pytorch, safetensors, clipseg, vision, image-segmentation, arxiv:2112.10003, license:apache-2.0, region:us

## File Tree

- **.gitattributes** (None bytes)
  - Download: [https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/.gitattributes](https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/.gitattributes)
- **README.md** (None bytes)
  - Download: [https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/README.md](https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/README.md)
- **config.json** (None bytes)
  - Download: [https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/config.json](https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/config.json)
- **merges.txt** (None bytes)
  - Download: [https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/merges.txt](https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/merges.txt)
- **model.safetensors** (None bytes)
  - Download: [https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/model.safetensors](https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/model.safetensors)
- **preprocessor_config.json** (None bytes)
  - Download: [https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/preprocessor_config.json](https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/preprocessor_config.json)
- **pytorch_model.bin** (None bytes)
  - Download: [https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/pytorch_model.bin](https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/pytorch_model.bin)
- **special_tokens_map.json** (None bytes)
  - Download: [https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/special_tokens_map.json](https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/special_tokens_map.json)
- **tokenizer_config.json** (None bytes)
  - Download: [https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/tokenizer_config.json](https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/tokenizer_config.json)
- **vocab.json** (None bytes)
  - Download: [https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/vocab.json](https://huggingface.co/CIDAS/clipseg-rd64-refined/resolve/main/vocab.json)


## External Links

- [arxiv.org](https://arxiv.org/abs/2112.10003)
- [github.com](https://github.com/timojl/clipseg)
- [huggingface.co](https://huggingface.co/docs/transformers/main/en/model_doc/clipseg)


## README.md

```markdown
---
license: apache-2.0
tags:
- vision
- image-segmentation
inference: false
---

# CLIPSeg model 

CLIPSeg model with reduce dimension 64, refined (using a more complex convolution). It was introduced in the paper [Image Segmentation Using Text and Image Prompts](https://arxiv.org/abs/2112.10003) by LÃ¼ddecke et al. and first released in [this repository](https://github.com/timojl/clipseg). 

# Intended use cases

This model is intended for zero-shot and one-shot image segmentation.

# Usage

Refer to the [documentation](https://huggingface.co/docs/transformers/main/en/model_doc/clipseg).
```


---

*Generated on 2025-06-21 15:07:05*
*Source: https://huggingface.co/CIDAS/clipseg-rd64-refined*
