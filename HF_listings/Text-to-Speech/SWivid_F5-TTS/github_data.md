# GitHub Data for SWivid_F5-TTS

**Task Category:** Text-to-Speech

## Repository 1: SWivid/F5-TTS

# GitHub Repository Data

**Repository:** [SWivid/F5-TTS](https://github.com/SWivid/F5-TTS)

## Basic Information

- **Description:** Official code for "F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching"
- **Created:** 2024-10-08T13:36:55+00:00
- **Last Updated:** 2025-06-22T01:31:27+00:00
- **Last Pushed:** 2025-06-11T19:54:04+00:00
- **Default Branch:** main
- **Size:** 2209 KB

## Statistics

- **Stars:** 12,392
- **Forks:** 1,784
- **Watchers:** 12,392
- **Open Issues:** 34
- **Total Issues:** 0
- **Pull Requests:** 186

## License

- **Type:** MIT License
- **SPDX ID:** MIT
- **URL:** [License](https://github.com/SWivid/F5-TTS/blob/main/LICENSE)

## Languages

- **Python:** 489,854 bytes
- **Shell:** 7,040 bytes
- **Dockerfile:** 865 bytes

## Top Contributors

1. **SWivid** - 347 contributions
2. **lpscr** - 73 contributions
3. **ZhikangNiu** - 42 contributions
4. **kunci115** - 14 contributions
5. **hcsolakoglu** - 13 contributions
6. **jpgallegoar** - 13 contributions
7. **fakerybakery** - 12 contributions
8. **JarodMica** - 10 contributions
9. **huanglizhuo** - 4 contributions
10. **cocktailpeanut** - 4 contributions

## File Structure (Sample of 10 files)

Total files: 125

- `.github` (tree)
- `.github/ISSUE_TEMPLATE` (tree)
- `.github/ISSUE_TEMPLATE/bug_report.yml` (blob)
- `.github/ISSUE_TEMPLATE/config.yml` (blob)
- `.github/ISSUE_TEMPLATE/feature_request.yml` (blob)
- `.github/ISSUE_TEMPLATE/help_wanted.yml` (blob)
- `.github/ISSUE_TEMPLATE/question.yml` (blob)
- `.github/workflows` (tree)
- `.github/workflows/pre-commit.yaml` (blob)
- `.github/workflows/publish-docker-image.yaml` (blob)

## Recent Issues

- üü¢ **#1097** Query regarding the amount of data used for training F5-TTS Small (open)
- üü¢ **#1096** Conditioning on 54 emotion scores and freestyle emotion captions (open)
- üü¢ **#1094** Couldn't assign noise with shape torch.Size([3660, 100]), engine supports [min, opt, max] = [(2, 100, 100), (2, 1500, 100), (8, 3000, 100)] (open)
- üü¢ **#1093** gradio root_path configuration not effective in f5-tts_infer-gradio (open)
- üü¢ **#1092** help pls (open)

## Recent Pull Requests

- üü¢ **#1091** Update WAV File Naming and Dependencies üìùüîä (open)
- üî¥ **#1084** Speedup inference by batching CFG in DiT (closed)
- üî¥ **#1077** Update: Empirically Pruned Step Sampling (closed)
- üî¥ **#1076** docs: add installation requirements to README (closed)
- üî¥ **#1072** German Model support (closed)

## Recent Commits

- **8975fca8** Merge pull request #1084 from starkwj/main - Yushen CHEN (2025-06-11T19:54:04+00:00)
- **8b0053ad** backward compatibility - SWivid (2025-06-11T19:52:12+00:00)
- **b3ef4ed1** correct imple., minor fixes - SWivid (2025-06-11T19:32:19+00:00)
- **b1a94384** Batch cfg DiT forward - starkwj (2025-06-11T09:03:30+00:00)
- **0914170e** Add flash_attn2 support attn_mask, minor fixes (#1066) - Zhikang Niu (2025-06-11T04:14:32+00:00)
- **c6ebad02** switch sync-hf workflow logic on release, avoid hidden space error with pypi/local_editable mismatch - SWivid (2025-06-05T23:23:54+00:00)
- **cfaba638** refresh hf-space first - SWivid (2025-06-05T23:22:02+00:00)
- **646f34b2** v1.1.5 pypi - SWivid (2025-06-05T23:08:59+00:00)
- **2e2acc6e** Update: Empirically Pruned Step Sampling (#1077) - Jerrister Zheng (2025-06-04T14:59:30+00:00)
- **6fbe7592** rebase default sample_rate to 24khz for runtime - SWivid (2025-06-04T03:22:31+00:00)

## External Links Found in README

- https://download.pytorch.org/whl/rocm6.2
- https://github.com/lucidrains
- https://github.com/SWivid/F5-TTS/issues?q=is%3Aissue
- https://github.com/bfs18
- https://img.shields.io/badge/arXiv-2410.06885-b31b1b.svg?logo=arXiv
- https://pytorch-extension.intel.com/installation?request=platform
- https://arxiv.org/abs/2406.18009
- https://www.modelscope.cn/models/SWivid/F5-TTS_Emilia-ZH-EN
- https://github.com/tarepan/SpeechMOS
- https://github.com/NVIDIA/BigVGAN
- https://img.shields.io/badge/ü§ñ-Space%20demo-blue
- https://github.com/user-attachments/assets/12d7749c-071a-427c-81bf-b87b91def670"
- https://github.com/MahmoudAshraf97/ctc-forced-aligner
- https://huggingface.co/charactr/vocos-mel-24khz
- https://github.com/DakeQQ
- https://img.shields.io/badge/ü§ó-Space%20demo-yellow
- https://x-lance.sjtu.edu.cn/
- https://modelscope.cn/studios/modelscope/E2-F5-TTS
- https://swivid.github.io/F5-TTS_updates
- https://huggingface.co/SWivid/F5-TTS

## Raw Data

<details>
<summary>Click to expand raw JSON data</summary>

```json
{
  "id": 869549554,
  "name": "F5-TTS",
  "full_name": "SWivid/F5-TTS",
  "description": "Official code for \"F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching\"",
  "html_url": "https://github.com/SWivid/F5-TTS",
  "clone_url": "https://github.com/SWivid/F5-TTS.git",
  "ssh_url": "git@github.com:SWivid/F5-TTS.git",
  "homepage": "https://arxiv.org/abs/2410.06885",
  "topics": [],
  "default_branch": "main",
  "created_at": "2024-10-08T13:36:55+00:00",
  "updated_at": "2025-06-22T01:31:27+00:00",
  "pushed_at": "2025-06-11T19:54:04+00:00",
  "size_kb": 2209,
  "watchers_count": 12392,
  "stargazers_count": 12392,
  "forks_count": 1784,
  "open_issues_count": 34,
  "license": {
    "key": "mit",
    "name": "MIT License",
    "spdx_id": "MIT",
    "url": "https://github.com/SWivid/F5-TTS/blob/main/LICENSE"
  },
  "languages": {
    "Python": 489854,
    "Shell": 7040,
    "Dockerfile": 865
  },
  "top_contributors": [
    {
      "login": "SWivid",
      "contributions": 347
    },
    {
      "login": "lpscr",
      "contributions": 73
    },
    {
      "login": "ZhikangNiu",
      "contributions": 42
    },
    {
      "login": "kunci115",
      "contributions": 14
    },
    {
      "login": "hcsolakoglu",
      "contributions": 13
    },
    {
      "login": "jpgallegoar",
      "contributions": 13
    },
    {
      "login": "fakerybakery",
      "contributions": 12
    },
    {
      "login": "JarodMica",
      "contributions": 10
    },
    {
      "login": "huanglizhuo",
      "contributions": 4
    },
    {
      "login": "cocktailpeanut",
      "contributions": 4
    },
    {
      "login": "AsmoKoskinen",
      "contributions": 4
    },
    {
      "login": "petermg",
      "contributions": 4
    },
    {
      "login": "justinjohn0306",
      "contributions": 4
    },
    {
      "login": "DDXDB",
      "contributions": 3
    },
    {
      "login": "YoungPhlo",
      "contributions": 3
    },
    {
      "login": "Jerrister",
      "contributions": 2
    },
    {
      "login": "atlonxp",
      "contributions": 2
    },
    {
      "login": "Chiyan200",
      "contributions": 2
    },
    {
      "login": "yuekaizhang",
      "contributions": 2
    },
    {
      "login": "HotDro4illa",
      "contributions": 2
    }
  ],
  "file_tree_count": 125,
  "file_tree_sample": [
    {
      "path": ".github",
      "type": "tree"
    },
    {
      "path": ".github/ISSUE_TEMPLATE",
      "type": "tree"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/bug_report.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/config.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/feature_request.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/help_wanted.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/question.yml",
      "type": "blob"
    },
    {
      "path": ".github/workflows",
      "type": "tree"
    },
    {
      "path": ".github/workflows/pre-commit.yaml",
      "type": "blob"
    },
    {
      "path": ".github/workflows/publish-docker-image.yaml",
      "type": "blob"
    }
  ],
  "issues_count": 0,
  "pulls_count": 186,
  "recent_issues": [
    {
      "number": 1097,
      "title": "Query regarding the amount of data used for training F5-TTS Small",
      "state": "open"
    },
    {
      "number": 1096,
      "title": "Conditioning on 54 emotion scores and freestyle emotion captions",
      "state": "open"
    },
    {
      "number": 1094,
      "title": "Couldn't assign noise with shape torch.Size([3660, 100]), engine supports [min, opt, max] = [(2, 100, 100), (2, 1500, 100), (8, 3000, 100)]",
      "state": "open"
    },
    {
      "number": 1093,
      "title": "gradio root_path configuration not effective in f5-tts_infer-gradio",
      "state": "open"
    },
    {
      "number": 1092,
      "title": "help pls",
      "state": "open"
    }
  ],
  "recent_pulls": [
    {
      "number": 1091,
      "title": "Update WAV File Naming and Dependencies \ud83d\udcdd\ud83d\udd0a",
      "state": "open"
    },
    {
      "number": 1084,
      "title": "Speedup inference by batching CFG in DiT",
      "state": "closed"
    },
    {
      "number": 1077,
      "title": "Update: Empirically Pruned Step Sampling",
      "state": "closed"
    },
    {
      "number": 1076,
      "title": "docs: add installation requirements to README",
      "state": "closed"
    },
    {
      "number": 1072,
      "title": "German Model support",
      "state": "closed"
    }
  ],
  "recent_commits": [
    {
      "sha": "8975fca803894dda767de674ce3667c8b5e190af",
      "author": "Yushen CHEN",
      "date": "2025-06-11T19:54:04+00:00",
      "message": "Merge pull request #1084 from starkwj/main"
    },
    {
      "sha": "8b0053ad0cab9bde8b12c63780a75ac5c3d3ca76",
      "author": "SWivid",
      "date": "2025-06-11T19:52:12+00:00",
      "message": "backward compatibility"
    },
    {
      "sha": "b3ef4ed1d732772389b5c0fbf8a5803c910e8e26",
      "author": "SWivid",
      "date": "2025-06-11T19:32:19+00:00",
      "message": "correct imple., minor fixes"
    },
    {
      "sha": "b1a94384961b5e6b2272773128ecf76233db77df",
      "author": "starkwj",
      "date": "2025-06-11T09:03:30+00:00",
      "message": "Batch cfg DiT forward"
    },
    {
      "sha": "0914170e98916b181bc84cb90213f5350abda42c",
      "author": "Zhikang Niu",
      "date": "2025-06-11T04:14:32+00:00",
      "message": "Add flash_attn2 support attn_mask, minor fixes (#1066)"
    },
    {
      "sha": "c6ebad0220059d7084c15a44b88be7bd399041cb",
      "author": "SWivid",
      "date": "2025-06-05T23:23:54+00:00",
      "message": "switch sync-hf workflow logic on release, avoid hidden space error with pypi/local_editable mismatch"
    },
    {
      "sha": "cfaba6387f291726238923ef04e00a937b74ac00",
      "author": "SWivid",
      "date": "2025-06-05T23:22:02+00:00",
      "message": "refresh hf-space first"
    },
    {
      "sha": "646f34b20fd233b1de813811343add64f0d1eca9",
      "author": "SWivid",
      "date": "2025-06-05T23:08:59+00:00",
      "message": "v1.1.5 pypi"
    },
    {
      "sha": "2e2acc6ea27bcfa7fca01cf2d01422de2a126ccd",
      "author": "Jerrister Zheng",
      "date": "2025-06-04T14:59:30+00:00",
      "message": "Update: Empirically Pruned Step Sampling (#1077)"
    },
    {
      "sha": "6fbe7592f5a74e120aa5a56fe9af91b81b53eaec",
      "author": "SWivid",
      "date": "2025-06-04T03:22:31+00:00",
      "message": "rebase default sample_rate to 24khz for runtime"
    },
    {
      "sha": "7e37bc5d9a69e65a1a8b1f3a0b432ebac100a2a5",
      "author": "Alice Yanagi",
      "date": "2025-06-04T03:18:00+00:00",
      "message": "Fix the duration computation in `triton_trtllm/client_grpc.py` (#1071)"
    },
    {
      "sha": "35f130ee85ff7b86283f5ba1e7d80fef6722c598",
      "author": "SWivid",
      "date": "2025-06-03T22:11:49+00:00",
      "message": "minor update for infer-gradio"
    },
    {
      "sha": "e6469f705feb85039817ceef7d2091e4d6be6121",
      "author": "SWivid",
      "date": "2025-06-03T14:09:13+00:00",
      "message": "update shared.md"
    },
    {
      "sha": "31cd81809578c60c17f14906cee2b2d00159e185",
      "author": "SWivid",
      "date": "2025-06-03T13:23:47+00:00",
      "message": "formatting"
    },
    {
      "sha": "1d13664b24f12b957d8b9f2e453a159a6895164b",
      "author": "Yushen CHEN",
      "date": "2025-06-03T13:18:41+00:00",
      "message": "Merge pull request #1063 from ionite34/dev"
    },
    {
      "sha": "b27471ea064d1259be4cca23dec8897d9c332bb9",
      "author": "Yushen CHEN",
      "date": "2025-06-03T13:18:25+00:00",
      "message": "Merge pull request #1072 from hvoss-techfak/main"
    },
    {
      "sha": "8fb55f107e9aa710bd9594eb94ef93f08eaf2088",
      "author": "Hendric Voss",
      "date": "2025-06-03T12:08:30+00:00",
      "message": "Update SHARED.md"
    },
    {
      "sha": "ccb380b7528d57289e0b868fc0a3ec2571e31e73",
      "author": "Hendric Voss",
      "date": "2025-06-03T12:08:03+00:00",
      "message": "Added German Model"
    },
    {
      "sha": "3027b439534b4efcad1bc7bbf963b5eb2cd7a3fd",
      "author": "Ionite",
      "date": "2025-05-28T19:24:35+00:00",
      "message": "Fix training with file path spaces"
    },
    {
      "sha": "ecd1c3949a4f5d1a19d8b73eec45002dbffe44fb",
      "author": "SWivid",
      "date": "2025-05-22T15:10:29+00:00",
      "message": "Add py312 check for tempfile delete_on_close keyword"
    }
  ],
  "readme_text": "# F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching\n\n[![python](https://img.shields.io/badge/Python-3.10-brightgreen)](https://github.com/SWivid/F5-TTS)\n[![arXiv](https://img.shields.io/badge/arXiv-2410.06885-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2410.06885)\n[![demo](https://img.shields.io/badge/GitHub-Demo%20page-orange.svg)](https://swivid.github.io/F5-TTS/)\n[![hfspace](https://img.shields.io/badge/\ud83e\udd17-Space%20demo-yellow)](https://huggingface.co/spaces/mrfakename/E2-F5-TTS)\n[![msspace](https://img.shields.io/badge/\ud83e\udd16-Space%20demo-blue)](https://modelscope.cn/studios/modelscope/E2-F5-TTS)\n[![lab](https://img.shields.io/badge/X--LANCE-Lab-grey?labelColor=lightgrey)](https://x-lance.sjtu.edu.cn/)\n[![lab](https://img.shields.io/badge/Peng%20Cheng-Lab-grey?labelColor=lightgrey)](https://www.pcl.ac.cn)\n<!-- <img src=\"https://github.com/user-attachments/assets/12d7749c-071a-427c-81bf-b87b91def670\" alt=\"Watermark\" style=\"width: 40px; height: auto\"> -->\n\n**F5-TTS**: Diffusion Transformer with ConvNeXt V2, faster trained and inference.\n\n**E2 TTS**: Flat-UNet Transformer, closest reproduction from [paper](https://arxiv.org/abs/2406.18009).\n\n**Sway Sampling**: Inference-time flow step sampling strategy, greatly improves performance\n\n### Thanks to all the contributors !\n\n## News\n- **2025/03/12**: \ud83d\udd25 F5-TTS v1 base model with better training and inference performance. [Few demo](https://swivid.github.io/F5-TTS_updates).\n- **2024/10/08**: F5-TTS & E2 TTS base models on [\ud83e\udd17 Hugging Face](https://huggingface.co/SWivid/F5-TTS), [\ud83e\udd16 Model Scope](https://www.modelscope.cn/models/SWivid/F5-TTS_Emilia-ZH-EN), [\ud83d\udfe3 Wisemodel](https://wisemodel.cn/models/SJTU_X-LANCE/F5-TTS_Emilia-ZH-EN).\n\n## Installation\n\n### Create a separate environment if needed\n\n```bash\n# Create a python 3.10 conda env (you could also use virtualenv)\nconda create -n f5-tts python=3.10\nconda activate f5-tts\n```\n\n### Install PyTorch with matched device\n\n<details>\n<summary>NVIDIA GPU</summary>\n\n> ```bash\n> # Install pytorch with your CUDA version, e.g.\n> pip install torch==2.4.0+cu124 torchaudio==2.4.0+cu124 --extra-index-url https://download.pytorch.org/whl/cu124\n> ```\n\n</details>\n\n<details>\n<summary>AMD GPU</summary>\n\n> ```bash\n> # Install pytorch with your ROCm version (Linux only), e.g.\n> pip install torch==2.5.1+rocm6.2 torchaudio==2.5.1+rocm6.2 --extra-index-url https://download.pytorch.org/whl/rocm6.2\n> ```\n\n</details>\n\n<details>\n<summary>Intel GPU</summary>\n\n> ```bash\n> # Install pytorch with your XPU version, e.g.\n> # Intel\u00ae Deep Learning Essentials or Intel\u00ae oneAPI Base Toolkit must be installed\n> pip install torch torchaudio --index-url https://download.pytorch.org/whl/test/xpu\n> \n> # Intel GPU support is also available through IPEX (Intel\u00ae Extension for PyTorch)\n> # IPEX does not require the Intel\u00ae Deep Learning Essentials or Intel\u00ae oneAPI Base Toolkit\n> # See: https://pytorch-extension.intel.com/installation?request=platform\n> ```\n\n</details>\n\n<details>\n<summary>Apple Silicon</summary>\n\n> ```bash\n> # Install the stable pytorch, e.g.\n> pip install torch torchaudio\n> ```\n\n</details>\n\n### Then you can choose one from below:\n\n> ### 1. As a pip package (if just for inference)\n> \n> ```bash\n> pip install f5-tts\n> ```\n> \n> ### 2. Local editable (if also do training, finetuning)\n> \n> ```bash\n> git clone https://github.com/SWivid/F5-TTS.git\n> cd F5-TTS\n> # git submodule update --init --recursive  # (optional, if use bigvgan as vocoder)\n> pip install -e .\n> ```\n\n### Docker usage also available\n```bash\n# Build from Dockerfile\ndocker build -t f5tts:v1 .\n\n# Run from GitHub Container Registry\ndocker container run --rm -it --gpus=all --mount 'type=volume,source=f5-tts,target=/root/.cache/huggingface/hub/' -p 7860:7860 ghcr.io/swivid/f5-tts:main\n\n# Quickstart if you want to just run the web interface (not CLI)\ndocker container run --rm -it --gpus=all --mount 'type=volume,source=f5-tts,target=/root/.cache/huggingface/hub/' -p 7860:7860 ghcr.io/swivid/f5-tts:main f5-tts_infer-gradio --host 0.0.0.0\n```\n\n### Runtime\n\nDeployment solution with Triton and TensorRT-LLM.\n\n#### Benchmark Results\nDecoding on a single L20 GPU, using 26 different prompt_audio & target_text pairs, 16 NFE.\n\n| Model               | Concurrency    | Avg Latency | RTF    | Mode            |\n|---------------------|----------------|-------------|--------|-----------------|\n| F5-TTS Base (Vocos) | 2              | 253 ms      | 0.0394 | Client-Server   |\n| F5-TTS Base (Vocos) | 1 (Batch_size) | -           | 0.0402 | Offline TRT-LLM |\n| F5-TTS Base (Vocos) | 1 (Batch_size) | -           | 0.1467 | Offline Pytorch |\n\nSee [detailed instructions](src/f5_tts/runtime/triton_trtllm/README.md) for more information.\n\n\n## Inference\n\n- In order to achieve desired performance, take a moment to read [detailed guidance](src/f5_tts/infer).\n- By properly searching the keywords of problem encountered, [issues](https://github.com/SWivid/F5-TTS/issues?q=is%3Aissue) are very helpful.\n\n### 1. Gradio App\n\nCurrently supported features:\n\n- Basic TTS with Chunk Inference\n- Multi-Style / Multi-Speaker Generation\n- Voice Chat powered by Qwen2.5-3B-Instruct\n- [Custom inference with more language support](src/f5_tts/infer/SHARED.md)\n\n```bash\n# Launch a Gradio app (web interface)\nf5-tts_infer-gradio\n\n# Specify the port/host\nf5-tts_infer-gradio --port 7860 --host 0.0.0.0\n\n# Launch a share link\nf5-tts_infer-gradio --share\n```\n\n<details>\n<summary>NVIDIA device docker compose file example</summary>\n\n```yaml\nservices:\n  f5-tts:\n    image: ghcr.io/swivid/f5-tts:main\n    ports:\n      - \"7860:7860\"\n    environment:\n      GRADIO_SERVER_PORT: 7860\n    entrypoint: [\"f5-tts_infer-gradio\", \"--port\", \"7860\", \"--host\", \"0.0.0.0\"]\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: 1\n              capabilities: [gpu]\n\nvolumes:\n  f5-tts:\n    driver: local\n```\n\n</details>\n\n### 2. CLI Inference\n\n```bash\n# Run with flags\n# Leave --ref_text \"\" will have ASR model transcribe (extra GPU memory usage)\nf5-tts_infer-cli --model F5TTS_v1_Base \\\n--ref_audio \"provide_prompt_wav_path_here.wav\" \\\n--ref_text \"The content, subtitle or transcription of reference audio.\" \\\n--gen_text \"Some text you want TTS model generate for you.\"\n\n# Run with default setting. src/f5_tts/infer/examples/basic/basic.toml\nf5-tts_infer-cli\n# Or with your own .toml file\nf5-tts_infer-cli -c custom.toml\n\n# Multi voice. See src/f5_tts/infer/README.md\nf5-tts_infer-cli -c src/f5_tts/infer/examples/multi/story.toml\n```\n\n\n## Training\n\n### 1. With Hugging Face Accelerate\n\nRefer to [training & finetuning guidance](src/f5_tts/train) for best practice.\n\n### 2. With Gradio App\n\n```bash\n# Quick start with Gradio web interface\nf5-tts_finetune-gradio\n```\n\nRead [training & finetuning guidance](src/f5_tts/train) for more instructions.\n\n\n## [Evaluation](src/f5_tts/eval)\n\n\n## Development\n\nUse pre-commit to ensure code quality (will run linters and formatters automatically):\n\n```bash\npip install pre-commit\npre-commit install\n```\n\nWhen making a pull request, before each commit, run: \n\n```bash\npre-commit run --all-files\n```\n\nNote: Some model components have linting exceptions for E722 to accommodate tensor notation.\n\n\n## Acknowledgements\n\n- [E2-TTS](https://arxiv.org/abs/2406.18009) brilliant work, simple and effective\n- [Emilia](https://arxiv.org/abs/2407.05361), [WenetSpeech4TTS](https://arxiv.org/abs/2406.05763), [LibriTTS](https://arxiv.org/abs/1904.02882), [LJSpeech](https://keithito.com/LJ-Speech-Dataset/) valuable datasets\n- [lucidrains](https://github.com/lucidrains) initial CFM structure with also [bfs18](https://github.com/bfs18) for discussion\n- [SD3](https://arxiv.org/abs/2403.03206) & [Hugging Face diffusers](https://github.com/huggingface/diffusers) DiT and MMDiT code structure\n- [torchdiffeq](https://github.com/rtqichen/torchdiffeq) as ODE solver, [Vocos](https://huggingface.co/charactr/vocos-mel-24khz) and [BigVGAN](https://github.com/NVIDIA/BigVGAN) as vocoder\n- [FunASR](https://github.com/modelscope/FunASR), [faster-whisper](https://github.com/SYSTRAN/faster-whisper), [UniSpeech](https://github.com/microsoft/UniSpeech), [SpeechMOS](https://github.com/tarepan/SpeechMOS) for evaluation tools\n- [ctc-forced-aligner](https://github.com/MahmoudAshraf97/ctc-forced-aligner) for speech edit test\n- [mrfakename](https://x.com/realmrfakename) huggingface space demo ~\n- [f5-tts-mlx](https://github.com/lucasnewman/f5-tts-mlx/tree/main) Implementation with MLX framework by [Lucas Newman](https://github.com/lucasnewman)\n- [F5-TTS-ONNX](https://github.com/DakeQQ/F5-TTS-ONNX) ONNX Runtime version by [DakeQQ](https://github.com/DakeQQ)\n- [Yuekai Zhang](https://github.com/yuekaizhang) Triton and TensorRT-LLM support ~\n\n## Citation\nIf our work and codebase is useful for you, please cite as:\n```\n@article{chen-etal-2024-f5tts,\n      title={F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching}, \n      author={Yushen Chen and Zhikang Niu and Ziyang Ma and Keqi Deng and Chunhui Wang and Jian Zhao and Kai Yu and Xie Chen},\n      journal={arXiv preprint arXiv:2410.06885},\n      year={2024},\n}\n```\n## License\n\nOur code is released under MIT License. The pre-trained models are licensed under the CC-BY-NC license due to the training data Emilia, which is an in-the-wild dataset. Sorry for any inconvenience this may cause.\n",
  "external_links_in_readme": [
    "https://download.pytorch.org/whl/rocm6.2",
    "https://github.com/lucidrains",
    "https://github.com/SWivid/F5-TTS/issues?q=is%3Aissue",
    "https://github.com/bfs18",
    "https://img.shields.io/badge/arXiv-2410.06885-b31b1b.svg?logo=arXiv",
    "https://pytorch-extension.intel.com/installation?request=platform",
    "https://arxiv.org/abs/2406.18009",
    "https://www.modelscope.cn/models/SWivid/F5-TTS_Emilia-ZH-EN",
    "https://github.com/tarepan/SpeechMOS",
    "https://github.com/NVIDIA/BigVGAN",
    "https://img.shields.io/badge/\ud83e\udd16-Space%20demo-blue",
    "https://github.com/user-attachments/assets/12d7749c-071a-427c-81bf-b87b91def670\"",
    "https://github.com/MahmoudAshraf97/ctc-forced-aligner",
    "https://huggingface.co/charactr/vocos-mel-24khz",
    "https://github.com/DakeQQ",
    "https://img.shields.io/badge/\ud83e\udd17-Space%20demo-yellow",
    "https://x-lance.sjtu.edu.cn/",
    "https://modelscope.cn/studios/modelscope/E2-F5-TTS",
    "https://swivid.github.io/F5-TTS_updates",
    "https://huggingface.co/SWivid/F5-TTS",
    "https://wisemodel.cn/models/SJTU_X-LANCE/F5-TTS_Emilia-ZH-EN",
    "https://github.com/SWivid/F5-TTS",
    "https://arxiv.org/abs/1904.02882",
    "https://arxiv.org/abs/2403.03206",
    "https://swivid.github.io/F5-TTS/",
    "https://github.com/lucasnewman",
    "https://github.com/yuekaizhang",
    "https://img.shields.io/badge/GitHub-Demo%20page-orange.svg",
    "https://arxiv.org/abs/2407.05361",
    "https://www.pcl.ac.cn",
    "https://arxiv.org/abs/2406.05763",
    "https://img.shields.io/badge/X--LANCE-Lab-grey?labelColor=lightgrey",
    "https://github.com/huggingface/diffusers",
    "https://github.com/rtqichen/torchdiffeq",
    "https://github.com/modelscope/FunASR",
    "https://github.com/SYSTRAN/faster-whisper",
    "https://huggingface.co/spaces/mrfakename/E2-F5-TTS",
    "https://download.pytorch.org/whl/cu124",
    "https://github.com/microsoft/UniSpeech",
    "https://github.com/SWivid/F5-TTS.git",
    "https://arxiv.org/abs/2410.06885",
    "https://github.com/DakeQQ/F5-TTS-ONNX",
    "https://img.shields.io/badge/Peng%20Cheng-Lab-grey?labelColor=lightgrey",
    "https://x.com/realmrfakename",
    "https://download.pytorch.org/whl/test/xpu",
    "https://keithito.com/LJ-Speech-Dataset/",
    "https://github.com/lucasnewman/f5-tts-mlx/tree/main",
    "https://img.shields.io/badge/Python-3.10-brightgreen"
  ]
}
```

</details>


---

