# GitHub Data for pyannote_speaker-diarization-3.1

**Task Category:** Audio Classification

## Repository 1: joonson/voxconverse

# GitHub Repository Data

**Repository:** [joonson/voxconverse](https://github.com/joonson/voxconverse)

## Basic Information

- **Description:** Spot the conversation: speaker diarisation in the wild
- **Created:** 2020-07-14T09:48:57+00:00
- **Last Updated:** 2025-06-20T02:09:24+00:00
- **Last Pushed:** 2022-07-26T18:48:44+00:00
- **Default Branch:** master
- **Size:** 312 KB

## Statistics

- **Stars:** 141
- **Forks:** 15
- **Watchers:** 141
- **Open Issues:** 1
- **Total Issues:** 0
- **Pull Requests:** 1

## License

- **Type:** No license specified

## Top Contributors

1. **JaesungHuh** - 6 contributions
2. **joonson** - 2 contributions

## File Structure (Sample of 10 files)

Total files: 452

- `.gitignore` (blob)
- `README.md` (blob)
- `dev` (tree)
- `dev/abjxc.rttm` (blob)
- `dev/afjiv.rttm` (blob)
- `dev/ahnss.rttm` (blob)
- `dev/aisvi.rttm` (blob)
- `dev/akthc.rttm` (blob)
- `dev/ampme.rttm` (blob)
- `dev/asxwr.rttm` (blob)

## Recent Issues

- ðŸ”´ **#10** commands for adding duration.csv file of audios (closed)
- ðŸ”´ **#9** Different folder for Version 0.2 and 0.3 (closed)
- ðŸ”´ **#8** About the video files (closed)
- ðŸŸ¢ **#7** labels for the test set (open)
- ðŸ”´ **#6** Can you share the video data? (closed)

## Recent Pull Requests

- ðŸ”´ **#10** commands for adding duration.csv file of audios (closed)

## Recent Commits

- **24bf60be** fix readme - Jaesung Huh (2022-07-25T16:46:39+00:00)
- **55a094ad** fix readme - Jaesung Huh (2022-07-25T16:45:13+00:00)
- **2862ac10** change the version name from 0.0.3 to 0.3 - JaesungHuh (2022-07-21T00:05:28+00:00)
- **d7653be9** ver 0.0.3 - Jaesung Huh (2022-07-20T23:59:47+00:00)
- **48312391** ver 0.3.0 - Jaesung Huh (2022-07-20T23:56:32+00:00)
- **b22c62da** fix readme - jaesung-huh (2021-07-21T13:36:17+00:00)
- **7d86afef** fix readme - jaesung-huh (2021-07-21T13:33:47+00:00)
- **065f911d** v0.0.2 - jaesung-huh (2021-07-21T13:31:43+00:00)
- **908a5472** v0.0.2 - jaesung-huh (2021-07-21T13:31:01+00:00)
- **60560f51** delette test file - jaesung-huh (2021-07-21T13:30:25+00:00)

## External Links Found in README

- https://www.robots.ox.ac.uk/~vgg/data/voxconverse/data/voxconverse_dev_wav.zip
- http://www.robots.ox.ac.uk/~vgg/data/voxconverse/index.html
- https://creativecommons.org/licenses/by/4.0
- https://www.robots.ox.ac.uk/~vgg/data/voxconverse/data/voxconverse_test_wav.zip

## Raw Data

<details>
<summary>Click to expand raw JSON data</summary>

```json
{
  "id": 279545997,
  "name": "voxconverse",
  "full_name": "joonson/voxconverse",
  "description": "Spot the conversation: speaker diarisation in the wild",
  "html_url": "https://github.com/joonson/voxconverse",
  "clone_url": "https://github.com/joonson/voxconverse.git",
  "ssh_url": "git@github.com:joonson/voxconverse.git",
  "homepage": "",
  "topics": [],
  "default_branch": "master",
  "created_at": "2020-07-14T09:48:57+00:00",
  "updated_at": "2025-06-20T02:09:24+00:00",
  "pushed_at": "2022-07-26T18:48:44+00:00",
  "size_kb": 312,
  "watchers_count": 141,
  "stargazers_count": 141,
  "forks_count": 15,
  "open_issues_count": 1,
  "license": null,
  "languages": {},
  "top_contributors": [
    {
      "login": "JaesungHuh",
      "contributions": 6
    },
    {
      "login": "joonson",
      "contributions": 2
    }
  ],
  "file_tree_count": 452,
  "file_tree_sample": [
    {
      "path": ".gitignore",
      "type": "blob"
    },
    {
      "path": "README.md",
      "type": "blob"
    },
    {
      "path": "dev",
      "type": "tree"
    },
    {
      "path": "dev/abjxc.rttm",
      "type": "blob"
    },
    {
      "path": "dev/afjiv.rttm",
      "type": "blob"
    },
    {
      "path": "dev/ahnss.rttm",
      "type": "blob"
    },
    {
      "path": "dev/aisvi.rttm",
      "type": "blob"
    },
    {
      "path": "dev/akthc.rttm",
      "type": "blob"
    },
    {
      "path": "dev/ampme.rttm",
      "type": "blob"
    },
    {
      "path": "dev/asxwr.rttm",
      "type": "blob"
    }
  ],
  "issues_count": 0,
  "pulls_count": 1,
  "recent_issues": [
    {
      "number": 10,
      "title": "commands for adding duration.csv file of audios",
      "state": "closed"
    },
    {
      "number": 9,
      "title": "Different folder for Version 0.2 and 0.3",
      "state": "closed"
    },
    {
      "number": 8,
      "title": "About the video files",
      "state": "closed"
    },
    {
      "number": 7,
      "title": "labels for the test set",
      "state": "open"
    },
    {
      "number": 6,
      "title": "Can you share the video data?",
      "state": "closed"
    }
  ],
  "recent_pulls": [
    {
      "number": 10,
      "title": "commands for adding duration.csv file of audios",
      "state": "closed"
    }
  ],
  "recent_commits": [
    {
      "sha": "24bf60be297701cd7e4ef18550c6d390c1b87365",
      "author": "Jaesung Huh",
      "date": "2022-07-25T16:46:39+00:00",
      "message": "fix readme"
    },
    {
      "sha": "55a094adbe3304adacd3ae5e5c8aa121160a9e54",
      "author": "Jaesung Huh",
      "date": "2022-07-25T16:45:13+00:00",
      "message": "fix readme"
    },
    {
      "sha": "2862ac103f184c1b72a943948e34e75bea3a5acc",
      "author": "JaesungHuh",
      "date": "2022-07-21T00:05:28+00:00",
      "message": "change the version name from 0.0.3 to 0.3"
    },
    {
      "sha": "d7653be994089b6f6b2478bf90e50328d3ab5fd0",
      "author": "Jaesung Huh",
      "date": "2022-07-20T23:59:47+00:00",
      "message": "ver 0.0.3"
    },
    {
      "sha": "48312391280c284a82a616899892b2efa948eadb",
      "author": "Jaesung Huh",
      "date": "2022-07-20T23:56:32+00:00",
      "message": "ver 0.3.0"
    },
    {
      "sha": "b22c62daca9ff7bebacede724254a9562b0626db",
      "author": "jaesung-huh",
      "date": "2021-07-21T13:36:17+00:00",
      "message": "fix readme"
    },
    {
      "sha": "7d86afef94bf5b87da076932c51efe2aceadd4f2",
      "author": "jaesung-huh",
      "date": "2021-07-21T13:33:47+00:00",
      "message": "fix readme"
    },
    {
      "sha": "065f911d0818d5170ed974bfc138a25189b3ee05",
      "author": "jaesung-huh",
      "date": "2021-07-21T13:31:43+00:00",
      "message": "v0.0.2"
    },
    {
      "sha": "908a5472b3b7da49a149dfd0746228a26c09ce06",
      "author": "jaesung-huh",
      "date": "2021-07-21T13:31:01+00:00",
      "message": "v0.0.2"
    },
    {
      "sha": "60560f51debbeccb7f2dca9b7d40c028dd456c0c",
      "author": "jaesung-huh",
      "date": "2021-07-21T13:30:25+00:00",
      "message": "delette test file"
    },
    {
      "sha": "c27d208a3dfb250a86ede9040bfb1150de8259db",
      "author": "jaesung-huh",
      "date": "2021-07-21T13:28:33+00:00",
      "message": "v0.0.2"
    },
    {
      "sha": "9a8756d276210b546d224245a6a6220a26d30fe4",
      "author": "JaesungHuh",
      "date": "2021-07-21T13:26:14+00:00",
      "message": "Delete .DS_Store"
    },
    {
      "sha": "213bb909038a89c1bf51f6e6a00400720c5bc5d9",
      "author": "jaesung-huh",
      "date": "2021-07-21T13:25:29+00:00",
      "message": "aa"
    },
    {
      "sha": "d9eaaec41e0ede7c0af2d3331ede27cfc91f01e2",
      "author": "joonson",
      "date": "2020-07-15T15:47:39+00:00",
      "message": "v0.0.1"
    },
    {
      "sha": "4b940a53df418b0fea0787ba8ff4c2eeede4b1d0",
      "author": "joonson",
      "date": "2020-07-14T10:16:20+00:00",
      "message": "v0.0.1"
    }
  ],
  "readme_text": "## VoxConverse speaker diarisation dataset\n\nVoxConverse is an audio-visual diarisation dataset consisting of multispeaker clips of human speech, extracted from YouTube videos.\nUpdates and additional information about the dataset can be found at our [website](http://www.robots.ox.ac.uk/~vgg/data/voxconverse/index.html).\n\n\n### Version 0.3\nWe have recently detected an error in some of our test rttm files. They are fixed in this master branch. Please use the 0.3 version for more accurate labels.\n\n### Version 0.2\nIf you want to see the previous version, please go to the ver0.2 branch in this repository.\n\n#### Audio files\n\nDev set audio files can be downloaded from [here](https://www.robots.ox.ac.uk/~vgg/data/voxconverse/data/voxconverse_dev_wav.zip). \nTest set audio files can be downloaded from [here](https://www.robots.ox.ac.uk/~vgg/data/voxconverse/data/voxconverse_test_wav.zip)\n\n#### Speaker Diarisation annotations \n\nAnnotations are provided as Rich Transcription Time Marked (RTTM) files and can be found in the ```dev```  and ```test``` folder. \n\n#### Citation\n\nPlease cite the following if you make use of the dataset.\n\n```\n@article{chung2020spot,\n  title={Spot the conversation: speaker diarisation in the wild},\n  author={Chung, Joon Son and Huh, Jaesung and Nagrani, Arsha and Afouras, Triantafyllos and Zisserman, Andrew},\n  booktitle={Interspeech},\n  year={2020}\n}\n```\n\n#### License\n\nThe VoxConverse dataset is available to download for research purposes under a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0). The copyright remains with the original owners of the video. \n\nIn order to obtain videos with a large amount of overlapping speech, we used data consisting of political debates and news segments. The views and opinions expressed by speakers in the dataset are those of the individual speakers and do not necessarily reflect positions of the University of Oxford, Naver Corporation, or the authors of the paper.\n\nWe would also like to note that the distribution of identities in this dataset may not be representative the global human population. Please be careful of unintended societal, gender, racial, linguistic and other biases when training or deploying models trained on this data.\n\n",
  "external_links_in_readme": [
    "https://www.robots.ox.ac.uk/~vgg/data/voxconverse/data/voxconverse_dev_wav.zip",
    "http://www.robots.ox.ac.uk/~vgg/data/voxconverse/index.html",
    "https://creativecommons.org/licenses/by/4.0",
    "https://www.robots.ox.ac.uk/~vgg/data/voxconverse/data/voxconverse_test_wav.zip"
  ]
}
```

</details>


---

## Repository 2: BUTSpeechFIT/AMI-diarization-setup

# GitHub Repository Data

**Repository:** [BUTSpeechFIT/AMI-diarization-setup](https://github.com/BUTSpeechFIT/AMI-diarization-setup)

## Basic Information

- **Description:** None
- **Created:** 2020-12-23T16:56:59+00:00
- **Last Updated:** 2025-06-18T08:51:21+00:00
- **Last Pushed:** 2023-10-17T15:48:04+00:00
- **Default Branch:** main
- **Size:** 2295 KB

## Statistics

- **Stars:** 54
- **Forks:** 27
- **Watchers:** 54
- **Open Issues:** 0
- **Total Issues:** 1
- **Pull Requests:** 1

## License

- **Type:** Apache License 2.0
- **SPDX ID:** Apache-2.0
- **URL:** [License](https://github.com/BUTSpeechFIT/AMI-diarization-setup/blob/main/LICENSE)

## Top Contributors

1. **fnlandini** - 8 contributions

## File Structure (Sample of 10 files)

Total files: 884

- `LICENSE` (blob)
- `README.md` (blob)
- `lists` (tree)
- `lists/dev.meetings.txt` (blob)
- `lists/dev.speakers.txt` (blob)
- `lists/test.meetings.txt` (blob)
- `lists/test.speakers.txt` (blob)
- `lists/train.meetings.txt` (blob)
- `lists/train.speakers.txt` (blob)
- `only_words` (tree)

## Recent Issues

- ðŸ”´ **#1** feat: add pyannote.database configuration file (closed)

## Recent Pull Requests

- ðŸ”´ **#1** feat: add pyannote.database configuration file (closed)

## Recent Commits

- **2509d893** Merge branch 'main' of https://github.com/BUTSpeechFIT/AMI-diarization-setup - Federico Landini (2023-10-17T15:47:44+00:00)
- **5a7aecaa** Add single rttm files for the three sets - Federico Landini (2023-10-17T15:46:57+00:00)
- **c8ddbcc5** Update README.md - fnlandini (2022-11-14T11:46:45+00:00)
- **b158cbec** Update readme with pointers to scoring examples - Federico Landini (2021-01-26T09:55:40+00:00)
- **4906e91d** Add uem files that consider the whole length of recordings - Federico Landini (2021-01-15T13:27:16+00:00)
- **c75450ac** Add link to paper in README - Federico Landini (2021-01-01T15:08:46+00:00)
- **126863e1** Add lists and lab and rttm files - Federico Landini (2020-12-23T17:26:52+00:00)
- **7003baa7** Initial commit - fnlandini (2020-12-23T16:57:00+00:00)

## External Links Found in README

- http://groups.inf.ed.ac.uk/ami/corpus/datasets.shtml
- https://github.com/pyannote
- https://github.com/pyannote/AMI-diarization-setup
- http://groups.inf.ed.ac.uk/ami/download/
- https://www.sciencedirect.com/science/article/pii/S0885230821000619
- https://github.com/kaldi-asr/kaldi/blob/d136b18346bee14166b950029405314401fc4a8b/egs/ami/s5c/run.sh#L138
- https://github.com/BUTSpeechFIT/VBx/blob/35e7954ac0042ea445dcec657130e2c3c0b94ee0/AMI_run.sh#L64

## Raw Data

<details>
<summary>Click to expand raw JSON data</summary>

```json
{
  "id": 323956724,
  "name": "AMI-diarization-setup",
  "full_name": "BUTSpeechFIT/AMI-diarization-setup",
  "description": null,
  "html_url": "https://github.com/BUTSpeechFIT/AMI-diarization-setup",
  "clone_url": "https://github.com/BUTSpeechFIT/AMI-diarization-setup.git",
  "ssh_url": "git@github.com:BUTSpeechFIT/AMI-diarization-setup.git",
  "homepage": null,
  "topics": [],
  "default_branch": "main",
  "created_at": "2020-12-23T16:56:59+00:00",
  "updated_at": "2025-06-18T08:51:21+00:00",
  "pushed_at": "2023-10-17T15:48:04+00:00",
  "size_kb": 2295,
  "watchers_count": 54,
  "stargazers_count": 54,
  "forks_count": 27,
  "open_issues_count": 0,
  "license": {
    "key": "apache-2.0",
    "name": "Apache License 2.0",
    "spdx_id": "Apache-2.0",
    "url": "https://github.com/BUTSpeechFIT/AMI-diarization-setup/blob/main/LICENSE"
  },
  "languages": {},
  "top_contributors": [
    {
      "login": "fnlandini",
      "contributions": 8
    }
  ],
  "file_tree_count": 884,
  "file_tree_sample": [
    {
      "path": "LICENSE",
      "type": "blob"
    },
    {
      "path": "README.md",
      "type": "blob"
    },
    {
      "path": "lists",
      "type": "tree"
    },
    {
      "path": "lists/dev.meetings.txt",
      "type": "blob"
    },
    {
      "path": "lists/dev.speakers.txt",
      "type": "blob"
    },
    {
      "path": "lists/test.meetings.txt",
      "type": "blob"
    },
    {
      "path": "lists/test.speakers.txt",
      "type": "blob"
    },
    {
      "path": "lists/train.meetings.txt",
      "type": "blob"
    },
    {
      "path": "lists/train.speakers.txt",
      "type": "blob"
    },
    {
      "path": "only_words",
      "type": "tree"
    }
  ],
  "issues_count": 1,
  "pulls_count": 1,
  "recent_issues": [
    {
      "number": 1,
      "title": "feat: add pyannote.database configuration file",
      "state": "closed"
    }
  ],
  "recent_pulls": [
    {
      "number": 1,
      "title": "feat: add pyannote.database configuration file",
      "state": "closed"
    }
  ],
  "recent_commits": [
    {
      "sha": "2509d8933721023fab4def2618aabd5c28eb82e9",
      "author": "Federico Landini",
      "date": "2023-10-17T15:47:44+00:00",
      "message": "Merge branch 'main' of https://github.com/BUTSpeechFIT/AMI-diarization-setup"
    },
    {
      "sha": "5a7aecaa36627646808cae31151d6b5e55827f7e",
      "author": "Federico Landini",
      "date": "2023-10-17T15:46:57+00:00",
      "message": "Add single rttm files for the three sets"
    },
    {
      "sha": "c8ddbcc50d0e0af29b47414d84e7b3b1eb10faca",
      "author": "fnlandini",
      "date": "2022-11-14T11:46:45+00:00",
      "message": "Update README.md"
    },
    {
      "sha": "b158cbecae7c91298346c6bec1d6dcad473f61d3",
      "author": "Federico Landini",
      "date": "2021-01-26T09:55:40+00:00",
      "message": "Update readme with pointers to scoring examples"
    },
    {
      "sha": "4906e91db2c942909732ef740c7ee9705602b7a4",
      "author": "Federico Landini",
      "date": "2021-01-15T13:27:16+00:00",
      "message": "Add uem files that consider the whole length of recordings"
    },
    {
      "sha": "c75450acb40948ecf44d902473a6aaca27eb0315",
      "author": "Federico Landini",
      "date": "2021-01-01T15:08:46+00:00",
      "message": "Add link to paper in README"
    },
    {
      "sha": "126863e146ce533e339041a7f65c5c6a3cf83223",
      "author": "Federico Landini",
      "date": "2020-12-23T17:26:52+00:00",
      "message": "Add lists and lab and rttm files"
    },
    {
      "sha": "7003baa715244271360cbe75c629329f85202da4",
      "author": "fnlandini",
      "date": "2020-12-23T16:57:00+00:00",
      "message": "Initial commit"
    }
  ],
  "readme_text": "# AMI-diarization-setup\n\nDiarization setup for AMI corpus[1] based on [Full-corpus-ASR partition](http://groups.inf.ed.ac.uk/ami/corpus/datasets.shtml). The diarization references are directly derived from the manual annotations, [version 1.6.2](http://groups.inf.ed.ac.uk/ami/download/). To generate the references:\n- All words are considered as speech and included in the references. \n- Speaker turns respect precisely the annotations, but adjacent speech segments (words) of the same speaker are merged not to create false break points. Consecutive speech segments from the same speaker separated by pauses (silence) are not merged in any case.\nSome researchers might find useful a version of diarization references that not only includes words but also vocal sounds as marked in the manual annotations and for this reason we also share such set of references. However, there are inconsistencies in what annotators marked as vocal sounds and we prefer the setup containing only words.\n\nThe uem files consider the whole lengths of the recordings.\n\n[1] J. Carletta, S. Ashby, S. Bourban, M. Flynn, M. Guillemot, T. Hain, J. Kadlec, V. Karaiskos, W. Kraaij, M. Kronenthal, et al., The AMI meeting corpus: A pre-announcement, in: International workshop on machine learning for multimodal interaction, Springer, 2006, pp. 28\u201339.\n\n\n### Scoring\nFor the sake of keeping this repository as simple as possible, we do not include scoring scripts. However, you can refer to the following links for examples on how to score using this setup [with dscore](https://github.com/BUTSpeechFIT/VBx/blob/35e7954ac0042ea445dcec657130e2c3c0b94ee0/AMI_run.sh#L64) or [with md-eval](https://github.com/kaldi-asr/kaldi/blob/d136b18346bee14166b950029405314401fc4a8b/egs/ami/s5c/run.sh#L138).\nIn order to use this setup directly with [pyannote](https://github.com/pyannote), refer to [this fork](https://github.com/pyannote/AMI-diarization-setup).\n\n\n### Citations\nIn case of using the setup, please cite:\\\nF. Landini, J. Profant, M. Diez, L. Burget: [Bayesian HMM clustering of x-vector sequences (VBx) in speaker diarization: theory, implementation and analysis on standard tasks](https://www.sciencedirect.com/science/article/pii/S0885230821000619)\n\n\n## Contact\nIf you have any comment or question, please contact landini@fit.vutbr.cz or mireia@fit.vutbr.cz\n",
  "external_links_in_readme": [
    "http://groups.inf.ed.ac.uk/ami/corpus/datasets.shtml",
    "https://github.com/pyannote",
    "https://github.com/pyannote/AMI-diarization-setup",
    "http://groups.inf.ed.ac.uk/ami/download/",
    "https://www.sciencedirect.com/science/article/pii/S0885230821000619",
    "https://github.com/kaldi-asr/kaldi/blob/d136b18346bee14166b950029405314401fc4a8b/egs/ami/s5c/run.sh#L138",
    "https://github.com/BUTSpeechFIT/VBx/blob/35e7954ac0042ea445dcec657130e2c3c0b94ee0/AMI_run.sh#L64"
  ]
}
```

</details>


---

## Repository 3: pyannote/pyannote-audio

# GitHub Repository Data

**Repository:** [pyannote/pyannote-audio](https://github.com/pyannote/pyannote-audio)

## Basic Information

- **Description:** Neural building blocks for speaker diarization: speech activity detection, speaker change detection, overlapped speech detection, speaker embedding 
- **Created:** 2016-03-07T17:26:15+00:00
- **Last Updated:** 2025-06-21T19:32:29+00:00
- **Last Pushed:** 2025-06-18T16:16:10+00:00
- **Default Branch:** main
- **Size:** 264175 KB

## Statistics

- **Stars:** 7,742
- **Forks:** 891
- **Watchers:** 7,742
- **Open Issues:** 37
- **Total Issues:** 0
- **Pull Requests:** 564

## License

- **Type:** MIT License
- **SPDX ID:** MIT
- **URL:** [License](https://github.com/pyannote/pyannote-audio/blob/main/LICENSE)

## Languages

- **Jupyter Notebook:** 1,482,887 bytes
- **Python:** 725,205 bytes

## Topics

- `pytorch`
- `speech-processing`
- `speaker-diarization`
- `speech-activity-detection`
- `speaker-change-detection`
- `speaker-embedding`
- `voice-activity-detection`
- `pretrained-models`
- `overlapped-speech-detection`
- `speaker-recognition`
- `speaker-verification`

## Top Contributors

1. **hbredin** - 2231 contributions
2. **mogwai** - 42 contributions
3. **FrenchKrab** - 17 contributions
4. **juanmc2005** - 11 contributions
5. **clement-pages** - 10 contributions
6. **pkorshunov** - 5 contributions
7. **yinruiqing** - 5 contributions
8. **wesbz** - 3 contributions
9. **flyingleafe** - 3 contributions
10. **kan-cloud** - 3 contributions

## File Structure (Sample of 10 files)

Total files: 274

- `.faq` (tree)
- `.faq/FAQ.md` (blob)
- `.faq/suggest.md` (blob)
- `.gitattributes` (blob)
- `.github` (tree)
- `.github/FUNDING.yml` (blob)
- `.github/ISSUE_TEMPLATE` (tree)
- `.github/ISSUE_TEMPLATE/bug_report.yml` (blob)
- `.github/ISSUE_TEMPLATE/config.yml` (blob)
- `.github/stale.yml` (blob)

## Recent Issues

- ðŸŸ¢ **#1886** Kernel Crash on Mac M4 when running training_a_model.ipynb with mps  (open)
- ðŸŸ¢ **#1885** einops error (open)
- ðŸ”´ **#1883** Allow to load a Calibration object from an in-memory dict directly (closed)
- ðŸ”´ **#1882** feat(cli): benchmark speaker count estimation (closed)
- ðŸŸ¢ **#1881** Notebook cannot be rendered on GitHub (open)

## Recent Pull Requests

- ðŸ”´ **#1883** Allow to load a Calibration object from an in-memory dict directly (closed)
- ðŸ”´ **#1882** feat(cli): benchmark speaker count estimation (closed)
- ðŸ”´ **#1880** feat(cli): add --metric option to "pyannote-audio optimize" (closed)
- ðŸ”´ **#1879** cli(benchmark): improve command (closed)
- ðŸ”´ **#1878** cli(benchmark):add a progress bar (closed)

## Recent Commits

- **240a7f3e** Merge branch 'release/3.3.2' - HervÃ© BREDIN (2024-09-11T11:06:31+00:00)
- **faf6126b** setup: bump version - HervÃ© BREDIN (2024-09-11T11:06:04+00:00)
- **b393e552** doc: update changelog - HervÃ© BREDIN (2024-09-11T11:05:50+00:00)
- **0ea4c025** doc: fix Pipeline docstring - huisman (2024-08-19T15:17:55+00:00)
- **286ea1a4** fix: fix support for `numpy==2.x` - Patrice Ferlet (2024-07-01T11:39:57+00:00)
- **2e04ec7f** Merge tag '3.3.1' into develop - HervÃ© BREDIN (2024-06-19T12:01:50+00:00)
- **4dd55a51** Merge branch 'release/3.3.1' - HervÃ© BREDIN (2024-06-19T12:01:37+00:00)
- **82f345a3** doc: update changelog and bump version - HervÃ© BREDIN (2024-06-19T12:01:24+00:00)
- **bd7b977c** fix: fix support for `speechbrain==1.0` (#1659) - Adel Moumen (2024-06-19T11:58:31+00:00)
- **1a5b870a** setup: drop support for Python 3.8 (#1728) - HervÃ© BREDIN (2024-06-19T11:03:24+00:00)

## External Links Found in README

- https://img.youtube.com/vi/37R_R82lfwA/0.jpg"></a>
- https://catalog.ldc.upenn.edu/LDC2022S14
- https://www.pyannote.ai
- https://github.com/revdotcom/speech-datasets
- https://hf.co/pyannote/speaker-diarization-2.1
- https://hf.co/pyannote/segmentation-3.0
- https://www.openslr.org/119/
- https://www.openslr.org/123/
- https://github.com/BUTSpeechFIT/CALLHOME_sublists/issues/1
- https://hf.co/pyannote/speaker-diarization-3.1
- https://hf.co/models?other=pyannote-audio-pipeline
- https://hf.co/settings/tokens
- https://huggingface.co/pyannote
- https://herve.niderb.fr/fastpages/2022/10/23/One-speaker-segmentation-model-to-rule-them-all
- https://arxiv.org/abs/2110.07058
- https://github.com/X-LANCE/MSDWILD
- https://catalog.ldc.upenn.edu/LDC2001S97
- https://github.com/joonson/voxconverse
- https://github.com/simonottenhauskenbun
- https://groups.inf.ed.ac.uk/ami/corpus/

## Raw Data

<details>
<summary>Click to expand raw JSON data</summary>

```json
{
  "id": 53344691,
  "name": "pyannote-audio",
  "full_name": "pyannote/pyannote-audio",
  "description": "Neural building blocks for speaker diarization: speech activity detection, speaker change detection, overlapped speech detection, speaker embedding ",
  "html_url": "https://github.com/pyannote/pyannote-audio",
  "clone_url": "https://github.com/pyannote/pyannote-audio.git",
  "ssh_url": "git@github.com:pyannote/pyannote-audio.git",
  "homepage": "http://pyannote.github.io",
  "topics": [
    "pytorch",
    "speech-processing",
    "speaker-diarization",
    "speech-activity-detection",
    "speaker-change-detection",
    "speaker-embedding",
    "voice-activity-detection",
    "pretrained-models",
    "overlapped-speech-detection",
    "speaker-recognition",
    "speaker-verification"
  ],
  "default_branch": "main",
  "created_at": "2016-03-07T17:26:15+00:00",
  "updated_at": "2025-06-21T19:32:29+00:00",
  "pushed_at": "2025-06-18T16:16:10+00:00",
  "size_kb": 264175,
  "watchers_count": 7742,
  "stargazers_count": 7742,
  "forks_count": 891,
  "open_issues_count": 37,
  "license": {
    "key": "mit",
    "name": "MIT License",
    "spdx_id": "MIT",
    "url": "https://github.com/pyannote/pyannote-audio/blob/main/LICENSE"
  },
  "languages": {
    "Jupyter Notebook": 1482887,
    "Python": 725205
  },
  "top_contributors": [
    {
      "login": "hbredin",
      "contributions": 2231
    },
    {
      "login": "mogwai",
      "contributions": 42
    },
    {
      "login": "FrenchKrab",
      "contributions": 17
    },
    {
      "login": "juanmc2005",
      "contributions": 11
    },
    {
      "login": "clement-pages",
      "contributions": 10
    },
    {
      "login": "pkorshunov",
      "contributions": 5
    },
    {
      "login": "yinruiqing",
      "contributions": 5
    },
    {
      "login": "wesbz",
      "contributions": 3
    },
    {
      "login": "flyingleafe",
      "contributions": 3
    },
    {
      "login": "kan-cloud",
      "contributions": 3
    },
    {
      "login": "clbarras",
      "contributions": 3
    },
    {
      "login": "MarvinLvn",
      "contributions": 3
    },
    {
      "login": "Mymoza",
      "contributions": 3
    },
    {
      "login": "J-Petiot",
      "contributions": 3
    },
    {
      "login": "martinjbaker",
      "contributions": 2
    },
    {
      "login": "hadware",
      "contributions": 2
    },
    {
      "login": "dependabot[bot]",
      "contributions": 2
    },
    {
      "login": "PaulLerner",
      "contributions": 2
    },
    {
      "login": "julien-c",
      "contributions": 2
    },
    {
      "login": "GregGovit",
      "contributions": 2
    }
  ],
  "file_tree_count": 274,
  "file_tree_sample": [
    {
      "path": ".faq",
      "type": "tree"
    },
    {
      "path": ".faq/FAQ.md",
      "type": "blob"
    },
    {
      "path": ".faq/suggest.md",
      "type": "blob"
    },
    {
      "path": ".gitattributes",
      "type": "blob"
    },
    {
      "path": ".github",
      "type": "tree"
    },
    {
      "path": ".github/FUNDING.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE",
      "type": "tree"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/bug_report.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/config.yml",
      "type": "blob"
    },
    {
      "path": ".github/stale.yml",
      "type": "blob"
    }
  ],
  "issues_count": 0,
  "pulls_count": 564,
  "recent_issues": [
    {
      "number": 1886,
      "title": "Kernel Crash on Mac M4 when running training_a_model.ipynb with mps ",
      "state": "open"
    },
    {
      "number": 1885,
      "title": "einops error",
      "state": "open"
    },
    {
      "number": 1883,
      "title": "Allow to load a Calibration object from an in-memory dict directly",
      "state": "closed"
    },
    {
      "number": 1882,
      "title": "feat(cli): benchmark speaker count estimation",
      "state": "closed"
    },
    {
      "number": 1881,
      "title": "Notebook cannot be rendered on GitHub",
      "state": "open"
    }
  ],
  "recent_pulls": [
    {
      "number": 1883,
      "title": "Allow to load a Calibration object from an in-memory dict directly",
      "state": "closed"
    },
    {
      "number": 1882,
      "title": "feat(cli): benchmark speaker count estimation",
      "state": "closed"
    },
    {
      "number": 1880,
      "title": "feat(cli): add --metric option to \"pyannote-audio optimize\"",
      "state": "closed"
    },
    {
      "number": 1879,
      "title": "cli(benchmark): improve command",
      "state": "closed"
    },
    {
      "number": 1878,
      "title": "cli(benchmark):add a progress bar",
      "state": "closed"
    }
  ],
  "recent_commits": [
    {
      "sha": "240a7f3ef60bc613169df860b536b10e338dbf3c",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-09-11T11:06:31+00:00",
      "message": "Merge branch 'release/3.3.2'"
    },
    {
      "sha": "faf6126b5d8de8f7b1df950c342101582c5f687b",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-09-11T11:06:04+00:00",
      "message": "setup: bump version"
    },
    {
      "sha": "b393e55272efb0cc54c96c9ca451bcbc6b7e8260",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-09-11T11:05:50+00:00",
      "message": "doc: update changelog"
    },
    {
      "sha": "0ea4c025ee048c36d74ccdb8b3f4939a27ad729b",
      "author": "huisman",
      "date": "2024-08-19T15:17:55+00:00",
      "message": "doc: fix Pipeline docstring"
    },
    {
      "sha": "286ea1a4e34e2dd7d7926f590e402dac1e17494b",
      "author": "Patrice Ferlet",
      "date": "2024-07-01T11:39:57+00:00",
      "message": "fix: fix support for `numpy==2.x`"
    },
    {
      "sha": "2e04ec7fb65ea9a12325d2212963790afc6037e6",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-19T12:01:50+00:00",
      "message": "Merge tag '3.3.1' into develop"
    },
    {
      "sha": "4dd55a51b2e0484e0265b660c85dbe39f293c488",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-19T12:01:37+00:00",
      "message": "Merge branch 'release/3.3.1'"
    },
    {
      "sha": "82f345a3df5ea5cdcf0b8e24f8d090e4bddc3765",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-19T12:01:24+00:00",
      "message": "doc: update changelog and bump version"
    },
    {
      "sha": "bd7b977c21611b1f76ec4227cf247febda624afc",
      "author": "Adel Moumen",
      "date": "2024-06-19T11:58:31+00:00",
      "message": "fix: fix support for `speechbrain==1.0` (#1659)"
    },
    {
      "sha": "1a5b870a90f0a83eabde42f0377f5214d53d2439",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-19T11:03:24+00:00",
      "message": "setup: drop support for Python 3.8 (#1728)"
    },
    {
      "sha": "50b21d4b2fdbf87a07d9158655d25feacfab678b",
      "author": "ibevers",
      "date": "2024-06-19T10:34:45+00:00",
      "message": "fix: fix support for NumPy 2.0.0"
    },
    {
      "sha": "cd3f550d00ea6bfb155dc7aef17e4f9c2516ee55",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-14T08:39:20+00:00",
      "message": "Merge tag '3.3.0' into develop"
    },
    {
      "sha": "adaf770a7088ddd0d3a86db7150278b2f5045bb5",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-14T08:39:03+00:00",
      "message": "Merge branch 'release/3.3.0'"
    },
    {
      "sha": "d260ba05594407436e1238981e2eface1dae0dd5",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-14T08:38:44+00:00",
      "message": "doc: bump version number"
    },
    {
      "sha": "49d3b8eed6d1ee10a69defa2b39b75fd96a8fb0d",
      "author": "Joonas Kalda",
      "date": "2024-05-30T10:46:27+00:00",
      "message": "feat(separation): add PixIT task, ToTaToNet model and SpeechSeparation pipeline (#1676)"
    },
    {
      "sha": "f1951a6f730d2479ababf6758692ff649415b461",
      "author": "benniekiss",
      "date": "2024-05-28T12:34:21+00:00",
      "message": "improve(pipeline): optimize memory usage in `Inference.aggregate`"
    },
    {
      "sha": "d327195529ebd5bec920b8d7394c6f92a6d4c409",
      "author": "Cl\u00e9ment Pag\u00e9s",
      "date": "2024-05-24T10:30:06+00:00",
      "message": "fix(task): fix metadata preparation with missing validation subset"
    },
    {
      "sha": "5e03622cb3fdc3a9d96a0cadb6dd4aad1e75ff43",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-05-19T14:53:40+00:00",
      "message": "improve(pipeline): do not extract embeddings in `SpeakerDiarization` pipeline when `max_speakers` is 1 (#1686)"
    },
    {
      "sha": "f1a6db2a2a02c0e80a3073027d1ae9b49d45b3c1",
      "author": "Purfview",
      "date": "2024-05-17T19:03:32+00:00",
      "message": "fix(doc): remove mention of unsupported `numpy.ndarray` waveform (#1691)"
    },
    {
      "sha": "5ae4c9b685feee02cbd58d25210e51def7037079",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-05-17T18:59:02+00:00",
      "message": "improve(io): use (faster) soundfile backend when available (#1711)"
    }
  ],
  "readme_text": "Using `pyannote.audio` open-source toolkit in production?  \nConsider switching to [pyannoteAI](https://www.pyannote.ai) for better and faster options.\n\n# `pyannote.audio` speaker diarization toolkit\n\n`pyannote.audio` is an open-source toolkit written in Python for speaker diarization. Based on [PyTorch](pytorch.org) machine learning framework, it comes with state-of-the-art [pretrained models and pipelines](https://hf.co/pyannote), that can be further finetuned to your own data for even better performance.\n\n<p align=\"center\">\n <a href=\"https://www.youtube.com/watch?v=37R_R82lfwA\"><img src=\"https://img.youtube.com/vi/37R_R82lfwA/0.jpg\"></a>\n</p>\n\n## TL;DR\n\n1. Install [`pyannote.audio`](https://github.com/pyannote/pyannote-audio) with `pip install pyannote.audio`\n2. Accept [`pyannote/segmentation-3.0`](https://hf.co/pyannote/segmentation-3.0) user conditions\n3. Accept [`pyannote/speaker-diarization-3.1`](https://hf.co/pyannote/speaker-diarization-3.1) user conditions\n4. Create access token at [`hf.co/settings/tokens`](https://hf.co/settings/tokens).\n\n```python\nfrom pyannote.audio import Pipeline\npipeline = Pipeline.from_pretrained(\n    \"pyannote/speaker-diarization-3.1\",\n    use_auth_token=\"HUGGINGFACE_ACCESS_TOKEN_GOES_HERE\")\n\n# send pipeline to GPU (when available)\nimport torch\npipeline.to(torch.device(\"cuda\"))\n\n# apply pretrained pipeline\ndiarization = pipeline(\"audio.wav\")\n\n# print the result\nfor turn, _, speaker in diarization.itertracks(yield_label=True):\n    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n# start=0.2s stop=1.5s speaker_0\n# start=1.8s stop=3.9s speaker_1\n# start=4.2s stop=5.7s speaker_0\n# ...\n```\n\n## Highlights\n\n- :hugs: pretrained [pipelines](https://hf.co/models?other=pyannote-audio-pipeline) (and [models](https://hf.co/models?other=pyannote-audio-model)) on [:hugs: model hub](https://huggingface.co/pyannote)\n- :exploding_head: state-of-the-art performance (see [Benchmark](#benchmark))\n- :snake: Python-first API\n- :zap: multi-GPU training with [pytorch-lightning](https://pytorchlightning.ai/)\n\n## Documentation\n\n- [Changelog](CHANGELOG.md)\n- [Frequently asked questions](FAQ.md)\n- Models\n  - Available tasks explained\n  - [Applying a pretrained model](tutorials/applying_a_model.ipynb)\n  - [Training, fine-tuning, and transfer learning](tutorials/training_a_model.ipynb)\n- Pipelines\n  - Available pipelines explained\n  - [Applying a pretrained pipeline](tutorials/applying_a_pipeline.ipynb)\n  - [Adapting a pretrained pipeline to your own data](tutorials/adapting_pretrained_pipeline.ipynb)\n  - [Training a pipeline](tutorials/voice_activity_detection.ipynb)\n- Contributing\n  - [Adding a new model](tutorials/add_your_own_model.ipynb)\n  - [Adding a new task](tutorials/add_your_own_task.ipynb)\n  - Adding a new pipeline\n  - Sharing pretrained models and pipelines\n- Blog\n  - 2022-12-02 > [\"How I reached 1st place at Ego4D 2022, 1st place at Albayzin 2022, and 6th place at VoxSRC 2022 speaker diarization challenges\"](tutorials/adapting_pretrained_pipeline.ipynb)\n  - 2022-10-23 > [\"One speaker segmentation model to rule them all\"](https://herve.niderb.fr/fastpages/2022/10/23/One-speaker-segmentation-model-to-rule-them-all)\n  - 2021-08-05 > [\"Streaming voice activity detection with pyannote.audio\"](https://herve.niderb.fr/fastpages/2021/08/05/Streaming-voice-activity-detection-with-pyannote.html)\n- Videos\n  - [Introduction to speaker diarization](https://umotion.univ-lemans.fr/video/9513-speech-segmentation-and-speaker-diarization/) / JSALT 2023 summer school / 90 min\n  - [Speaker segmentation model](https://www.youtube.com/watch?v=wDH2rvkjymY) / Interspeech 2021 / 3 min\n  - [First release of pyannote.audio](https://www.youtube.com/watch?v=37R_R82lfwA) / ICASSP 2020 / 8 min\n- Community contributions (not maintained by the core team)\n  - 2024-04-05 > [Offline speaker diarization (speaker-diarization-3.1)](tutorials/community/offline_usage_speaker_diarization.ipynb) by [Simon Ottenhaus](https://github.com/simonottenhauskenbun)\n\n## Benchmark\n\nOut of the box, `pyannote.audio` speaker diarization [pipeline](https://hf.co/pyannote/speaker-diarization-3.1) v3.1 is expected to be much better (and faster) than v2.x.\nThose numbers are diarization error rates (in %):\n\n| Benchmark                                                                                                                   | [v2.1](https://hf.co/pyannote/speaker-diarization-2.1) | [v3.1](https://hf.co/pyannote/speaker-diarization-3.1) | [pyannoteAI](https://www.pyannote.ai) |\n| --------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------ |\n| [AISHELL-4](https://arxiv.org/abs/2104.03603)                                                                               | 14.1                                                   | 12.2                                                   | 11.9                                             |\n| [AliMeeting](https://www.openslr.org/119/) (channel 1)                                                                      | 27.4                                                   | 24.4                                                   | 22.5                                             |\n| [AMI](https://groups.inf.ed.ac.uk/ami/corpus/) (IHM)                                                                        | 18.9                                                   | 18.8                                                   | 16.6                                             |\n| [AMI](https://groups.inf.ed.ac.uk/ami/corpus/) (SDM)                                                                        | 27.1                                                   | 22.4                                                   | 20.9                                             |\n| [AVA-AVD](https://arxiv.org/abs/2111.14448)                                                                                 | 66.3                                                   | 50.0                                                   | 39.8                                             |\n| [CALLHOME](https://catalog.ldc.upenn.edu/LDC2001S97) ([part 2](https://github.com/BUTSpeechFIT/CALLHOME_sublists/issues/1)) | 31.6                                                   | 28.4                                                   | 22.2                                             |\n| [DIHARD 3](https://catalog.ldc.upenn.edu/LDC2022S14) ([full](https://arxiv.org/abs/2012.01477))                             | 26.9                                                   | 21.7                                                   | 17.2                                             |\n| [Earnings21](https://github.com/revdotcom/speech-datasets)                                                                  | 17.0                                                   | 9.4                                                    | 9.0                                              |\n| [Ego4D](https://arxiv.org/abs/2110.07058) (dev.)                                                                            | 61.5                                                   | 51.2                                                   | 43.8                                             |\n| [MSDWild](https://github.com/X-LANCE/MSDWILD)                                                                               | 32.8                                                   | 25.3                                                   | 19.8                                             |\n| [RAMC](https://www.openslr.org/123/)                                                                                        | 22.5                                                   | 22.2                                                   | 18.4                                             |\n| [REPERE](https://www.islrn.org/resources/360-758-359-485-0/) (phase2)                                                       | 8.2                                                    | 7.8                                                    | 7.6                                              |\n| [VoxConverse](https://github.com/joonson/voxconverse) (v0.3)                                                                | 11.2                                                   | 11.3                                                   | 9.4                                              |\n\n[Diarization error rate](http://pyannote.github.io/pyannote-metrics/reference.html#diarization) (in %)\n\n## Citations\n\nIf you use `pyannote.audio` please use the following citations:\n\n```bibtex\n@inproceedings{Plaquet23,\n  author={Alexis Plaquet and Herv\u00e9 Bredin},\n  title={{Powerset multi-class cross entropy loss for neural speaker diarization}},\n  year=2023,\n  booktitle={Proc. INTERSPEECH 2023},\n}\n```\n\n```bibtex\n@inproceedings{Bredin23,\n  author={Herv\u00e9 Bredin},\n  title={{pyannote.audio 2.1 speaker diarization pipeline: principle, benchmark, and recipe}},\n  year=2023,\n  booktitle={Proc. INTERSPEECH 2023},\n}\n```\n\n## Development\n\nThe commands below will setup pre-commit hooks and packages needed for developing the `pyannote.audio` library.\n\n```bash\npip install -e .[dev,testing]\npre-commit install\n```\n\n## Test\n\n```bash\npytest\n```\n",
  "external_links_in_readme": [
    "https://img.youtube.com/vi/37R_R82lfwA/0.jpg\"></a>",
    "https://catalog.ldc.upenn.edu/LDC2022S14",
    "https://www.pyannote.ai",
    "https://github.com/revdotcom/speech-datasets",
    "https://hf.co/pyannote/speaker-diarization-2.1",
    "https://hf.co/pyannote/segmentation-3.0",
    "https://www.openslr.org/119/",
    "https://www.openslr.org/123/",
    "https://github.com/BUTSpeechFIT/CALLHOME_sublists/issues/1",
    "https://hf.co/pyannote/speaker-diarization-3.1",
    "https://hf.co/models?other=pyannote-audio-pipeline",
    "https://hf.co/settings/tokens",
    "https://huggingface.co/pyannote",
    "https://herve.niderb.fr/fastpages/2022/10/23/One-speaker-segmentation-model-to-rule-them-all",
    "https://arxiv.org/abs/2110.07058",
    "https://github.com/X-LANCE/MSDWILD",
    "https://catalog.ldc.upenn.edu/LDC2001S97",
    "https://github.com/joonson/voxconverse",
    "https://github.com/simonottenhauskenbun",
    "https://groups.inf.ed.ac.uk/ami/corpus/",
    "https://www.youtube.com/watch?v=wDH2rvkjymY",
    "https://www.youtube.com/watch?v=37R_R82lfwA",
    "https://umotion.univ-lemans.fr/video/9513-speech-segmentation-and-speaker-diarization/",
    "https://arxiv.org/abs/2104.03603",
    "https://www.islrn.org/resources/360-758-359-485-0/",
    "https://hf.co/models?other=pyannote-audio-model",
    "https://arxiv.org/abs/2111.14448",
    "https://github.com/pyannote/pyannote-audio",
    "https://www.youtube.com/watch?v=37R_R82lfwA\"><img",
    "https://pytorchlightning.ai/",
    "https://arxiv.org/abs/2012.01477",
    "http://pyannote.github.io/pyannote-metrics/reference.html#diarization",
    "https://hf.co/pyannote",
    "https://herve.niderb.fr/fastpages/2021/08/05/Streaming-voice-activity-detection-with-pyannote.html"
  ]
}
```

</details>


---

## Repository 4: pyannote/pyannote-audio

# GitHub Repository Data

**Repository:** [pyannote/pyannote-audio](https://github.com/pyannote/pyannote-audio)

## Basic Information

- **Description:** Neural building blocks for speaker diarization: speech activity detection, speaker change detection, overlapped speech detection, speaker embedding 
- **Created:** 2016-03-07T17:26:15+00:00
- **Last Updated:** 2025-06-21T19:32:29+00:00
- **Last Pushed:** 2025-06-18T16:16:10+00:00
- **Default Branch:** main
- **Size:** 264175 KB

## Statistics

- **Stars:** 7,742
- **Forks:** 891
- **Watchers:** 7,742
- **Open Issues:** 37
- **Total Issues:** 0
- **Pull Requests:** 564

## License

- **Type:** MIT License
- **SPDX ID:** MIT
- **URL:** [License](https://github.com/pyannote/pyannote-audio/blob/main/LICENSE)

## Languages

- **Jupyter Notebook:** 1,482,887 bytes
- **Python:** 725,205 bytes

## Topics

- `pytorch`
- `speech-processing`
- `speaker-diarization`
- `speech-activity-detection`
- `speaker-change-detection`
- `speaker-embedding`
- `voice-activity-detection`
- `pretrained-models`
- `overlapped-speech-detection`
- `speaker-recognition`
- `speaker-verification`

## Top Contributors

1. **hbredin** - 2231 contributions
2. **mogwai** - 42 contributions
3. **FrenchKrab** - 17 contributions
4. **juanmc2005** - 11 contributions
5. **clement-pages** - 10 contributions
6. **pkorshunov** - 5 contributions
7. **yinruiqing** - 5 contributions
8. **wesbz** - 3 contributions
9. **flyingleafe** - 3 contributions
10. **kan-cloud** - 3 contributions

## File Structure (Sample of 10 files)

Total files: 274

- `.faq` (tree)
- `.faq/FAQ.md` (blob)
- `.faq/suggest.md` (blob)
- `.gitattributes` (blob)
- `.github` (tree)
- `.github/FUNDING.yml` (blob)
- `.github/ISSUE_TEMPLATE` (tree)
- `.github/ISSUE_TEMPLATE/bug_report.yml` (blob)
- `.github/ISSUE_TEMPLATE/config.yml` (blob)
- `.github/stale.yml` (blob)

## Recent Issues

- ðŸŸ¢ **#1886** Kernel Crash on Mac M4 when running training_a_model.ipynb with mps  (open)
- ðŸŸ¢ **#1885** einops error (open)
- ðŸ”´ **#1883** Allow to load a Calibration object from an in-memory dict directly (closed)
- ðŸ”´ **#1882** feat(cli): benchmark speaker count estimation (closed)
- ðŸŸ¢ **#1881** Notebook cannot be rendered on GitHub (open)

## Recent Pull Requests

- ðŸ”´ **#1883** Allow to load a Calibration object from an in-memory dict directly (closed)
- ðŸ”´ **#1882** feat(cli): benchmark speaker count estimation (closed)
- ðŸ”´ **#1880** feat(cli): add --metric option to "pyannote-audio optimize" (closed)
- ðŸ”´ **#1879** cli(benchmark): improve command (closed)
- ðŸ”´ **#1878** cli(benchmark):add a progress bar (closed)

## Recent Commits

- **240a7f3e** Merge branch 'release/3.3.2' - HervÃ© BREDIN (2024-09-11T11:06:31+00:00)
- **faf6126b** setup: bump version - HervÃ© BREDIN (2024-09-11T11:06:04+00:00)
- **b393e552** doc: update changelog - HervÃ© BREDIN (2024-09-11T11:05:50+00:00)
- **0ea4c025** doc: fix Pipeline docstring - huisman (2024-08-19T15:17:55+00:00)
- **286ea1a4** fix: fix support for `numpy==2.x` - Patrice Ferlet (2024-07-01T11:39:57+00:00)
- **2e04ec7f** Merge tag '3.3.1' into develop - HervÃ© BREDIN (2024-06-19T12:01:50+00:00)
- **4dd55a51** Merge branch 'release/3.3.1' - HervÃ© BREDIN (2024-06-19T12:01:37+00:00)
- **82f345a3** doc: update changelog and bump version - HervÃ© BREDIN (2024-06-19T12:01:24+00:00)
- **bd7b977c** fix: fix support for `speechbrain==1.0` (#1659) - Adel Moumen (2024-06-19T11:58:31+00:00)
- **1a5b870a** setup: drop support for Python 3.8 (#1728) - HervÃ© BREDIN (2024-06-19T11:03:24+00:00)

## External Links Found in README

- https://img.youtube.com/vi/37R_R82lfwA/0.jpg"></a>
- https://catalog.ldc.upenn.edu/LDC2022S14
- https://www.pyannote.ai
- https://github.com/revdotcom/speech-datasets
- https://hf.co/pyannote/speaker-diarization-2.1
- https://hf.co/pyannote/segmentation-3.0
- https://www.openslr.org/119/
- https://www.openslr.org/123/
- https://github.com/BUTSpeechFIT/CALLHOME_sublists/issues/1
- https://hf.co/pyannote/speaker-diarization-3.1
- https://hf.co/models?other=pyannote-audio-pipeline
- https://hf.co/settings/tokens
- https://huggingface.co/pyannote
- https://herve.niderb.fr/fastpages/2022/10/23/One-speaker-segmentation-model-to-rule-them-all
- https://arxiv.org/abs/2110.07058
- https://github.com/X-LANCE/MSDWILD
- https://catalog.ldc.upenn.edu/LDC2001S97
- https://github.com/joonson/voxconverse
- https://github.com/simonottenhauskenbun
- https://groups.inf.ed.ac.uk/ami/corpus/

## Raw Data

<details>
<summary>Click to expand raw JSON data</summary>

```json
{
  "id": 53344691,
  "name": "pyannote-audio",
  "full_name": "pyannote/pyannote-audio",
  "description": "Neural building blocks for speaker diarization: speech activity detection, speaker change detection, overlapped speech detection, speaker embedding ",
  "html_url": "https://github.com/pyannote/pyannote-audio",
  "clone_url": "https://github.com/pyannote/pyannote-audio.git",
  "ssh_url": "git@github.com:pyannote/pyannote-audio.git",
  "homepage": "http://pyannote.github.io",
  "topics": [
    "pytorch",
    "speech-processing",
    "speaker-diarization",
    "speech-activity-detection",
    "speaker-change-detection",
    "speaker-embedding",
    "voice-activity-detection",
    "pretrained-models",
    "overlapped-speech-detection",
    "speaker-recognition",
    "speaker-verification"
  ],
  "default_branch": "main",
  "created_at": "2016-03-07T17:26:15+00:00",
  "updated_at": "2025-06-21T19:32:29+00:00",
  "pushed_at": "2025-06-18T16:16:10+00:00",
  "size_kb": 264175,
  "watchers_count": 7742,
  "stargazers_count": 7742,
  "forks_count": 891,
  "open_issues_count": 37,
  "license": {
    "key": "mit",
    "name": "MIT License",
    "spdx_id": "MIT",
    "url": "https://github.com/pyannote/pyannote-audio/blob/main/LICENSE"
  },
  "languages": {
    "Jupyter Notebook": 1482887,
    "Python": 725205
  },
  "top_contributors": [
    {
      "login": "hbredin",
      "contributions": 2231
    },
    {
      "login": "mogwai",
      "contributions": 42
    },
    {
      "login": "FrenchKrab",
      "contributions": 17
    },
    {
      "login": "juanmc2005",
      "contributions": 11
    },
    {
      "login": "clement-pages",
      "contributions": 10
    },
    {
      "login": "pkorshunov",
      "contributions": 5
    },
    {
      "login": "yinruiqing",
      "contributions": 5
    },
    {
      "login": "wesbz",
      "contributions": 3
    },
    {
      "login": "flyingleafe",
      "contributions": 3
    },
    {
      "login": "kan-cloud",
      "contributions": 3
    },
    {
      "login": "clbarras",
      "contributions": 3
    },
    {
      "login": "MarvinLvn",
      "contributions": 3
    },
    {
      "login": "Mymoza",
      "contributions": 3
    },
    {
      "login": "J-Petiot",
      "contributions": 3
    },
    {
      "login": "martinjbaker",
      "contributions": 2
    },
    {
      "login": "hadware",
      "contributions": 2
    },
    {
      "login": "dependabot[bot]",
      "contributions": 2
    },
    {
      "login": "PaulLerner",
      "contributions": 2
    },
    {
      "login": "julien-c",
      "contributions": 2
    },
    {
      "login": "GregGovit",
      "contributions": 2
    }
  ],
  "file_tree_count": 274,
  "file_tree_sample": [
    {
      "path": ".faq",
      "type": "tree"
    },
    {
      "path": ".faq/FAQ.md",
      "type": "blob"
    },
    {
      "path": ".faq/suggest.md",
      "type": "blob"
    },
    {
      "path": ".gitattributes",
      "type": "blob"
    },
    {
      "path": ".github",
      "type": "tree"
    },
    {
      "path": ".github/FUNDING.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE",
      "type": "tree"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/bug_report.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/config.yml",
      "type": "blob"
    },
    {
      "path": ".github/stale.yml",
      "type": "blob"
    }
  ],
  "issues_count": 0,
  "pulls_count": 564,
  "recent_issues": [
    {
      "number": 1886,
      "title": "Kernel Crash on Mac M4 when running training_a_model.ipynb with mps ",
      "state": "open"
    },
    {
      "number": 1885,
      "title": "einops error",
      "state": "open"
    },
    {
      "number": 1883,
      "title": "Allow to load a Calibration object from an in-memory dict directly",
      "state": "closed"
    },
    {
      "number": 1882,
      "title": "feat(cli): benchmark speaker count estimation",
      "state": "closed"
    },
    {
      "number": 1881,
      "title": "Notebook cannot be rendered on GitHub",
      "state": "open"
    }
  ],
  "recent_pulls": [
    {
      "number": 1883,
      "title": "Allow to load a Calibration object from an in-memory dict directly",
      "state": "closed"
    },
    {
      "number": 1882,
      "title": "feat(cli): benchmark speaker count estimation",
      "state": "closed"
    },
    {
      "number": 1880,
      "title": "feat(cli): add --metric option to \"pyannote-audio optimize\"",
      "state": "closed"
    },
    {
      "number": 1879,
      "title": "cli(benchmark): improve command",
      "state": "closed"
    },
    {
      "number": 1878,
      "title": "cli(benchmark):add a progress bar",
      "state": "closed"
    }
  ],
  "recent_commits": [
    {
      "sha": "240a7f3ef60bc613169df860b536b10e338dbf3c",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-09-11T11:06:31+00:00",
      "message": "Merge branch 'release/3.3.2'"
    },
    {
      "sha": "faf6126b5d8de8f7b1df950c342101582c5f687b",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-09-11T11:06:04+00:00",
      "message": "setup: bump version"
    },
    {
      "sha": "b393e55272efb0cc54c96c9ca451bcbc6b7e8260",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-09-11T11:05:50+00:00",
      "message": "doc: update changelog"
    },
    {
      "sha": "0ea4c025ee048c36d74ccdb8b3f4939a27ad729b",
      "author": "huisman",
      "date": "2024-08-19T15:17:55+00:00",
      "message": "doc: fix Pipeline docstring"
    },
    {
      "sha": "286ea1a4e34e2dd7d7926f590e402dac1e17494b",
      "author": "Patrice Ferlet",
      "date": "2024-07-01T11:39:57+00:00",
      "message": "fix: fix support for `numpy==2.x`"
    },
    {
      "sha": "2e04ec7fb65ea9a12325d2212963790afc6037e6",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-19T12:01:50+00:00",
      "message": "Merge tag '3.3.1' into develop"
    },
    {
      "sha": "4dd55a51b2e0484e0265b660c85dbe39f293c488",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-19T12:01:37+00:00",
      "message": "Merge branch 'release/3.3.1'"
    },
    {
      "sha": "82f345a3df5ea5cdcf0b8e24f8d090e4bddc3765",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-19T12:01:24+00:00",
      "message": "doc: update changelog and bump version"
    },
    {
      "sha": "bd7b977c21611b1f76ec4227cf247febda624afc",
      "author": "Adel Moumen",
      "date": "2024-06-19T11:58:31+00:00",
      "message": "fix: fix support for `speechbrain==1.0` (#1659)"
    },
    {
      "sha": "1a5b870a90f0a83eabde42f0377f5214d53d2439",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-19T11:03:24+00:00",
      "message": "setup: drop support for Python 3.8 (#1728)"
    },
    {
      "sha": "50b21d4b2fdbf87a07d9158655d25feacfab678b",
      "author": "ibevers",
      "date": "2024-06-19T10:34:45+00:00",
      "message": "fix: fix support for NumPy 2.0.0"
    },
    {
      "sha": "cd3f550d00ea6bfb155dc7aef17e4f9c2516ee55",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-14T08:39:20+00:00",
      "message": "Merge tag '3.3.0' into develop"
    },
    {
      "sha": "adaf770a7088ddd0d3a86db7150278b2f5045bb5",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-14T08:39:03+00:00",
      "message": "Merge branch 'release/3.3.0'"
    },
    {
      "sha": "d260ba05594407436e1238981e2eface1dae0dd5",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-14T08:38:44+00:00",
      "message": "doc: bump version number"
    },
    {
      "sha": "49d3b8eed6d1ee10a69defa2b39b75fd96a8fb0d",
      "author": "Joonas Kalda",
      "date": "2024-05-30T10:46:27+00:00",
      "message": "feat(separation): add PixIT task, ToTaToNet model and SpeechSeparation pipeline (#1676)"
    },
    {
      "sha": "f1951a6f730d2479ababf6758692ff649415b461",
      "author": "benniekiss",
      "date": "2024-05-28T12:34:21+00:00",
      "message": "improve(pipeline): optimize memory usage in `Inference.aggregate`"
    },
    {
      "sha": "d327195529ebd5bec920b8d7394c6f92a6d4c409",
      "author": "Cl\u00e9ment Pag\u00e9s",
      "date": "2024-05-24T10:30:06+00:00",
      "message": "fix(task): fix metadata preparation with missing validation subset"
    },
    {
      "sha": "5e03622cb3fdc3a9d96a0cadb6dd4aad1e75ff43",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-05-19T14:53:40+00:00",
      "message": "improve(pipeline): do not extract embeddings in `SpeakerDiarization` pipeline when `max_speakers` is 1 (#1686)"
    },
    {
      "sha": "f1a6db2a2a02c0e80a3073027d1ae9b49d45b3c1",
      "author": "Purfview",
      "date": "2024-05-17T19:03:32+00:00",
      "message": "fix(doc): remove mention of unsupported `numpy.ndarray` waveform (#1691)"
    },
    {
      "sha": "5ae4c9b685feee02cbd58d25210e51def7037079",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-05-17T18:59:02+00:00",
      "message": "improve(io): use (faster) soundfile backend when available (#1711)"
    }
  ],
  "readme_text": "Using `pyannote.audio` open-source toolkit in production?  \nConsider switching to [pyannoteAI](https://www.pyannote.ai) for better and faster options.\n\n# `pyannote.audio` speaker diarization toolkit\n\n`pyannote.audio` is an open-source toolkit written in Python for speaker diarization. Based on [PyTorch](pytorch.org) machine learning framework, it comes with state-of-the-art [pretrained models and pipelines](https://hf.co/pyannote), that can be further finetuned to your own data for even better performance.\n\n<p align=\"center\">\n <a href=\"https://www.youtube.com/watch?v=37R_R82lfwA\"><img src=\"https://img.youtube.com/vi/37R_R82lfwA/0.jpg\"></a>\n</p>\n\n## TL;DR\n\n1. Install [`pyannote.audio`](https://github.com/pyannote/pyannote-audio) with `pip install pyannote.audio`\n2. Accept [`pyannote/segmentation-3.0`](https://hf.co/pyannote/segmentation-3.0) user conditions\n3. Accept [`pyannote/speaker-diarization-3.1`](https://hf.co/pyannote/speaker-diarization-3.1) user conditions\n4. Create access token at [`hf.co/settings/tokens`](https://hf.co/settings/tokens).\n\n```python\nfrom pyannote.audio import Pipeline\npipeline = Pipeline.from_pretrained(\n    \"pyannote/speaker-diarization-3.1\",\n    use_auth_token=\"HUGGINGFACE_ACCESS_TOKEN_GOES_HERE\")\n\n# send pipeline to GPU (when available)\nimport torch\npipeline.to(torch.device(\"cuda\"))\n\n# apply pretrained pipeline\ndiarization = pipeline(\"audio.wav\")\n\n# print the result\nfor turn, _, speaker in diarization.itertracks(yield_label=True):\n    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n# start=0.2s stop=1.5s speaker_0\n# start=1.8s stop=3.9s speaker_1\n# start=4.2s stop=5.7s speaker_0\n# ...\n```\n\n## Highlights\n\n- :hugs: pretrained [pipelines](https://hf.co/models?other=pyannote-audio-pipeline) (and [models](https://hf.co/models?other=pyannote-audio-model)) on [:hugs: model hub](https://huggingface.co/pyannote)\n- :exploding_head: state-of-the-art performance (see [Benchmark](#benchmark))\n- :snake: Python-first API\n- :zap: multi-GPU training with [pytorch-lightning](https://pytorchlightning.ai/)\n\n## Documentation\n\n- [Changelog](CHANGELOG.md)\n- [Frequently asked questions](FAQ.md)\n- Models\n  - Available tasks explained\n  - [Applying a pretrained model](tutorials/applying_a_model.ipynb)\n  - [Training, fine-tuning, and transfer learning](tutorials/training_a_model.ipynb)\n- Pipelines\n  - Available pipelines explained\n  - [Applying a pretrained pipeline](tutorials/applying_a_pipeline.ipynb)\n  - [Adapting a pretrained pipeline to your own data](tutorials/adapting_pretrained_pipeline.ipynb)\n  - [Training a pipeline](tutorials/voice_activity_detection.ipynb)\n- Contributing\n  - [Adding a new model](tutorials/add_your_own_model.ipynb)\n  - [Adding a new task](tutorials/add_your_own_task.ipynb)\n  - Adding a new pipeline\n  - Sharing pretrained models and pipelines\n- Blog\n  - 2022-12-02 > [\"How I reached 1st place at Ego4D 2022, 1st place at Albayzin 2022, and 6th place at VoxSRC 2022 speaker diarization challenges\"](tutorials/adapting_pretrained_pipeline.ipynb)\n  - 2022-10-23 > [\"One speaker segmentation model to rule them all\"](https://herve.niderb.fr/fastpages/2022/10/23/One-speaker-segmentation-model-to-rule-them-all)\n  - 2021-08-05 > [\"Streaming voice activity detection with pyannote.audio\"](https://herve.niderb.fr/fastpages/2021/08/05/Streaming-voice-activity-detection-with-pyannote.html)\n- Videos\n  - [Introduction to speaker diarization](https://umotion.univ-lemans.fr/video/9513-speech-segmentation-and-speaker-diarization/) / JSALT 2023 summer school / 90 min\n  - [Speaker segmentation model](https://www.youtube.com/watch?v=wDH2rvkjymY) / Interspeech 2021 / 3 min\n  - [First release of pyannote.audio](https://www.youtube.com/watch?v=37R_R82lfwA) / ICASSP 2020 / 8 min\n- Community contributions (not maintained by the core team)\n  - 2024-04-05 > [Offline speaker diarization (speaker-diarization-3.1)](tutorials/community/offline_usage_speaker_diarization.ipynb) by [Simon Ottenhaus](https://github.com/simonottenhauskenbun)\n\n## Benchmark\n\nOut of the box, `pyannote.audio` speaker diarization [pipeline](https://hf.co/pyannote/speaker-diarization-3.1) v3.1 is expected to be much better (and faster) than v2.x.\nThose numbers are diarization error rates (in %):\n\n| Benchmark                                                                                                                   | [v2.1](https://hf.co/pyannote/speaker-diarization-2.1) | [v3.1](https://hf.co/pyannote/speaker-diarization-3.1) | [pyannoteAI](https://www.pyannote.ai) |\n| --------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------ |\n| [AISHELL-4](https://arxiv.org/abs/2104.03603)                                                                               | 14.1                                                   | 12.2                                                   | 11.9                                             |\n| [AliMeeting](https://www.openslr.org/119/) (channel 1)                                                                      | 27.4                                                   | 24.4                                                   | 22.5                                             |\n| [AMI](https://groups.inf.ed.ac.uk/ami/corpus/) (IHM)                                                                        | 18.9                                                   | 18.8                                                   | 16.6                                             |\n| [AMI](https://groups.inf.ed.ac.uk/ami/corpus/) (SDM)                                                                        | 27.1                                                   | 22.4                                                   | 20.9                                             |\n| [AVA-AVD](https://arxiv.org/abs/2111.14448)                                                                                 | 66.3                                                   | 50.0                                                   | 39.8                                             |\n| [CALLHOME](https://catalog.ldc.upenn.edu/LDC2001S97) ([part 2](https://github.com/BUTSpeechFIT/CALLHOME_sublists/issues/1)) | 31.6                                                   | 28.4                                                   | 22.2                                             |\n| [DIHARD 3](https://catalog.ldc.upenn.edu/LDC2022S14) ([full](https://arxiv.org/abs/2012.01477))                             | 26.9                                                   | 21.7                                                   | 17.2                                             |\n| [Earnings21](https://github.com/revdotcom/speech-datasets)                                                                  | 17.0                                                   | 9.4                                                    | 9.0                                              |\n| [Ego4D](https://arxiv.org/abs/2110.07058) (dev.)                                                                            | 61.5                                                   | 51.2                                                   | 43.8                                             |\n| [MSDWild](https://github.com/X-LANCE/MSDWILD)                                                                               | 32.8                                                   | 25.3                                                   | 19.8                                             |\n| [RAMC](https://www.openslr.org/123/)                                                                                        | 22.5                                                   | 22.2                                                   | 18.4                                             |\n| [REPERE](https://www.islrn.org/resources/360-758-359-485-0/) (phase2)                                                       | 8.2                                                    | 7.8                                                    | 7.6                                              |\n| [VoxConverse](https://github.com/joonson/voxconverse) (v0.3)                                                                | 11.2                                                   | 11.3                                                   | 9.4                                              |\n\n[Diarization error rate](http://pyannote.github.io/pyannote-metrics/reference.html#diarization) (in %)\n\n## Citations\n\nIf you use `pyannote.audio` please use the following citations:\n\n```bibtex\n@inproceedings{Plaquet23,\n  author={Alexis Plaquet and Herv\u00e9 Bredin},\n  title={{Powerset multi-class cross entropy loss for neural speaker diarization}},\n  year=2023,\n  booktitle={Proc. INTERSPEECH 2023},\n}\n```\n\n```bibtex\n@inproceedings{Bredin23,\n  author={Herv\u00e9 Bredin},\n  title={{pyannote.audio 2.1 speaker diarization pipeline: principle, benchmark, and recipe}},\n  year=2023,\n  booktitle={Proc. INTERSPEECH 2023},\n}\n```\n\n## Development\n\nThe commands below will setup pre-commit hooks and packages needed for developing the `pyannote.audio` library.\n\n```bash\npip install -e .[dev,testing]\npre-commit install\n```\n\n## Test\n\n```bash\npytest\n```\n",
  "external_links_in_readme": [
    "https://img.youtube.com/vi/37R_R82lfwA/0.jpg\"></a>",
    "https://catalog.ldc.upenn.edu/LDC2022S14",
    "https://www.pyannote.ai",
    "https://github.com/revdotcom/speech-datasets",
    "https://hf.co/pyannote/speaker-diarization-2.1",
    "https://hf.co/pyannote/segmentation-3.0",
    "https://www.openslr.org/119/",
    "https://www.openslr.org/123/",
    "https://github.com/BUTSpeechFIT/CALLHOME_sublists/issues/1",
    "https://hf.co/pyannote/speaker-diarization-3.1",
    "https://hf.co/models?other=pyannote-audio-pipeline",
    "https://hf.co/settings/tokens",
    "https://huggingface.co/pyannote",
    "https://herve.niderb.fr/fastpages/2022/10/23/One-speaker-segmentation-model-to-rule-them-all",
    "https://arxiv.org/abs/2110.07058",
    "https://github.com/X-LANCE/MSDWILD",
    "https://catalog.ldc.upenn.edu/LDC2001S97",
    "https://github.com/joonson/voxconverse",
    "https://github.com/simonottenhauskenbun",
    "https://groups.inf.ed.ac.uk/ami/corpus/",
    "https://www.youtube.com/watch?v=wDH2rvkjymY",
    "https://www.youtube.com/watch?v=37R_R82lfwA",
    "https://umotion.univ-lemans.fr/video/9513-speech-segmentation-and-speaker-diarization/",
    "https://arxiv.org/abs/2104.03603",
    "https://www.islrn.org/resources/360-758-359-485-0/",
    "https://hf.co/models?other=pyannote-audio-model",
    "https://arxiv.org/abs/2111.14448",
    "https://github.com/pyannote/pyannote-audio",
    "https://www.youtube.com/watch?v=37R_R82lfwA\"><img",
    "https://pytorchlightning.ai/",
    "https://arxiv.org/abs/2012.01477",
    "http://pyannote.github.io/pyannote-metrics/reference.html#diarization",
    "https://hf.co/pyannote",
    "https://herve.niderb.fr/fastpages/2021/08/05/Streaming-voice-activity-detection-with-pyannote.html"
  ]
}
```

</details>


---

