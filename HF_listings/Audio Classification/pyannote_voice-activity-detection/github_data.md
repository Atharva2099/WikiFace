# GitHub Data for pyannote_voice-activity-detection

**Task Category:** Audio Classification

## Repository 1: pyannote/pyannote-audio

# GitHub Repository Data

**Repository:** [pyannote/pyannote-audio](https://github.com/pyannote/pyannote-audio)

## Basic Information

- **Description:** Neural building blocks for speaker diarization: speech activity detection, speaker change detection, overlapped speech detection, speaker embedding 
- **Created:** 2016-03-07T17:26:15+00:00
- **Last Updated:** 2025-06-21T19:32:29+00:00
- **Last Pushed:** 2025-06-18T16:16:10+00:00
- **Default Branch:** main
- **Size:** 264175 KB

## Statistics

- **Stars:** 7,742
- **Forks:** 891
- **Watchers:** 7,742
- **Open Issues:** 37
- **Total Issues:** 0
- **Pull Requests:** 564

## License

- **Type:** MIT License
- **SPDX ID:** MIT
- **URL:** [License](https://github.com/pyannote/pyannote-audio/blob/main/LICENSE)

## Languages

- **Jupyter Notebook:** 1,482,887 bytes
- **Python:** 725,205 bytes

## Topics

- `pytorch`
- `speech-processing`
- `speaker-diarization`
- `speech-activity-detection`
- `speaker-change-detection`
- `speaker-embedding`
- `voice-activity-detection`
- `pretrained-models`
- `overlapped-speech-detection`
- `speaker-recognition`
- `speaker-verification`

## Top Contributors

1. **hbredin** - 2231 contributions
2. **mogwai** - 42 contributions
3. **FrenchKrab** - 17 contributions
4. **juanmc2005** - 11 contributions
5. **clement-pages** - 10 contributions
6. **pkorshunov** - 5 contributions
7. **yinruiqing** - 5 contributions
8. **wesbz** - 3 contributions
9. **flyingleafe** - 3 contributions
10. **kan-cloud** - 3 contributions

## File Structure (Sample of 10 files)

Total files: 274

- `.faq` (tree)
- `.faq/FAQ.md` (blob)
- `.faq/suggest.md` (blob)
- `.gitattributes` (blob)
- `.github` (tree)
- `.github/FUNDING.yml` (blob)
- `.github/ISSUE_TEMPLATE` (tree)
- `.github/ISSUE_TEMPLATE/bug_report.yml` (blob)
- `.github/ISSUE_TEMPLATE/config.yml` (blob)
- `.github/stale.yml` (blob)

## Recent Issues

- ðŸŸ¢ **#1886** Kernel Crash on Mac M4 when running training_a_model.ipynb with mps  (open)
- ðŸŸ¢ **#1885** einops error (open)
- ðŸ”´ **#1883** Allow to load a Calibration object from an in-memory dict directly (closed)
- ðŸ”´ **#1882** feat(cli): benchmark speaker count estimation (closed)
- ðŸŸ¢ **#1881** Notebook cannot be rendered on GitHub (open)

## Recent Pull Requests

- ðŸ”´ **#1883** Allow to load a Calibration object from an in-memory dict directly (closed)
- ðŸ”´ **#1882** feat(cli): benchmark speaker count estimation (closed)
- ðŸ”´ **#1880** feat(cli): add --metric option to "pyannote-audio optimize" (closed)
- ðŸ”´ **#1879** cli(benchmark): improve command (closed)
- ðŸ”´ **#1878** cli(benchmark):add a progress bar (closed)

## Recent Commits

- **240a7f3e** Merge branch 'release/3.3.2' - HervÃ© BREDIN (2024-09-11T11:06:31+00:00)
- **faf6126b** setup: bump version - HervÃ© BREDIN (2024-09-11T11:06:04+00:00)
- **b393e552** doc: update changelog - HervÃ© BREDIN (2024-09-11T11:05:50+00:00)
- **0ea4c025** doc: fix Pipeline docstring - huisman (2024-08-19T15:17:55+00:00)
- **286ea1a4** fix: fix support for `numpy==2.x` - Patrice Ferlet (2024-07-01T11:39:57+00:00)
- **2e04ec7f** Merge tag '3.3.1' into develop - HervÃ© BREDIN (2024-06-19T12:01:50+00:00)
- **4dd55a51** Merge branch 'release/3.3.1' - HervÃ© BREDIN (2024-06-19T12:01:37+00:00)
- **82f345a3** doc: update changelog and bump version - HervÃ© BREDIN (2024-06-19T12:01:24+00:00)
- **bd7b977c** fix: fix support for `speechbrain==1.0` (#1659) - Adel Moumen (2024-06-19T11:58:31+00:00)
- **1a5b870a** setup: drop support for Python 3.8 (#1728) - HervÃ© BREDIN (2024-06-19T11:03:24+00:00)

## External Links Found in README

- https://img.youtube.com/vi/37R_R82lfwA/0.jpg"></a>
- https://catalog.ldc.upenn.edu/LDC2022S14
- https://www.pyannote.ai
- https://github.com/revdotcom/speech-datasets
- https://hf.co/pyannote/speaker-diarization-2.1
- https://hf.co/pyannote/segmentation-3.0
- https://www.openslr.org/119/
- https://www.openslr.org/123/
- https://github.com/BUTSpeechFIT/CALLHOME_sublists/issues/1
- https://hf.co/pyannote/speaker-diarization-3.1
- https://hf.co/models?other=pyannote-audio-pipeline
- https://hf.co/settings/tokens
- https://huggingface.co/pyannote
- https://herve.niderb.fr/fastpages/2022/10/23/One-speaker-segmentation-model-to-rule-them-all
- https://arxiv.org/abs/2110.07058
- https://github.com/X-LANCE/MSDWILD
- https://catalog.ldc.upenn.edu/LDC2001S97
- https://github.com/joonson/voxconverse
- https://github.com/simonottenhauskenbun
- https://groups.inf.ed.ac.uk/ami/corpus/

## Raw Data

<details>
<summary>Click to expand raw JSON data</summary>

```json
{
  "id": 53344691,
  "name": "pyannote-audio",
  "full_name": "pyannote/pyannote-audio",
  "description": "Neural building blocks for speaker diarization: speech activity detection, speaker change detection, overlapped speech detection, speaker embedding ",
  "html_url": "https://github.com/pyannote/pyannote-audio",
  "clone_url": "https://github.com/pyannote/pyannote-audio.git",
  "ssh_url": "git@github.com:pyannote/pyannote-audio.git",
  "homepage": "http://pyannote.github.io",
  "topics": [
    "pytorch",
    "speech-processing",
    "speaker-diarization",
    "speech-activity-detection",
    "speaker-change-detection",
    "speaker-embedding",
    "voice-activity-detection",
    "pretrained-models",
    "overlapped-speech-detection",
    "speaker-recognition",
    "speaker-verification"
  ],
  "default_branch": "main",
  "created_at": "2016-03-07T17:26:15+00:00",
  "updated_at": "2025-06-21T19:32:29+00:00",
  "pushed_at": "2025-06-18T16:16:10+00:00",
  "size_kb": 264175,
  "watchers_count": 7742,
  "stargazers_count": 7742,
  "forks_count": 891,
  "open_issues_count": 37,
  "license": {
    "key": "mit",
    "name": "MIT License",
    "spdx_id": "MIT",
    "url": "https://github.com/pyannote/pyannote-audio/blob/main/LICENSE"
  },
  "languages": {
    "Jupyter Notebook": 1482887,
    "Python": 725205
  },
  "top_contributors": [
    {
      "login": "hbredin",
      "contributions": 2231
    },
    {
      "login": "mogwai",
      "contributions": 42
    },
    {
      "login": "FrenchKrab",
      "contributions": 17
    },
    {
      "login": "juanmc2005",
      "contributions": 11
    },
    {
      "login": "clement-pages",
      "contributions": 10
    },
    {
      "login": "pkorshunov",
      "contributions": 5
    },
    {
      "login": "yinruiqing",
      "contributions": 5
    },
    {
      "login": "wesbz",
      "contributions": 3
    },
    {
      "login": "flyingleafe",
      "contributions": 3
    },
    {
      "login": "kan-cloud",
      "contributions": 3
    },
    {
      "login": "clbarras",
      "contributions": 3
    },
    {
      "login": "MarvinLvn",
      "contributions": 3
    },
    {
      "login": "Mymoza",
      "contributions": 3
    },
    {
      "login": "J-Petiot",
      "contributions": 3
    },
    {
      "login": "martinjbaker",
      "contributions": 2
    },
    {
      "login": "hadware",
      "contributions": 2
    },
    {
      "login": "dependabot[bot]",
      "contributions": 2
    },
    {
      "login": "PaulLerner",
      "contributions": 2
    },
    {
      "login": "julien-c",
      "contributions": 2
    },
    {
      "login": "GregGovit",
      "contributions": 2
    }
  ],
  "file_tree_count": 274,
  "file_tree_sample": [
    {
      "path": ".faq",
      "type": "tree"
    },
    {
      "path": ".faq/FAQ.md",
      "type": "blob"
    },
    {
      "path": ".faq/suggest.md",
      "type": "blob"
    },
    {
      "path": ".gitattributes",
      "type": "blob"
    },
    {
      "path": ".github",
      "type": "tree"
    },
    {
      "path": ".github/FUNDING.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE",
      "type": "tree"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/bug_report.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/config.yml",
      "type": "blob"
    },
    {
      "path": ".github/stale.yml",
      "type": "blob"
    }
  ],
  "issues_count": 0,
  "pulls_count": 564,
  "recent_issues": [
    {
      "number": 1886,
      "title": "Kernel Crash on Mac M4 when running training_a_model.ipynb with mps ",
      "state": "open"
    },
    {
      "number": 1885,
      "title": "einops error",
      "state": "open"
    },
    {
      "number": 1883,
      "title": "Allow to load a Calibration object from an in-memory dict directly",
      "state": "closed"
    },
    {
      "number": 1882,
      "title": "feat(cli): benchmark speaker count estimation",
      "state": "closed"
    },
    {
      "number": 1881,
      "title": "Notebook cannot be rendered on GitHub",
      "state": "open"
    }
  ],
  "recent_pulls": [
    {
      "number": 1883,
      "title": "Allow to load a Calibration object from an in-memory dict directly",
      "state": "closed"
    },
    {
      "number": 1882,
      "title": "feat(cli): benchmark speaker count estimation",
      "state": "closed"
    },
    {
      "number": 1880,
      "title": "feat(cli): add --metric option to \"pyannote-audio optimize\"",
      "state": "closed"
    },
    {
      "number": 1879,
      "title": "cli(benchmark): improve command",
      "state": "closed"
    },
    {
      "number": 1878,
      "title": "cli(benchmark):add a progress bar",
      "state": "closed"
    }
  ],
  "recent_commits": [
    {
      "sha": "240a7f3ef60bc613169df860b536b10e338dbf3c",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-09-11T11:06:31+00:00",
      "message": "Merge branch 'release/3.3.2'"
    },
    {
      "sha": "faf6126b5d8de8f7b1df950c342101582c5f687b",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-09-11T11:06:04+00:00",
      "message": "setup: bump version"
    },
    {
      "sha": "b393e55272efb0cc54c96c9ca451bcbc6b7e8260",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-09-11T11:05:50+00:00",
      "message": "doc: update changelog"
    },
    {
      "sha": "0ea4c025ee048c36d74ccdb8b3f4939a27ad729b",
      "author": "huisman",
      "date": "2024-08-19T15:17:55+00:00",
      "message": "doc: fix Pipeline docstring"
    },
    {
      "sha": "286ea1a4e34e2dd7d7926f590e402dac1e17494b",
      "author": "Patrice Ferlet",
      "date": "2024-07-01T11:39:57+00:00",
      "message": "fix: fix support for `numpy==2.x`"
    },
    {
      "sha": "2e04ec7fb65ea9a12325d2212963790afc6037e6",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-19T12:01:50+00:00",
      "message": "Merge tag '3.3.1' into develop"
    },
    {
      "sha": "4dd55a51b2e0484e0265b660c85dbe39f293c488",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-19T12:01:37+00:00",
      "message": "Merge branch 'release/3.3.1'"
    },
    {
      "sha": "82f345a3df5ea5cdcf0b8e24f8d090e4bddc3765",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-19T12:01:24+00:00",
      "message": "doc: update changelog and bump version"
    },
    {
      "sha": "bd7b977c21611b1f76ec4227cf247febda624afc",
      "author": "Adel Moumen",
      "date": "2024-06-19T11:58:31+00:00",
      "message": "fix: fix support for `speechbrain==1.0` (#1659)"
    },
    {
      "sha": "1a5b870a90f0a83eabde42f0377f5214d53d2439",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-19T11:03:24+00:00",
      "message": "setup: drop support for Python 3.8 (#1728)"
    },
    {
      "sha": "50b21d4b2fdbf87a07d9158655d25feacfab678b",
      "author": "ibevers",
      "date": "2024-06-19T10:34:45+00:00",
      "message": "fix: fix support for NumPy 2.0.0"
    },
    {
      "sha": "cd3f550d00ea6bfb155dc7aef17e4f9c2516ee55",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-14T08:39:20+00:00",
      "message": "Merge tag '3.3.0' into develop"
    },
    {
      "sha": "adaf770a7088ddd0d3a86db7150278b2f5045bb5",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-14T08:39:03+00:00",
      "message": "Merge branch 'release/3.3.0'"
    },
    {
      "sha": "d260ba05594407436e1238981e2eface1dae0dd5",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-06-14T08:38:44+00:00",
      "message": "doc: bump version number"
    },
    {
      "sha": "49d3b8eed6d1ee10a69defa2b39b75fd96a8fb0d",
      "author": "Joonas Kalda",
      "date": "2024-05-30T10:46:27+00:00",
      "message": "feat(separation): add PixIT task, ToTaToNet model and SpeechSeparation pipeline (#1676)"
    },
    {
      "sha": "f1951a6f730d2479ababf6758692ff649415b461",
      "author": "benniekiss",
      "date": "2024-05-28T12:34:21+00:00",
      "message": "improve(pipeline): optimize memory usage in `Inference.aggregate`"
    },
    {
      "sha": "d327195529ebd5bec920b8d7394c6f92a6d4c409",
      "author": "Cl\u00e9ment Pag\u00e9s",
      "date": "2024-05-24T10:30:06+00:00",
      "message": "fix(task): fix metadata preparation with missing validation subset"
    },
    {
      "sha": "5e03622cb3fdc3a9d96a0cadb6dd4aad1e75ff43",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-05-19T14:53:40+00:00",
      "message": "improve(pipeline): do not extract embeddings in `SpeakerDiarization` pipeline when `max_speakers` is 1 (#1686)"
    },
    {
      "sha": "f1a6db2a2a02c0e80a3073027d1ae9b49d45b3c1",
      "author": "Purfview",
      "date": "2024-05-17T19:03:32+00:00",
      "message": "fix(doc): remove mention of unsupported `numpy.ndarray` waveform (#1691)"
    },
    {
      "sha": "5ae4c9b685feee02cbd58d25210e51def7037079",
      "author": "Herv\u00e9 BREDIN",
      "date": "2024-05-17T18:59:02+00:00",
      "message": "improve(io): use (faster) soundfile backend when available (#1711)"
    }
  ],
  "readme_text": "Using `pyannote.audio` open-source toolkit in production?  \nConsider switching to [pyannoteAI](https://www.pyannote.ai) for better and faster options.\n\n# `pyannote.audio` speaker diarization toolkit\n\n`pyannote.audio` is an open-source toolkit written in Python for speaker diarization. Based on [PyTorch](pytorch.org) machine learning framework, it comes with state-of-the-art [pretrained models and pipelines](https://hf.co/pyannote), that can be further finetuned to your own data for even better performance.\n\n<p align=\"center\">\n <a href=\"https://www.youtube.com/watch?v=37R_R82lfwA\"><img src=\"https://img.youtube.com/vi/37R_R82lfwA/0.jpg\"></a>\n</p>\n\n## TL;DR\n\n1. Install [`pyannote.audio`](https://github.com/pyannote/pyannote-audio) with `pip install pyannote.audio`\n2. Accept [`pyannote/segmentation-3.0`](https://hf.co/pyannote/segmentation-3.0) user conditions\n3. Accept [`pyannote/speaker-diarization-3.1`](https://hf.co/pyannote/speaker-diarization-3.1) user conditions\n4. Create access token at [`hf.co/settings/tokens`](https://hf.co/settings/tokens).\n\n```python\nfrom pyannote.audio import Pipeline\npipeline = Pipeline.from_pretrained(\n    \"pyannote/speaker-diarization-3.1\",\n    use_auth_token=\"HUGGINGFACE_ACCESS_TOKEN_GOES_HERE\")\n\n# send pipeline to GPU (when available)\nimport torch\npipeline.to(torch.device(\"cuda\"))\n\n# apply pretrained pipeline\ndiarization = pipeline(\"audio.wav\")\n\n# print the result\nfor turn, _, speaker in diarization.itertracks(yield_label=True):\n    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n# start=0.2s stop=1.5s speaker_0\n# start=1.8s stop=3.9s speaker_1\n# start=4.2s stop=5.7s speaker_0\n# ...\n```\n\n## Highlights\n\n- :hugs: pretrained [pipelines](https://hf.co/models?other=pyannote-audio-pipeline) (and [models](https://hf.co/models?other=pyannote-audio-model)) on [:hugs: model hub](https://huggingface.co/pyannote)\n- :exploding_head: state-of-the-art performance (see [Benchmark](#benchmark))\n- :snake: Python-first API\n- :zap: multi-GPU training with [pytorch-lightning](https://pytorchlightning.ai/)\n\n## Documentation\n\n- [Changelog](CHANGELOG.md)\n- [Frequently asked questions](FAQ.md)\n- Models\n  - Available tasks explained\n  - [Applying a pretrained model](tutorials/applying_a_model.ipynb)\n  - [Training, fine-tuning, and transfer learning](tutorials/training_a_model.ipynb)\n- Pipelines\n  - Available pipelines explained\n  - [Applying a pretrained pipeline](tutorials/applying_a_pipeline.ipynb)\n  - [Adapting a pretrained pipeline to your own data](tutorials/adapting_pretrained_pipeline.ipynb)\n  - [Training a pipeline](tutorials/voice_activity_detection.ipynb)\n- Contributing\n  - [Adding a new model](tutorials/add_your_own_model.ipynb)\n  - [Adding a new task](tutorials/add_your_own_task.ipynb)\n  - Adding a new pipeline\n  - Sharing pretrained models and pipelines\n- Blog\n  - 2022-12-02 > [\"How I reached 1st place at Ego4D 2022, 1st place at Albayzin 2022, and 6th place at VoxSRC 2022 speaker diarization challenges\"](tutorials/adapting_pretrained_pipeline.ipynb)\n  - 2022-10-23 > [\"One speaker segmentation model to rule them all\"](https://herve.niderb.fr/fastpages/2022/10/23/One-speaker-segmentation-model-to-rule-them-all)\n  - 2021-08-05 > [\"Streaming voice activity detection with pyannote.audio\"](https://herve.niderb.fr/fastpages/2021/08/05/Streaming-voice-activity-detection-with-pyannote.html)\n- Videos\n  - [Introduction to speaker diarization](https://umotion.univ-lemans.fr/video/9513-speech-segmentation-and-speaker-diarization/) / JSALT 2023 summer school / 90 min\n  - [Speaker segmentation model](https://www.youtube.com/watch?v=wDH2rvkjymY) / Interspeech 2021 / 3 min\n  - [First release of pyannote.audio](https://www.youtube.com/watch?v=37R_R82lfwA) / ICASSP 2020 / 8 min\n- Community contributions (not maintained by the core team)\n  - 2024-04-05 > [Offline speaker diarization (speaker-diarization-3.1)](tutorials/community/offline_usage_speaker_diarization.ipynb) by [Simon Ottenhaus](https://github.com/simonottenhauskenbun)\n\n## Benchmark\n\nOut of the box, `pyannote.audio` speaker diarization [pipeline](https://hf.co/pyannote/speaker-diarization-3.1) v3.1 is expected to be much better (and faster) than v2.x.\nThose numbers are diarization error rates (in %):\n\n| Benchmark                                                                                                                   | [v2.1](https://hf.co/pyannote/speaker-diarization-2.1) | [v3.1](https://hf.co/pyannote/speaker-diarization-3.1) | [pyannoteAI](https://www.pyannote.ai) |\n| --------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------ | ------------------------------------------------------ | ------------------------------------------------ |\n| [AISHELL-4](https://arxiv.org/abs/2104.03603)                                                                               | 14.1                                                   | 12.2                                                   | 11.9                                             |\n| [AliMeeting](https://www.openslr.org/119/) (channel 1)                                                                      | 27.4                                                   | 24.4                                                   | 22.5                                             |\n| [AMI](https://groups.inf.ed.ac.uk/ami/corpus/) (IHM)                                                                        | 18.9                                                   | 18.8                                                   | 16.6                                             |\n| [AMI](https://groups.inf.ed.ac.uk/ami/corpus/) (SDM)                                                                        | 27.1                                                   | 22.4                                                   | 20.9                                             |\n| [AVA-AVD](https://arxiv.org/abs/2111.14448)                                                                                 | 66.3                                                   | 50.0                                                   | 39.8                                             |\n| [CALLHOME](https://catalog.ldc.upenn.edu/LDC2001S97) ([part 2](https://github.com/BUTSpeechFIT/CALLHOME_sublists/issues/1)) | 31.6                                                   | 28.4                                                   | 22.2                                             |\n| [DIHARD 3](https://catalog.ldc.upenn.edu/LDC2022S14) ([full](https://arxiv.org/abs/2012.01477))                             | 26.9                                                   | 21.7                                                   | 17.2                                             |\n| [Earnings21](https://github.com/revdotcom/speech-datasets)                                                                  | 17.0                                                   | 9.4                                                    | 9.0                                              |\n| [Ego4D](https://arxiv.org/abs/2110.07058) (dev.)                                                                            | 61.5                                                   | 51.2                                                   | 43.8                                             |\n| [MSDWild](https://github.com/X-LANCE/MSDWILD)                                                                               | 32.8                                                   | 25.3                                                   | 19.8                                             |\n| [RAMC](https://www.openslr.org/123/)                                                                                        | 22.5                                                   | 22.2                                                   | 18.4                                             |\n| [REPERE](https://www.islrn.org/resources/360-758-359-485-0/) (phase2)                                                       | 8.2                                                    | 7.8                                                    | 7.6                                              |\n| [VoxConverse](https://github.com/joonson/voxconverse) (v0.3)                                                                | 11.2                                                   | 11.3                                                   | 9.4                                              |\n\n[Diarization error rate](http://pyannote.github.io/pyannote-metrics/reference.html#diarization) (in %)\n\n## Citations\n\nIf you use `pyannote.audio` please use the following citations:\n\n```bibtex\n@inproceedings{Plaquet23,\n  author={Alexis Plaquet and Herv\u00e9 Bredin},\n  title={{Powerset multi-class cross entropy loss for neural speaker diarization}},\n  year=2023,\n  booktitle={Proc. INTERSPEECH 2023},\n}\n```\n\n```bibtex\n@inproceedings{Bredin23,\n  author={Herv\u00e9 Bredin},\n  title={{pyannote.audio 2.1 speaker diarization pipeline: principle, benchmark, and recipe}},\n  year=2023,\n  booktitle={Proc. INTERSPEECH 2023},\n}\n```\n\n## Development\n\nThe commands below will setup pre-commit hooks and packages needed for developing the `pyannote.audio` library.\n\n```bash\npip install -e .[dev,testing]\npre-commit install\n```\n\n## Test\n\n```bash\npytest\n```\n",
  "external_links_in_readme": [
    "https://img.youtube.com/vi/37R_R82lfwA/0.jpg\"></a>",
    "https://catalog.ldc.upenn.edu/LDC2022S14",
    "https://www.pyannote.ai",
    "https://github.com/revdotcom/speech-datasets",
    "https://hf.co/pyannote/speaker-diarization-2.1",
    "https://hf.co/pyannote/segmentation-3.0",
    "https://www.openslr.org/119/",
    "https://www.openslr.org/123/",
    "https://github.com/BUTSpeechFIT/CALLHOME_sublists/issues/1",
    "https://hf.co/pyannote/speaker-diarization-3.1",
    "https://hf.co/models?other=pyannote-audio-pipeline",
    "https://hf.co/settings/tokens",
    "https://huggingface.co/pyannote",
    "https://herve.niderb.fr/fastpages/2022/10/23/One-speaker-segmentation-model-to-rule-them-all",
    "https://arxiv.org/abs/2110.07058",
    "https://github.com/X-LANCE/MSDWILD",
    "https://catalog.ldc.upenn.edu/LDC2001S97",
    "https://github.com/joonson/voxconverse",
    "https://github.com/simonottenhauskenbun",
    "https://groups.inf.ed.ac.uk/ami/corpus/",
    "https://www.youtube.com/watch?v=wDH2rvkjymY",
    "https://www.youtube.com/watch?v=37R_R82lfwA",
    "https://umotion.univ-lemans.fr/video/9513-speech-segmentation-and-speaker-diarization/",
    "https://arxiv.org/abs/2104.03603",
    "https://www.islrn.org/resources/360-758-359-485-0/",
    "https://hf.co/models?other=pyannote-audio-model",
    "https://arxiv.org/abs/2111.14448",
    "https://github.com/pyannote/pyannote-audio",
    "https://www.youtube.com/watch?v=37R_R82lfwA\"><img",
    "https://pytorchlightning.ai/",
    "https://arxiv.org/abs/2012.01477",
    "http://pyannote.github.io/pyannote-metrics/reference.html#diarization",
    "https://hf.co/pyannote",
    "https://herve.niderb.fr/fastpages/2021/08/05/Streaming-voice-activity-detection-with-pyannote.html"
  ]
}
```

</details>


---

