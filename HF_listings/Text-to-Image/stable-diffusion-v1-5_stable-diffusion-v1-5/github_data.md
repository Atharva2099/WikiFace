# GitHub Data for stable-diffusion-v1-5_stable-diffusion-v1-5

**Task Category:** Text-to-Image

## Repository 1: christophschuhmann/improved-aesthetic-predictor

# GitHub Repository Data

**Repository:** [christophschuhmann/improved-aesthetic-predictor](https://github.com/christophschuhmann/improved-aesthetic-predictor)

## Basic Information

- **Description:** CLIP+MLP Aesthetic Score Predictor
- **Created:** 2022-06-25T20:57:49+00:00
- **Last Updated:** 2025-06-20T11:46:36+00:00
- **Last Pushed:** 2024-07-01T11:58:57+00:00
- **Default Branch:** main
- **Size:** 10190 KB

## Statistics

- **Stars:** 1,116
- **Forks:** 102
- **Watchers:** 1,116
- **Open Issues:** 12
- **Total Issues:** 0
- **Pull Requests:** 6

## License

- **Type:** Apache License 2.0
- **SPDX ID:** Apache-2.0
- **URL:** [License](https://github.com/christophschuhmann/improved-aesthetic-predictor/blob/main/LICENSE)

## Languages

- **Python:** 14,738 bytes

## Top Contributors

1. **christophschuhmann** - 24 contributions

## File Structure (Sample of 10 files)

Total files: 10

- `F5WsLD0XoAAviiV (1).jpeg` (blob)
- `LICENSE` (blob)
- `README.md` (blob)
- `ava+logos-l14-linearMSE.pth` (blob)
- `ava+logos-l14-reluMSE.pth` (blob)
- `prepare-data-for-training.py` (blob)
- `sac+logos+ava1-l14-linearMSE.pth` (blob)
- `simple_inference.py` (blob)
- `train_predictor.py` (blob)
- `visulaize_100k_from_LAION400M.py` (blob)

## Recent Issues

- 游댮 **#16** add acc, precision, recall, f1 (closed)
- 游댮 **#15** Range of score values (closed)
- 游릭 **#14** TypeError: 'axis' must be None, an integer or a tuple of integers (open)
- 游릭 **#13** How to cite this work? (open)
- 游릭 **#12** Reproducing the scores in improved_aesthetics_6.5plus (open)

## Recent Pull Requests

- 游댮 **#16** add acc, precision, recall, f1 (closed)
- 游릭 **#10** Added requirements.txt and CPU only inference option (open)
- 游댮 **#8** Fix to run on M1 mac (closed)
- 游댮 **#7** Tool to automatically rank and extract either images or video frames using aesthetic prediction (closed)
- 游릭 **#4** docs: demo, experiments and live inference API on Tiyaro (open)

## Recent Commits

- **6934dd81** Add files via upload - Christoph Schuhmann (2023-10-12T18:37:26+00:00)
- **fe88a163** Update README.md - Christoph Schuhmann (2022-06-30T09:32:14+00:00)
- **d26e5881** Update README.md - Christoph Schuhmann (2022-06-30T09:31:13+00:00)
- **3a704177** Update simple_inference.py - Christoph Schuhmann (2022-06-30T09:28:58+00:00)
- **61f2f07a** Add files via upload - Christoph Schuhmann (2022-06-30T09:10:12+00:00)
- **97b252e8** Update train_predictor.py - Christoph Schuhmann (2022-06-26T08:46:31+00:00)
- **b2c9dcbb** Update simple_inference.py - Christoph Schuhmann (2022-06-26T08:45:20+00:00)
- **3fb50d40** Update visulaize_100k_from_LAION400M.py - Christoph Schuhmann (2022-06-26T08:44:49+00:00)
- **3ade56d7** Update simple_inference.py - Christoph Schuhmann (2022-06-26T08:43:28+00:00)
- **9f77db1c** Update train_predictor.py - Christoph Schuhmann (2022-06-26T08:42:40+00:00)

## External Links Found in README

- http://captions.christoph-schuhmann.de/aesthetic_viz_laion_sac+logos+ava1-l14-linearMSE-en-2.37B.html
- https://drive.google.com/drive/folders/186XiniJup5Rt9FXsHiAGWhgWz-nmCK_r?usp=sharing

## Raw Data

<details>
<summary>Click to expand raw JSON data</summary>

```json
{
  "id": 507415619,
  "name": "improved-aesthetic-predictor",
  "full_name": "christophschuhmann/improved-aesthetic-predictor",
  "description": "CLIP+MLP Aesthetic Score Predictor",
  "html_url": "https://github.com/christophschuhmann/improved-aesthetic-predictor",
  "clone_url": "https://github.com/christophschuhmann/improved-aesthetic-predictor.git",
  "ssh_url": "git@github.com:christophschuhmann/improved-aesthetic-predictor.git",
  "homepage": "",
  "topics": [],
  "default_branch": "main",
  "created_at": "2022-06-25T20:57:49+00:00",
  "updated_at": "2025-06-20T11:46:36+00:00",
  "pushed_at": "2024-07-01T11:58:57+00:00",
  "size_kb": 10190,
  "watchers_count": 1116,
  "stargazers_count": 1116,
  "forks_count": 102,
  "open_issues_count": 12,
  "license": {
    "key": "apache-2.0",
    "name": "Apache License 2.0",
    "spdx_id": "Apache-2.0",
    "url": "https://github.com/christophschuhmann/improved-aesthetic-predictor/blob/main/LICENSE"
  },
  "languages": {
    "Python": 14738
  },
  "top_contributors": [
    {
      "login": "christophschuhmann",
      "contributions": 24
    }
  ],
  "file_tree_count": 10,
  "file_tree_sample": [
    {
      "path": "F5WsLD0XoAAviiV (1).jpeg",
      "type": "blob"
    },
    {
      "path": "LICENSE",
      "type": "blob"
    },
    {
      "path": "README.md",
      "type": "blob"
    },
    {
      "path": "ava+logos-l14-linearMSE.pth",
      "type": "blob"
    },
    {
      "path": "ava+logos-l14-reluMSE.pth",
      "type": "blob"
    },
    {
      "path": "prepare-data-for-training.py",
      "type": "blob"
    },
    {
      "path": "sac+logos+ava1-l14-linearMSE.pth",
      "type": "blob"
    },
    {
      "path": "simple_inference.py",
      "type": "blob"
    },
    {
      "path": "train_predictor.py",
      "type": "blob"
    },
    {
      "path": "visulaize_100k_from_LAION400M.py",
      "type": "blob"
    }
  ],
  "issues_count": 0,
  "pulls_count": 6,
  "recent_issues": [
    {
      "number": 16,
      "title": "add acc, precision, recall, f1",
      "state": "closed"
    },
    {
      "number": 15,
      "title": "Range of score values",
      "state": "closed"
    },
    {
      "number": 14,
      "title": "TypeError: 'axis' must be None, an integer or a tuple of integers",
      "state": "open"
    },
    {
      "number": 13,
      "title": "How to cite this work?",
      "state": "open"
    },
    {
      "number": 12,
      "title": "Reproducing the scores in improved_aesthetics_6.5plus",
      "state": "open"
    }
  ],
  "recent_pulls": [
    {
      "number": 16,
      "title": "add acc, precision, recall, f1",
      "state": "closed"
    },
    {
      "number": 10,
      "title": "Added requirements.txt and CPU only inference option",
      "state": "open"
    },
    {
      "number": 8,
      "title": "Fix to run on M1 mac",
      "state": "closed"
    },
    {
      "number": 7,
      "title": "Tool to automatically rank and extract either images or video frames using aesthetic prediction",
      "state": "closed"
    },
    {
      "number": 4,
      "title": "docs: demo, experiments and live inference API on Tiyaro",
      "state": "open"
    }
  ],
  "recent_commits": [
    {
      "sha": "6934dd81792f086e613a121dbce43082cb8be85e",
      "author": "Christoph Schuhmann",
      "date": "2023-10-12T18:37:26+00:00",
      "message": "Add files via upload"
    },
    {
      "sha": "fe88a163f4661b4ddabba0751ff645e2e620746e",
      "author": "Christoph Schuhmann",
      "date": "2022-06-30T09:32:14+00:00",
      "message": "Update README.md"
    },
    {
      "sha": "d26e58810480bf07a86be3d3c7c0c334cdde805a",
      "author": "Christoph Schuhmann",
      "date": "2022-06-30T09:31:13+00:00",
      "message": "Update README.md"
    },
    {
      "sha": "3a704177ab3c1d159fe98b198ab2b69ff7d4bc1c",
      "author": "Christoph Schuhmann",
      "date": "2022-06-30T09:28:58+00:00",
      "message": "Update simple_inference.py"
    },
    {
      "sha": "61f2f07a2b16be5ffb40a10ba5adae4a74c9d0d9",
      "author": "Christoph Schuhmann",
      "date": "2022-06-30T09:10:12+00:00",
      "message": "Add files via upload"
    },
    {
      "sha": "97b252e8fd8028e1843bc32f88d6bbb694fe2fba",
      "author": "Christoph Schuhmann",
      "date": "2022-06-26T08:46:31+00:00",
      "message": "Update train_predictor.py"
    },
    {
      "sha": "b2c9dcbbd810b320adde7713a0bff6319a94eebe",
      "author": "Christoph Schuhmann",
      "date": "2022-06-26T08:45:20+00:00",
      "message": "Update simple_inference.py"
    },
    {
      "sha": "3fb50d401f1d56e19698e83f226d2d632424eeb6",
      "author": "Christoph Schuhmann",
      "date": "2022-06-26T08:44:49+00:00",
      "message": "Update visulaize_100k_from_LAION400M.py"
    },
    {
      "sha": "3ade56d79ad29c097eaf5c20f31ddd6131564539",
      "author": "Christoph Schuhmann",
      "date": "2022-06-26T08:43:28+00:00",
      "message": "Update simple_inference.py"
    },
    {
      "sha": "9f77db1c6042b709054b6db02d656a924e883eb3",
      "author": "Christoph Schuhmann",
      "date": "2022-06-26T08:42:40+00:00",
      "message": "Update train_predictor.py"
    },
    {
      "sha": "e688ed6d8ab4cfba30234e105c868e75585bfe1c",
      "author": "Christoph Schuhmann",
      "date": "2022-06-26T08:40:50+00:00",
      "message": "Update README.md"
    },
    {
      "sha": "5a5eaa42962835bcff9126b7e079033df25a3b76",
      "author": "Christoph Schuhmann",
      "date": "2022-06-26T08:32:13+00:00",
      "message": "Update README.md"
    },
    {
      "sha": "878b3a361a9a36c7c5c3b0028d1920fc24e891e0",
      "author": "Christoph Schuhmann",
      "date": "2022-06-26T08:31:49+00:00",
      "message": "Update README.md"
    },
    {
      "sha": "4929735b249f915e3454dfcb75a81382b4aa29ae",
      "author": "Christoph Schuhmann",
      "date": "2022-06-26T08:17:20+00:00",
      "message": "Update README.md"
    },
    {
      "sha": "e3364bde75be1f3f291de5bec849acfb0a130ef7",
      "author": "Christoph Schuhmann",
      "date": "2022-06-26T08:15:18+00:00",
      "message": "Create simple_inference.py"
    },
    {
      "sha": "810911f58b98da601ca7329c80e5b8020b40cb16",
      "author": "Christoph Schuhmann",
      "date": "2022-06-26T08:08:04+00:00",
      "message": "Rename avaclipmlp_inf_wds-relu.py to visulaize_100k_from_LAION400M.py"
    },
    {
      "sha": "33320a8e54215fcb7ea1ad5ccd2868abb18014f4",
      "author": "Christoph Schuhmann",
      "date": "2022-06-26T08:07:16+00:00",
      "message": "Update avaclipmlp_inf_wds-relu.py"
    },
    {
      "sha": "61a102c50d52c21ed63aed358f573f5c7fc2ae3a",
      "author": "Christoph Schuhmann",
      "date": "2022-06-26T07:54:02+00:00",
      "message": "Rename prep-logos-oai.py to prepare-data-for-training.py"
    },
    {
      "sha": "f23a829ffc70d320c2a51c12fe277735f407c9a6",
      "author": "Christoph Schuhmann",
      "date": "2022-06-26T07:52:50+00:00",
      "message": "Rename avalogoclip.py to train_predictor.py"
    },
    {
      "sha": "a7a6ed5962e39de1d769b71215dd994ee2e8bdf3",
      "author": "Christoph Schuhmann",
      "date": "2022-06-26T07:52:07+00:00",
      "message": "Update avalogoclip.py"
    }
  ],
  "readme_text": "# CLIP+MLP Aesthetic Score Predictor\n\nTrain, use and visualize an aesthetic score predictor ( how much people like on average an image ) based on a simple neural net that takes CLIP embeddings as inputs.\n\n\nLink to the AVA training data ( already prepared) :\nhttps://drive.google.com/drive/folders/186XiniJup5Rt9FXsHiAGWhgWz-nmCK_r?usp=sharing\n\n\nVisualizations of all images from LAION 5B (english subset with 2.37B images) in 40 buckets with the model sac+logos+ava1-l14-linearMSE.pth:\nhttp://captions.christoph-schuhmann.de/aesthetic_viz_laion_sac+logos+ava1-l14-linearMSE-en-2.37B.html\n\n\n",
  "external_links_in_readme": [
    "http://captions.christoph-schuhmann.de/aesthetic_viz_laion_sac+logos+ava1-l14-linearMSE-en-2.37B.html",
    "https://drive.google.com/drive/folders/186XiniJup5Rt9FXsHiAGWhgWz-nmCK_r?usp=sharing"
  ]
}
```

</details>


---

## Repository 2: huggingface/diffusers

# GitHub Repository Data

**Repository:** [huggingface/diffusers](https://github.com/huggingface/diffusers)

## Basic Information

- **Description:** 游뱅 Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch and FLAX.
- **Created:** 2022-05-30T16:04:02+00:00
- **Last Updated:** 2025-06-22T02:44:24+00:00
- **Last Pushed:** 2025-06-21T22:09:28+00:00
- **Default Branch:** main
- **Size:** 74451 KB

## Statistics

- **Stars:** 29,436
- **Forks:** 6,050
- **Watchers:** 29,436
- **Open Issues:** 700
- **Total Issues:** 0
- **Pull Requests:** 6,018

## License

- **Type:** Apache License 2.0
- **SPDX ID:** Apache-2.0
- **URL:** [License](https://github.com/huggingface/diffusers/blob/main/LICENSE)

## Languages

- **Python:** 21,990,626 bytes
- **Dockerfile:** 12,704 bytes
- **Makefile:** 2,782 bytes

## Topics

- `deep-learning`
- `diffusion`
- `image-generation`
- `pytorch`
- `score-based-generative-modeling`
- `image2image`
- `text2image`
- `stable-diffusion`
- `stable-diffusion-diffusers`
- `hacktoberfest`
- `flax`
- `jax`
- `latent-diffusion-models`
- `flux`
- `image2video`
- `text2video`
- `video2video`

## Top Contributors

1. **patrickvonplaten** - 1008 contributions
2. **sayakpaul** - 673 contributions
3. **patil-suraj** - 317 contributions
4. **DN6** - 268 contributions
5. **anton-l** - 253 contributions
6. **yiyixuxu** - 188 contributions
7. **a-r-r-o-w** - 161 contributions
8. **stevhliu** - 156 contributions
9. **pcuenca** - 151 contributions
10. **williamberman** - 123 contributions

## File Structure (Sample of 10 files)

Total files: 2,359

- `.github` (tree)
- `.github/ISSUE_TEMPLATE` (tree)
- `.github/ISSUE_TEMPLATE/bug-report.yml` (blob)
- `.github/ISSUE_TEMPLATE/config.yml` (blob)
- `.github/ISSUE_TEMPLATE/feature_request.md` (blob)
- `.github/ISSUE_TEMPLATE/feedback.md` (blob)
- `.github/ISSUE_TEMPLATE/new-model-addition.yml` (blob)
- `.github/ISSUE_TEMPLATE/remote-vae-pilot-feedback.yml` (blob)
- `.github/ISSUE_TEMPLATE/translate.md` (blob)
- `.github/PULL_REQUEST_TEMPLATE.md` (blob)

## Recent Issues

- 游릭 **#11765** Add `--lora_alpha` and metadata handling for `train_dreambooth_lora_hidream` (open)
- 游릭 **#11764** RepositoryNotFoundError on inpainting demo (open)
- 游릭 **#11763** Avoid creating tensor in CosmosAttnProcessor2_0 (#11761) (open)
- 游릭 **#11762** Could you help fix the backdoor vulnerability caused by two risky pre-trained models used in this repo? (open)
- 游릭 **#11761** Avoid creating tensor in CosmosAttnProcessor2_0 (open)

## Recent Pull Requests

- 游릭 **#11765** Add `--lora_alpha` and metadata handling for `train_dreambooth_lora_hidream` (open)
- 游릭 **#11763** Avoid creating tensor in CosmosAttnProcessor2_0 (#11761) (open)
- 游릭 **#11760** Follow up for Group Offload to Disk  (open)
- 游릭 **#11759** adjust to get CI test cases passed on XPU (open)
- 游릭 **#11758** [wip] enable FastPersist to (potentially) speed up disk saving in group offloading (open)

## Recent Commits

- **7fc53b5d** Fix dimensionalities in `apply_rotary_emb` functions' comments (#11717) - Tolga Cang칬z (2025-06-21T22:09:28+00:00)
- **0874dd04** [docs] LoRA scale scheduling (#11727) - Steven Liu (2025-06-20T17:15:29+00:00)
- **6184d8a4** [docs] device_map (#11711) - Steven Liu (2025-06-20T17:14:48+00:00)
- **5a6e3864** [docs] Quantization + torch.compile + offloading (#11703) - Steven Liu (2025-06-20T17:11:39+00:00)
- **42077e6c** Fix failing cpu offload test for LTX Latent Upscale (#11755) - Dhruv Nair (2025-06-20T04:07:34+00:00)
- **3d8d8485** fix invalid component handling behaviour in `PipelineQuantizationConfig` (#11750) - Sayak Paul (2025-06-20T02:24:12+00:00)
- **195926bb** Update Chroma Docs (#11753) - Dhruv Nair (2025-06-19T17:33:19+00:00)
- **85a916bb** make group offloading work with disk/nvme transfers (#11682) - Sayak Paul (2025-06-19T12:39:30+00:00)
- **3287ce28** Fix HiDream pipeline test module  (#11754) - Dhruv Nair (2025-06-19T11:36:14+00:00)
- **0c11c8c1** [CI] Fix SANA tests (#11756) - Dhruv Nair (2025-06-19T11:36:02+00:00)

## External Links Found in README

- https://github.com/huggingface/diffusers/issues
- https://huggingface.co/lllyasviel/sd-controlnet-canny">
- https://github.com/huggingface/diffusers}}
- https://github.com/huggingface/diffusers/releases"><img
- https://huggingface.co/docs/diffusers/api/schedulers/overview
- https://huggingface.co/docs/diffusers/training/overview
- https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22
- https://pepy.tech/project/diffusers"><img
- https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22New+pipeline%2Fmodel%22
- https://huggingface.co/models?library=diffusers&sort=downloads
- https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/image_variation">Stable
- https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/inpaint">Stable
- https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22New+scheduler%22
- https://huggingface.co/runwayml/stable-diffusion-inpainting">
- https://huggingface.co/docs/diffusers/api/pipelines/kandinsky">Kandinsky</a></td>
- https://huggingface.co/docs/diffusers/conceptual/philosophy#simple-over-easy
- https://github.com/microsoft/TaskMatrix
- https://github.com/Sanster/lama-cleaner
- https://github.com/deep-floyd/IF
- https://discord.gg/G7tWnz98XR"><img

## Raw Data

<details>
<summary>Click to expand raw JSON data</summary>

```json
{
  "id": 498011141,
  "name": "diffusers",
  "full_name": "huggingface/diffusers",
  "description": "\ud83e\udd17 Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch and FLAX.",
  "html_url": "https://github.com/huggingface/diffusers",
  "clone_url": "https://github.com/huggingface/diffusers.git",
  "ssh_url": "git@github.com:huggingface/diffusers.git",
  "homepage": "https://huggingface.co/docs/diffusers",
  "topics": [
    "deep-learning",
    "diffusion",
    "image-generation",
    "pytorch",
    "score-based-generative-modeling",
    "image2image",
    "text2image",
    "stable-diffusion",
    "stable-diffusion-diffusers",
    "hacktoberfest",
    "flax",
    "jax",
    "latent-diffusion-models",
    "flux",
    "image2video",
    "text2video",
    "video2video"
  ],
  "default_branch": "main",
  "created_at": "2022-05-30T16:04:02+00:00",
  "updated_at": "2025-06-22T02:44:24+00:00",
  "pushed_at": "2025-06-21T22:09:28+00:00",
  "size_kb": 74451,
  "watchers_count": 29436,
  "stargazers_count": 29436,
  "forks_count": 6050,
  "open_issues_count": 700,
  "license": {
    "key": "apache-2.0",
    "name": "Apache License 2.0",
    "spdx_id": "Apache-2.0",
    "url": "https://github.com/huggingface/diffusers/blob/main/LICENSE"
  },
  "languages": {
    "Python": 21990626,
    "Dockerfile": 12704,
    "Makefile": 2782
  },
  "top_contributors": [
    {
      "login": "patrickvonplaten",
      "contributions": 1008
    },
    {
      "login": "sayakpaul",
      "contributions": 673
    },
    {
      "login": "patil-suraj",
      "contributions": 317
    },
    {
      "login": "DN6",
      "contributions": 268
    },
    {
      "login": "anton-l",
      "contributions": 253
    },
    {
      "login": "yiyixuxu",
      "contributions": 188
    },
    {
      "login": "a-r-r-o-w",
      "contributions": 161
    },
    {
      "login": "stevhliu",
      "contributions": 156
    },
    {
      "login": "pcuenca",
      "contributions": 151
    },
    {
      "login": "williamberman",
      "contributions": 123
    },
    {
      "login": "hlky",
      "contributions": 110
    },
    {
      "login": "tolgacangoz",
      "contributions": 102
    },
    {
      "login": "linoytsaban",
      "contributions": 58
    },
    {
      "login": "kashif",
      "contributions": 51
    },
    {
      "login": "yao-matrix",
      "contributions": 30
    },
    {
      "login": "dg845",
      "contributions": 30
    },
    {
      "login": "asomoza",
      "contributions": 29
    },
    {
      "login": "apolinario",
      "contributions": 26
    },
    {
      "login": "younesbelkada",
      "contributions": 23
    },
    {
      "login": "Wauplin",
      "contributions": 23
    }
  ],
  "file_tree_count": 2359,
  "file_tree_sample": [
    {
      "path": ".github",
      "type": "tree"
    },
    {
      "path": ".github/ISSUE_TEMPLATE",
      "type": "tree"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/bug-report.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/config.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/feature_request.md",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/feedback.md",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/new-model-addition.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/remote-vae-pilot-feedback.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/translate.md",
      "type": "blob"
    },
    {
      "path": ".github/PULL_REQUEST_TEMPLATE.md",
      "type": "blob"
    }
  ],
  "issues_count": 0,
  "pulls_count": 6018,
  "recent_issues": [
    {
      "number": 11765,
      "title": "Add `--lora_alpha` and metadata handling for `train_dreambooth_lora_hidream`",
      "state": "open"
    },
    {
      "number": 11764,
      "title": "RepositoryNotFoundError on inpainting demo",
      "state": "open"
    },
    {
      "number": 11763,
      "title": "Avoid creating tensor in CosmosAttnProcessor2_0 (#11761)",
      "state": "open"
    },
    {
      "number": 11762,
      "title": "Could you help fix the backdoor vulnerability caused by two risky pre-trained models used in this repo?",
      "state": "open"
    },
    {
      "number": 11761,
      "title": "Avoid creating tensor in CosmosAttnProcessor2_0",
      "state": "open"
    }
  ],
  "recent_pulls": [
    {
      "number": 11765,
      "title": "Add `--lora_alpha` and metadata handling for `train_dreambooth_lora_hidream`",
      "state": "open"
    },
    {
      "number": 11763,
      "title": "Avoid creating tensor in CosmosAttnProcessor2_0 (#11761)",
      "state": "open"
    },
    {
      "number": 11760,
      "title": "Follow up for Group Offload to Disk ",
      "state": "open"
    },
    {
      "number": 11759,
      "title": "adjust to get CI test cases passed on XPU",
      "state": "open"
    },
    {
      "number": 11758,
      "title": "[wip] enable FastPersist to (potentially) speed up disk saving in group offloading",
      "state": "open"
    }
  ],
  "recent_commits": [
    {
      "sha": "7fc53b5d66867f9e59398f5a14dd3dd9fbc700dd",
      "author": "Tolga Cang\u00f6z",
      "date": "2025-06-21T22:09:28+00:00",
      "message": "Fix dimensionalities in `apply_rotary_emb` functions' comments (#11717)"
    },
    {
      "sha": "0874dd04dc1bb359053935109dc95483218b086f",
      "author": "Steven Liu",
      "date": "2025-06-20T17:15:29+00:00",
      "message": "[docs] LoRA scale scheduling (#11727)"
    },
    {
      "sha": "6184d8a43357f3397c0848b5d0b716cf389d1f30",
      "author": "Steven Liu",
      "date": "2025-06-20T17:14:48+00:00",
      "message": "[docs] device_map (#11711)"
    },
    {
      "sha": "5a6e386464bf7c57fa93e359930366933b3ec337",
      "author": "Steven Liu",
      "date": "2025-06-20T17:11:39+00:00",
      "message": "[docs] Quantization + torch.compile + offloading (#11703)"
    },
    {
      "sha": "42077e6c734df2fc7bbed373abceab99635500ad",
      "author": "Dhruv Nair",
      "date": "2025-06-20T04:07:34+00:00",
      "message": "Fix failing cpu offload test for LTX Latent Upscale (#11755)"
    },
    {
      "sha": "3d8d8485fccc2c26f90efefb93d47e0d2b864472",
      "author": "Sayak Paul",
      "date": "2025-06-20T02:24:12+00:00",
      "message": "fix invalid component handling behaviour in `PipelineQuantizationConfig` (#11750)"
    },
    {
      "sha": "195926bbdc69d20d442179b2fe96023edc751212",
      "author": "Dhruv Nair",
      "date": "2025-06-19T17:33:19+00:00",
      "message": "Update Chroma Docs (#11753)"
    },
    {
      "sha": "85a916bb8b2260d94014e15f096614c1c9f44d04",
      "author": "Sayak Paul",
      "date": "2025-06-19T12:39:30+00:00",
      "message": "make group offloading work with disk/nvme transfers (#11682)"
    },
    {
      "sha": "3287ce2890caeff7d7c5279cde24564282f05441",
      "author": "Dhruv Nair",
      "date": "2025-06-19T11:36:14+00:00",
      "message": "Fix HiDream pipeline test module  (#11754)"
    },
    {
      "sha": "0c11c8c1ac4c3520fefaa3e36638634a5d69b790",
      "author": "Dhruv Nair",
      "date": "2025-06-19T11:36:02+00:00",
      "message": "[CI] Fix SANA tests (#11756)"
    },
    {
      "sha": "fc51583c8afc066a29641c23bfbe3ccb2f43853f",
      "author": "Dhruv Nair",
      "date": "2025-06-19T11:33:12+00:00",
      "message": "[CI] Fix WAN VACE tests (#11757)"
    },
    {
      "sha": "fb57c76aa1972a0ef372b5dc2b012bc66af6ac78",
      "author": "Sayak Paul",
      "date": "2025-06-19T07:36:25+00:00",
      "message": "[LoRA] refactor lora loading at the model-level (#11719)"
    },
    {
      "sha": "7251bb4fd0cdf7dfad405ff268ccfe2c7455fdaf",
      "author": "dependabot[bot]",
      "date": "2025-06-19T05:39:33+00:00",
      "message": "Bump urllib3 from 2.2.3 to 2.5.0 in /examples/server (#11748)"
    },
    {
      "sha": "3fba74e15305d86ce285e8616714156f43c8efd8",
      "author": "Aryan",
      "date": "2025-06-19T02:37:47+00:00",
      "message": "Add missing HiDream license (#11747)"
    },
    {
      "sha": "a4df8dbc40e170ff828f8d8f79c2c861c9f1748d",
      "author": "Aryan",
      "date": "2025-06-19T02:16:01+00:00",
      "message": "Update more licenses to 2025 (#11746)"
    },
    {
      "sha": "48eae6f4204dbdca26e6c1f0c8dc64caa0e48f08",
      "author": "Sayak Paul",
      "date": "2025-06-19T02:15:06+00:00",
      "message": "[Quantizers] add `is_compileable` property to quantizers. (#11736)"
    },
    {
      "sha": "66394bf6c798a93a1e9536dac4999f77b690174c",
      "author": "Dhruv Nair",
      "date": "2025-06-18T16:54:41+00:00",
      "message": "Chroma Follow Up  (#11725)"
    },
    {
      "sha": "62cce3045d6710e9cd68869ac8391867e326928b",
      "author": "Sayak Paul",
      "date": "2025-06-18T15:26:00+00:00",
      "message": "[chore] change to 2025 licensing for remaining (#11741)"
    },
    {
      "sha": "05e867784ddb873d909a9a5cce8ee0f32eb6840d",
      "author": "Sayak Paul",
      "date": "2025-06-18T05:22:06+00:00",
      "message": "[tests] device_map tests for all models. (#11708)"
    },
    {
      "sha": "d72184eba358b883d7186a0a96dedd8118fcb72a",
      "author": "Leo Jiang",
      "date": "2025-06-18T03:56:02+00:00",
      "message": "[training] add ds support to lora hidream (#11737)"
    }
  ],
  "readme_text": "<!---\nCopyright 2022 - The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n-->\n\n<p align=\"center\">\n    <br>\n    <img src=\"https://raw.githubusercontent.com/huggingface/diffusers/main/docs/source/en/imgs/diffusers_library.jpg\" width=\"400\"/>\n    <br>\n<p>\n<p align=\"center\">\n    <a href=\"https://github.com/huggingface/diffusers/blob/main/LICENSE\"><img alt=\"GitHub\" src=\"https://img.shields.io/github/license/huggingface/datasets.svg?color=blue\"></a>\n    <a href=\"https://github.com/huggingface/diffusers/releases\"><img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/huggingface/diffusers.svg\"></a>\n    <a href=\"https://pepy.tech/project/diffusers\"><img alt=\"GitHub release\" src=\"https://static.pepy.tech/badge/diffusers/month\"></a>\n    <a href=\"CODE_OF_CONDUCT.md\"><img alt=\"Contributor Covenant\" src=\"https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg\"></a>\n    <a href=\"https://twitter.com/diffuserslib\"><img alt=\"X account\" src=\"https://img.shields.io/twitter/url/https/twitter.com/diffuserslib.svg?style=social&label=Follow%20%40diffuserslib\"></a>\n</p>\n\n\ud83e\udd17 Diffusers is the go-to library for state-of-the-art pretrained diffusion models for generating images, audio, and even 3D structures of molecules. Whether you're looking for a simple inference solution or training your own diffusion models, \ud83e\udd17 Diffusers is a modular toolbox that supports both. Our library is designed with a focus on [usability over performance](https://huggingface.co/docs/diffusers/conceptual/philosophy#usability-over-performance), [simple over easy](https://huggingface.co/docs/diffusers/conceptual/philosophy#simple-over-easy), and [customizability over abstractions](https://huggingface.co/docs/diffusers/conceptual/philosophy#tweakable-contributorfriendly-over-abstraction).\n\n\ud83e\udd17 Diffusers offers three core components:\n\n- State-of-the-art [diffusion pipelines](https://huggingface.co/docs/diffusers/api/pipelines/overview) that can be run in inference with just a few lines of code.\n- Interchangeable noise [schedulers](https://huggingface.co/docs/diffusers/api/schedulers/overview) for different diffusion speeds and output quality.\n- Pretrained [models](https://huggingface.co/docs/diffusers/api/models/overview) that can be used as building blocks, and combined with schedulers, for creating your own end-to-end diffusion systems.\n\n## Installation\n\nWe recommend installing \ud83e\udd17 Diffusers in a virtual environment from PyPI or Conda. For more details about installing [PyTorch](https://pytorch.org/get-started/locally/) and [Flax](https://flax.readthedocs.io/en/latest/#installation), please refer to their official documentation.\n\n### PyTorch\n\nWith `pip` (official package):\n\n```bash\npip install --upgrade diffusers[torch]\n```\n\nWith `conda` (maintained by the community):\n\n```sh\nconda install -c conda-forge diffusers\n```\n\n### Flax\n\nWith `pip` (official package):\n\n```bash\npip install --upgrade diffusers[flax]\n```\n\n### Apple Silicon (M1/M2) support\n\nPlease refer to the [How to use Stable Diffusion in Apple Silicon](https://huggingface.co/docs/diffusers/optimization/mps) guide.\n\n## Quickstart\n\nGenerating outputs is super easy with \ud83e\udd17 Diffusers. To generate an image from text, use the `from_pretrained` method to load any pretrained diffusion model (browse the [Hub](https://huggingface.co/models?library=diffusers&sort=downloads) for 30,000+ checkpoints):\n\n```python\nfrom diffusers import DiffusionPipeline\nimport torch\n\npipeline = DiffusionPipeline.from_pretrained(\"stable-diffusion-v1-5/stable-diffusion-v1-5\", torch_dtype=torch.float16)\npipeline.to(\"cuda\")\npipeline(\"An image of a squirrel in Picasso style\").images[0]\n```\n\nYou can also dig into the models and schedulers toolbox to build your own diffusion system:\n\n```python\nfrom diffusers import DDPMScheduler, UNet2DModel\nfrom PIL import Image\nimport torch\n\nscheduler = DDPMScheduler.from_pretrained(\"google/ddpm-cat-256\")\nmodel = UNet2DModel.from_pretrained(\"google/ddpm-cat-256\").to(\"cuda\")\nscheduler.set_timesteps(50)\n\nsample_size = model.config.sample_size\nnoise = torch.randn((1, 3, sample_size, sample_size), device=\"cuda\")\ninput = noise\n\nfor t in scheduler.timesteps:\n    with torch.no_grad():\n        noisy_residual = model(input, t).sample\n        prev_noisy_sample = scheduler.step(noisy_residual, t, input).prev_sample\n        input = prev_noisy_sample\n\nimage = (input / 2 + 0.5).clamp(0, 1)\nimage = image.cpu().permute(0, 2, 3, 1).numpy()[0]\nimage = Image.fromarray((image * 255).round().astype(\"uint8\"))\nimage\n```\n\nCheck out the [Quickstart](https://huggingface.co/docs/diffusers/quicktour) to launch your diffusion journey today!\n\n## How to navigate the documentation\n\n| **Documentation**                                                   | **What can I learn?**                                                                                                                                                                           |\n|---------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [Tutorial](https://huggingface.co/docs/diffusers/tutorials/tutorial_overview)                                                            | A basic crash course for learning how to use the library's most important features like using models and schedulers to build your own diffusion system, and training your own diffusion model.  |\n| [Loading](https://huggingface.co/docs/diffusers/using-diffusers/loading)                                                             | Guides for how to load and configure all the components (pipelines, models, and schedulers) of the library, as well as how to use different schedulers.                                         |\n| [Pipelines for inference](https://huggingface.co/docs/diffusers/using-diffusers/overview_techniques)                                             | Guides for how to use pipelines for different inference tasks, batched generation, controlling generated outputs and randomness, and how to contribute a pipeline to the library.               |\n| [Optimization](https://huggingface.co/docs/diffusers/optimization/fp16)                                                        | Guides for how to optimize your diffusion model to run faster and consume less memory.                                                                                                          |\n| [Training](https://huggingface.co/docs/diffusers/training/overview) | Guides for how to train a diffusion model for different tasks with different training techniques.                                                                                               |\n## Contribution\n\nWe \u2764\ufe0f  contributions from the open-source community!\nIf you want to contribute to this library, please check out our [Contribution guide](https://github.com/huggingface/diffusers/blob/main/CONTRIBUTING.md).\nYou can look out for [issues](https://github.com/huggingface/diffusers/issues) you'd like to tackle to contribute to the library.\n- See [Good first issues](https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22) for general opportunities to contribute\n- See [New model/pipeline](https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22New+pipeline%2Fmodel%22) to contribute exciting new diffusion models / diffusion pipelines\n- See [New scheduler](https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22New+scheduler%22)\n\nAlso, say \ud83d\udc4b in our public Discord channel <a href=\"https://discord.gg/G7tWnz98XR\"><img alt=\"Join us on Discord\" src=\"https://img.shields.io/discord/823813159592001537?color=5865F2&logo=discord&logoColor=white\"></a>. We discuss the hottest trends about diffusion models, help each other with contributions, personal projects or just hang out \u2615.\n\n\n## Popular Tasks & Pipelines\n\n<table>\n  <tr>\n    <th>Task</th>\n    <th>Pipeline</th>\n    <th>\ud83e\udd17 Hub</th>\n  </tr>\n  <tr style=\"border-top: 2px solid black\">\n    <td>Unconditional Image Generation</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/ddpm\"> DDPM </a></td>\n    <td><a href=\"https://huggingface.co/google/ddpm-ema-church-256\"> google/ddpm-ema-church-256 </a></td>\n  </tr>\n  <tr style=\"border-top: 2px solid black\">\n    <td>Text-to-Image</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img\">Stable Diffusion Text-to-Image</a></td>\n      <td><a href=\"https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5\"> stable-diffusion-v1-5/stable-diffusion-v1-5 </a></td>\n  </tr>\n  <tr>\n    <td>Text-to-Image</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/unclip\">unCLIP</a></td>\n      <td><a href=\"https://huggingface.co/kakaobrain/karlo-v1-alpha\"> kakaobrain/karlo-v1-alpha </a></td>\n  </tr>\n  <tr>\n    <td>Text-to-Image</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/deepfloyd_if\">DeepFloyd IF</a></td>\n      <td><a href=\"https://huggingface.co/DeepFloyd/IF-I-XL-v1.0\"> DeepFloyd/IF-I-XL-v1.0 </a></td>\n  </tr>\n  <tr>\n    <td>Text-to-Image</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/kandinsky\">Kandinsky</a></td>\n      <td><a href=\"https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder\"> kandinsky-community/kandinsky-2-2-decoder </a></td>\n  </tr>\n  <tr style=\"border-top: 2px solid black\">\n    <td>Text-guided Image-to-Image</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/controlnet\">ControlNet</a></td>\n      <td><a href=\"https://huggingface.co/lllyasviel/sd-controlnet-canny\"> lllyasviel/sd-controlnet-canny </a></td>\n  </tr>\n  <tr>\n    <td>Text-guided Image-to-Image</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/pix2pix\">InstructPix2Pix</a></td>\n      <td><a href=\"https://huggingface.co/timbrooks/instruct-pix2pix\"> timbrooks/instruct-pix2pix </a></td>\n  </tr>\n  <tr>\n    <td>Text-guided Image-to-Image</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/img2img\">Stable Diffusion Image-to-Image</a></td>\n      <td><a href=\"https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5\"> stable-diffusion-v1-5/stable-diffusion-v1-5 </a></td>\n  </tr>\n  <tr style=\"border-top: 2px solid black\">\n    <td>Text-guided Image Inpainting</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/inpaint\">Stable Diffusion Inpainting</a></td>\n      <td><a href=\"https://huggingface.co/runwayml/stable-diffusion-inpainting\"> runwayml/stable-diffusion-inpainting </a></td>\n  </tr>\n  <tr style=\"border-top: 2px solid black\">\n    <td>Image Variation</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/image_variation\">Stable Diffusion Image Variation</a></td>\n      <td><a href=\"https://huggingface.co/lambdalabs/sd-image-variations-diffusers\"> lambdalabs/sd-image-variations-diffusers </a></td>\n  </tr>\n  <tr style=\"border-top: 2px solid black\">\n    <td>Super Resolution</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/upscale\">Stable Diffusion Upscale</a></td>\n      <td><a href=\"https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler\"> stabilityai/stable-diffusion-x4-upscaler </a></td>\n  </tr>\n  <tr>\n    <td>Super Resolution</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/latent_upscale\">Stable Diffusion Latent Upscale</a></td>\n      <td><a href=\"https://huggingface.co/stabilityai/sd-x2-latent-upscaler\"> stabilityai/sd-x2-latent-upscaler </a></td>\n  </tr>\n</table>\n\n## Popular libraries using \ud83e\udde8 Diffusers\n\n- https://github.com/microsoft/TaskMatrix\n- https://github.com/invoke-ai/InvokeAI\n- https://github.com/InstantID/InstantID\n- https://github.com/apple/ml-stable-diffusion\n- https://github.com/Sanster/lama-cleaner\n- https://github.com/IDEA-Research/Grounded-Segment-Anything\n- https://github.com/ashawkey/stable-dreamfusion\n- https://github.com/deep-floyd/IF\n- https://github.com/bentoml/BentoML\n- https://github.com/bmaltais/kohya_ss\n- +14,000 other amazing GitHub repositories \ud83d\udcaa\n\nThank you for using us \u2764\ufe0f.\n\n## Credits\n\nThis library concretizes previous work by many different authors and would not have been possible without their great research and implementations. We'd like to thank, in particular, the following implementations which have helped us in our development and without which the API could not have been as polished today:\n\n- @CompVis' latent diffusion models library, available [here](https://github.com/CompVis/latent-diffusion)\n- @hojonathanho original DDPM implementation, available [here](https://github.com/hojonathanho/diffusion) as well as the extremely useful translation into PyTorch by @pesser, available [here](https://github.com/pesser/pytorch_diffusion)\n- @ermongroup's DDIM implementation, available [here](https://github.com/ermongroup/ddim)\n- @yang-song's Score-VE and Score-VP implementations, available [here](https://github.com/yang-song/score_sde_pytorch)\n\nWe also want to thank @heejkoo for the very helpful overview of papers, code and resources on diffusion models, available [here](https://github.com/heejkoo/Awesome-Diffusion-Models) as well as @crowsonkb and @rromb for useful discussions and insights.\n\n## Citation\n\n```bibtex\n@misc{von-platen-etal-2022-diffusers,\n  author = {Patrick von Platen and Suraj Patil and Anton Lozhkov and Pedro Cuenca and Nathan Lambert and Kashif Rasul and Mishig Davaadorj and Dhruv Nair and Sayak Paul and William Berman and Yiyi Xu and Steven Liu and Thomas Wolf},\n  title = {Diffusers: State-of-the-art diffusion models},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/huggingface/diffusers}}\n}\n```\n",
  "external_links_in_readme": [
    "https://github.com/huggingface/diffusers/issues",
    "https://huggingface.co/lllyasviel/sd-controlnet-canny\">",
    "https://github.com/huggingface/diffusers}}",
    "https://github.com/huggingface/diffusers/releases\"><img",
    "https://huggingface.co/docs/diffusers/api/schedulers/overview",
    "https://huggingface.co/docs/diffusers/training/overview",
    "https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22",
    "https://pepy.tech/project/diffusers\"><img",
    "https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22New+pipeline%2Fmodel%22",
    "https://huggingface.co/models?library=diffusers&sort=downloads",
    "https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/image_variation\">Stable",
    "https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/inpaint\">Stable",
    "https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22New+scheduler%22",
    "https://huggingface.co/runwayml/stable-diffusion-inpainting\">",
    "https://huggingface.co/docs/diffusers/api/pipelines/kandinsky\">Kandinsky</a></td>",
    "https://huggingface.co/docs/diffusers/conceptual/philosophy#simple-over-easy",
    "https://github.com/microsoft/TaskMatrix",
    "https://github.com/Sanster/lama-cleaner",
    "https://github.com/deep-floyd/IF",
    "https://discord.gg/G7tWnz98XR\"><img",
    "https://github.com/pesser/pytorch_diffusion",
    "https://github.com/InstantID/InstantID",
    "https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img\">Stable",
    "https://huggingface.co/docs/diffusers/api/pipelines/controlnet\">ControlNet</a></td>",
    "https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler\">",
    "https://huggingface.co/docs/diffusers/api/pipelines/overview",
    "https://huggingface.co/docs/diffusers/conceptual/philosophy#usability-over-performance",
    "https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder\">",
    "https://github.com/invoke-ai/InvokeAI",
    "https://img.shields.io/github/release/huggingface/diffusers.svg\"></a>",
    "https://github.com/bentoml/BentoML",
    "https://huggingface.co/timbrooks/instruct-pix2pix\">",
    "https://huggingface.co/google/ddpm-ema-church-256\">",
    "https://github.com/IDEA-Research/Grounded-Segment-Anything",
    "https://github.com/heejkoo/Awesome-Diffusion-Models",
    "https://github.com/huggingface/diffusers/blob/main/CONTRIBUTING.md",
    "https://twitter.com/diffuserslib\"><img",
    "https://huggingface.co/DeepFloyd/IF-I-XL-v1.0\">",
    "https://static.pepy.tech/badge/diffusers/month\"></a>",
    "https://github.com/bmaltais/kohya_ss",
    "https://huggingface.co/kakaobrain/karlo-v1-alpha\">",
    "https://huggingface.co/docs/diffusers/using-diffusers/overview_techniques",
    "https://github.com/apple/ml-stable-diffusion",
    "https://huggingface.co/docs/diffusers/quicktour",
    "https://github.com/ashawkey/stable-dreamfusion",
    "https://raw.githubusercontent.com/huggingface/diffusers/main/docs/source/en/imgs/diffusers_library.jpg\"",
    "https://img.shields.io/discord/823813159592001537?color=5865F2&logo=discord&logoColor=white\"></a>.",
    "https://huggingface.co/docs/diffusers/optimization/fp16",
    "https://github.com/huggingface/diffusers/blob/main/LICENSE\"><img",
    "https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg\"></a>",
    "https://github.com/hojonathanho/diffusion",
    "https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/latent_upscale\">Stable",
    "https://huggingface.co/docs/diffusers/api/pipelines/deepfloyd_if\">DeepFloyd",
    "https://huggingface.co/docs/diffusers/using-diffusers/loading",
    "https://flax.readthedocs.io/en/latest/#installation",
    "https://huggingface.co/docs/diffusers/optimization/mps",
    "https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/upscale\">Stable",
    "https://github.com/ermongroup/ddim",
    "https://pytorch.org/get-started/locally/",
    "https://huggingface.co/docs/diffusers/api/models/overview",
    "https://huggingface.co/docs/diffusers/conceptual/philosophy#tweakable-contributorfriendly-over-abstraction",
    "https://huggingface.co/stabilityai/sd-x2-latent-upscaler\">",
    "https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/img2img\">Stable",
    "https://github.com/CompVis/latent-diffusion",
    "https://huggingface.co/docs/diffusers/api/pipelines/pix2pix\">InstructPix2Pix</a></td>",
    "https://huggingface.co/lambdalabs/sd-image-variations-diffusers\">",
    "https://huggingface.co/docs/diffusers/api/pipelines/ddpm\">",
    "http://www.apache.org/licenses/LICENSE-2.0",
    "https://img.shields.io/github/license/huggingface/datasets.svg?color=blue\"></a>",
    "https://img.shields.io/twitter/url/https/twitter.com/diffuserslib.svg?style=social&label=Follow%20%40diffuserslib\"></a>",
    "https://github.com/yang-song/score_sde_pytorch",
    "https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5\">",
    "https://huggingface.co/docs/diffusers/api/pipelines/unclip\">unCLIP</a></td>",
    "https://huggingface.co/docs/diffusers/tutorials/tutorial_overview"
  ]
}
```

</details>


---

## Repository 3: runwayml/stable-diffusion

# GitHub Data Extraction Error

Error: 404 {"message": "Not Found", "documentation_url": "https://docs.github.com/rest/repos/repos#get-a-repository", "status": "404"}

Repository: https://github.com/runwayml/stable-diffusion

---

## Repository 4: CompVis/stable-diffusion

# GitHub Repository Data

**Repository:** [CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion)

## Basic Information

- **Description:** A latent text-to-image diffusion model
- **Created:** 2022-08-10T14:36:44+00:00
- **Last Updated:** 2025-06-22T01:19:50+00:00
- **Last Pushed:** 2024-06-18T01:53:49+00:00
- **Default Branch:** main
- **Size:** 43676 KB

## Statistics

- **Stars:** 70,977
- **Forks:** 10,461
- **Watchers:** 70,977
- **Open Issues:** 604
- **Total Issues:** 0
- **Pull Requests:** 156

## License

- **Type:** Other
- **SPDX ID:** NOASSERTION
- **URL:** [License](https://github.com/CompVis/stable-diffusion/blob/main/LICENSE)

## Languages

- **Jupyter Notebook:** 4,172,390 bytes
- **Python:** 520,234 bytes
- **Shell:** 3,005 bytes

## Top Contributors

1. **rromb** - 9 contributions
2. **pesser** - 7 contributions
3. **patrickvonplaten** - 6 contributions
4. **LuChengTHU** - 2 contributions
5. **owenvincent** - 2 contributions
6. **apolinario** - 1 contributions
7. **cpacker** - 1 contributions

## File Structure (Sample of 10 files)

Total files: 187

- `LICENSE` (blob)
- `README.md` (blob)
- `Stable_Diffusion_v1_Model_Card.md` (blob)
- `assets` (tree)
- `assets/a-painting-of-a-fire.png` (blob)
- `assets/a-photograph-of-a-fire.png` (blob)
- `assets/a-shirt-with-a-fire-printed-on-it.png` (blob)
- `assets/a-shirt-with-the-inscription-'fire'.png` (blob)
- `assets/a-watercolor-painting-of-a-fire.png` (blob)
- `assets/birdhouse.png` (blob)

## Recent Issues

- 游릭 **#896** Create urimage (open)
- 游댮 **#895** Create Abella danger (closed)
- 游댮 **#894** Codespace refactored trout pj76644xx6grfrv5r (closed)
- 游댮 **#893** Implementation of rope and alibi (closed)
- 游릭 **#892** Bounded attention (open)

## Recent Pull Requests

- 游릭 **#896** Create urimage (open)
- 游댮 **#895** Create Abella danger (closed)
- 游댮 **#894** Codespace refactored trout pj76644xx6grfrv5r (closed)
- 游댮 **#893** Implementation of rope and alibi (closed)
- 游릭 **#892** Bounded attention (open)

## Recent Commits

- **21f890f9** Update sampler.py - Robin Rombach (2022-11-16T20:34:06+00:00)
- **5a00c4f8** Merge pull request #440 from LuChengTHU/main - Robin Rombach (2022-11-16T11:51:43+00:00)
- **bf3b8783** add a stablizing trick for steps < 15 - LuChengTHU (2022-11-06T10:32:02+00:00)
- **8ee518a5** add dpm-solver support (much faster than plms) - LuChengTHU (2022-10-28T15:47:10+00:00)
- **69ae4b35** Release under CreativeML Open RAIL M License - Patrick Esser (2022-08-22T16:57:55+00:00)
- **a117e775** Merge branch 'patrickvonplaten-add_safety_checker' into main - Patrick Esser (2022-08-22T11:02:53+00:00)
- **673b0ab3** update safety model id - Patrick Esser (2022-08-22T10:58:42+00:00)
- **a6e2f3b1** Merge branch 'add_safety_checker' of https://github.com/patrickvonplaten/stable-diffusion into patrickvonplaten-add_safety_checker - Patrick Esser (2022-08-22T08:25:42+00:00)
- **b9851783** fix to numpy - Patrick von Platen (2022-08-19T17:14:29+00:00)
- **239ed0fd** fix more - Patrick von Platen (2022-08-19T17:09:41+00:00)

## External Links Found in README

- https://huggingface.co/datasets/laion/laion-high-resolution
- https://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html
- https://arxiv.org/abs/2205.11487
- https://www.licenses.ai/
- https://github.com/christophschuhmann/improved-aesthetic-predictor
- https://github.com/openai/guided-diffusion
- https://github.com/pesser
- https://runwayml.com/
- https://github.com/CompVis/latent-diffusion/pull/51
- https://stability.ai/
- https://github.com/ShieldMnt/invisible-watermark
- https://laion.ai/blog/laion-aesthetics/
- https://github.com/CompVis/stable-diffusion/pull/36
- https://github.com/rromb
- https://www.pinta-project.com/
- https://conda.io/
- https://www.licenses.ai/blog/2022/8/18/naming-convention-of-responsible-ai-licenses
- https://github.com/lucidrains?tab=repositories
- https://ommer-lab.com/research/latent-diffusion-models/
- https://huggingface.co/CompVis/stable-diffusion

## Raw Data

<details>
<summary>Click to expand raw JSON data</summary>

```json
{
  "id": 523379232,
  "name": "stable-diffusion",
  "full_name": "CompVis/stable-diffusion",
  "description": "A latent text-to-image diffusion model",
  "html_url": "https://github.com/CompVis/stable-diffusion",
  "clone_url": "https://github.com/CompVis/stable-diffusion.git",
  "ssh_url": "git@github.com:CompVis/stable-diffusion.git",
  "homepage": "https://ommer-lab.com/research/latent-diffusion-models/",
  "topics": [],
  "default_branch": "main",
  "created_at": "2022-08-10T14:36:44+00:00",
  "updated_at": "2025-06-22T01:19:50+00:00",
  "pushed_at": "2024-06-18T01:53:49+00:00",
  "size_kb": 43676,
  "watchers_count": 70977,
  "stargazers_count": 70977,
  "forks_count": 10461,
  "open_issues_count": 604,
  "license": {
    "key": "other",
    "name": "Other",
    "spdx_id": "NOASSERTION",
    "url": "https://github.com/CompVis/stable-diffusion/blob/main/LICENSE"
  },
  "languages": {
    "Jupyter Notebook": 4172390,
    "Python": 520234,
    "Shell": 3005
  },
  "top_contributors": [
    {
      "login": "rromb",
      "contributions": 9
    },
    {
      "login": "pesser",
      "contributions": 7
    },
    {
      "login": "patrickvonplaten",
      "contributions": 6
    },
    {
      "login": "LuChengTHU",
      "contributions": 2
    },
    {
      "login": "owenvincent",
      "contributions": 2
    },
    {
      "login": "apolinario",
      "contributions": 1
    },
    {
      "login": "cpacker",
      "contributions": 1
    }
  ],
  "file_tree_count": 187,
  "file_tree_sample": [
    {
      "path": "LICENSE",
      "type": "blob"
    },
    {
      "path": "README.md",
      "type": "blob"
    },
    {
      "path": "Stable_Diffusion_v1_Model_Card.md",
      "type": "blob"
    },
    {
      "path": "assets",
      "type": "tree"
    },
    {
      "path": "assets/a-painting-of-a-fire.png",
      "type": "blob"
    },
    {
      "path": "assets/a-photograph-of-a-fire.png",
      "type": "blob"
    },
    {
      "path": "assets/a-shirt-with-a-fire-printed-on-it.png",
      "type": "blob"
    },
    {
      "path": "assets/a-shirt-with-the-inscription-'fire'.png",
      "type": "blob"
    },
    {
      "path": "assets/a-watercolor-painting-of-a-fire.png",
      "type": "blob"
    },
    {
      "path": "assets/birdhouse.png",
      "type": "blob"
    }
  ],
  "issues_count": 0,
  "pulls_count": 156,
  "recent_issues": [
    {
      "number": 896,
      "title": "Create urimage",
      "state": "open"
    },
    {
      "number": 895,
      "title": "Create Abella danger",
      "state": "closed"
    },
    {
      "number": 894,
      "title": "Codespace refactored trout pj76644xx6grfrv5r",
      "state": "closed"
    },
    {
      "number": 893,
      "title": "Implementation of rope and alibi",
      "state": "closed"
    },
    {
      "number": 892,
      "title": "Bounded attention",
      "state": "open"
    }
  ],
  "recent_pulls": [
    {
      "number": 896,
      "title": "Create urimage",
      "state": "open"
    },
    {
      "number": 895,
      "title": "Create Abella danger",
      "state": "closed"
    },
    {
      "number": 894,
      "title": "Codespace refactored trout pj76644xx6grfrv5r",
      "state": "closed"
    },
    {
      "number": 893,
      "title": "Implementation of rope and alibi",
      "state": "closed"
    },
    {
      "number": 892,
      "title": "Bounded attention",
      "state": "open"
    }
  ],
  "recent_commits": [
    {
      "sha": "21f890f9da3cfbeaba8e2ac3c425ee9e998d5229",
      "author": "Robin Rombach",
      "date": "2022-11-16T20:34:06+00:00",
      "message": "Update sampler.py"
    },
    {
      "sha": "5a00c4f8db6c05c3e55a4d25c913796c15006e67",
      "author": "Robin Rombach",
      "date": "2022-11-16T11:51:43+00:00",
      "message": "Merge pull request #440 from LuChengTHU/main"
    },
    {
      "sha": "bf3b8783543bdbfc31721479091e35696baadd13",
      "author": "LuChengTHU",
      "date": "2022-11-06T10:32:02+00:00",
      "message": "add a stablizing trick for steps < 15"
    },
    {
      "sha": "8ee518a5a26d8f57d61985f81dc19d7e17a74a7d",
      "author": "LuChengTHU",
      "date": "2022-10-28T15:47:10+00:00",
      "message": "add dpm-solver support (much faster than plms)"
    },
    {
      "sha": "69ae4b35e0a0f6ee1af8bb9a5d0016ccb27e36dc",
      "author": "Patrick Esser",
      "date": "2022-08-22T16:57:55+00:00",
      "message": "Release under CreativeML Open RAIL M License"
    },
    {
      "sha": "a117e77545c8a13468d1e949031d841bbeff2a93",
      "author": "Patrick Esser",
      "date": "2022-08-22T11:02:53+00:00",
      "message": "Merge branch 'patrickvonplaten-add_safety_checker' into main"
    },
    {
      "sha": "673b0ab3a303fa539f950db00525f2e2bb0ce60e",
      "author": "Patrick Esser",
      "date": "2022-08-22T10:58:42+00:00",
      "message": "update safety model id"
    },
    {
      "sha": "a6e2f3b120eba81e9c290144f46ceda2145f1248",
      "author": "Patrick Esser",
      "date": "2022-08-22T08:25:42+00:00",
      "message": "Merge branch 'add_safety_checker' of https://github.com/patrickvonplaten/stable-diffusion into patrickvonplaten-add_safety_checker"
    },
    {
      "sha": "b9851783e5400900a5de8ad43cb6f407f2cd1e4d",
      "author": "Patrick von Platen",
      "date": "2022-08-19T17:14:29+00:00",
      "message": "fix to numpy"
    },
    {
      "sha": "239ed0fd0247807df4f62e5dc22dfe00f6e14db3",
      "author": "Patrick von Platen",
      "date": "2022-08-19T17:09:41+00:00",
      "message": "fix more"
    },
    {
      "sha": "f3f60fccc31acee192417e2e926260698201982f",
      "author": "Patrick von Platen",
      "date": "2022-08-19T17:08:10+00:00",
      "message": "correct merg"
    },
    {
      "sha": "eef5da90dbee4b22bdd864e53726993f98ae3366",
      "author": "Patrick von Platen",
      "date": "2022-08-19T17:05:39+00:00",
      "message": "finish"
    },
    {
      "sha": "536eb1a8ba9e7e3806727cc25331d43b1f076f07",
      "author": "Patrick von Platen",
      "date": "2022-08-19T16:03:22+00:00",
      "message": "Apply suggestions from code review"
    },
    {
      "sha": "d0c714ae4afa1c011269a956d6f260f84f77025e",
      "author": "Patrick von Platen",
      "date": "2022-08-19T16:01:56+00:00",
      "message": "[Safety Checker] Add Safety Checker Module"
    },
    {
      "sha": "7b8c883b078024f68b56e862f247a64f9e282aac",
      "author": "owenvincent",
      "date": "2022-08-18T13:46:44+00:00",
      "message": "Update README.md"
    },
    {
      "sha": "be6ab334c2acb047e168fccbb9f23d95bc7366e1",
      "author": "owenvincent",
      "date": "2022-08-18T11:49:59+00:00",
      "message": "update links in README.md"
    },
    {
      "sha": "d39f5b51a8d607fd855425a0d546b9f871034c3d",
      "author": "Patrick Esser",
      "date": "2022-08-16T21:13:39+00:00",
      "message": "update readme"
    },
    {
      "sha": "b57c05232a179758d26a6996c57c96b2d1197196",
      "author": "Patrick Esser",
      "date": "2022-08-16T21:11:39+00:00",
      "message": "Merge pull request #27 from apolinario/patch-1"
    },
    {
      "sha": "e1367298c7497de7b9a5f076f40433ce6857077e",
      "author": "apolinario",
      "date": "2022-08-16T19:08:28+00:00",
      "message": "Add diffusers as a way to inference in the model"
    },
    {
      "sha": "3fbbf28a8a66d6f0ffcaca43a76521b6d9b5bfb3",
      "author": "Robin Rombach",
      "date": "2022-08-13T15:06:31+00:00",
      "message": "Merge pull request #5 from cpacker/main"
    }
  ],
  "readme_text": "# Stable Diffusion\n*Stable Diffusion was made possible thanks to a collaboration with [Stability AI](https://stability.ai/) and [Runway](https://runwayml.com/) and builds upon our previous work:*\n\n[**High-Resolution Image Synthesis with Latent Diffusion Models**](https://ommer-lab.com/research/latent-diffusion-models/)<br/>\n[Robin Rombach](https://github.com/rromb)\\*,\n[Andreas Blattmann](https://github.com/ablattmann)\\*,\n[Dominik Lorenz](https://github.com/qp-qp)\\,\n[Patrick Esser](https://github.com/pesser),\n[Bj\u00f6rn Ommer](https://hci.iwr.uni-heidelberg.de/Staff/bommer)<br/>\n_[CVPR '22 Oral](https://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html) |\n[GitHub](https://github.com/CompVis/latent-diffusion) | [arXiv](https://arxiv.org/abs/2112.10752) | [Project page](https://ommer-lab.com/research/latent-diffusion-models/)_\n\n![txt2img-stable2](assets/stable-samples/txt2img/merged-0006.png)\n[Stable Diffusion](#stable-diffusion-v1) is a latent text-to-image diffusion\nmodel.\nThanks to a generous compute donation from [Stability AI](https://stability.ai/) and support from [LAION](https://laion.ai/), we were able to train a Latent Diffusion Model on 512x512 images from a subset of the [LAION-5B](https://laion.ai/blog/laion-5b/) database. \nSimilar to Google's [Imagen](https://arxiv.org/abs/2205.11487), \nthis model uses a frozen CLIP ViT-L/14 text encoder to condition the model on text prompts.\nWith its 860M UNet and 123M text encoder, the model is relatively lightweight and runs on a GPU with at least 10GB VRAM.\nSee [this section](#stable-diffusion-v1) below and the [model card](https://huggingface.co/CompVis/stable-diffusion).\n\n  \n## Requirements\nA suitable [conda](https://conda.io/) environment named `ldm` can be created\nand activated with:\n\n```\nconda env create -f environment.yaml\nconda activate ldm\n```\n\nYou can also update an existing [latent diffusion](https://github.com/CompVis/latent-diffusion) environment by running\n\n```\nconda install pytorch torchvision -c pytorch\npip install transformers==4.19.2 diffusers invisible-watermark\npip install -e .\n``` \n\n\n## Stable Diffusion v1\n\nStable Diffusion v1 refers to a specific configuration of the model\narchitecture that uses a downsampling-factor 8 autoencoder with an 860M UNet\nand CLIP ViT-L/14 text encoder for the diffusion model. The model was pretrained on 256x256 images and \nthen finetuned on 512x512 images.\n\n*Note: Stable Diffusion v1 is a general text-to-image diffusion model and therefore mirrors biases and (mis-)conceptions that are present\nin its training data. \nDetails on the training procedure and data, as well as the intended use of the model can be found in the corresponding [model card](Stable_Diffusion_v1_Model_Card.md).*\n\nThe weights are available via [the CompVis organization at Hugging Face](https://huggingface.co/CompVis) under [a license which contains specific use-based restrictions to prevent misuse and harm as informed by the model card, but otherwise remains permissive](LICENSE). While commercial use is permitted under the terms of the license, **we do not recommend using the provided weights for services or products without additional safety mechanisms and considerations**, since there are [known limitations and biases](Stable_Diffusion_v1_Model_Card.md#limitations-and-bias) of the weights, and research on safe and ethical deployment of general text-to-image models is an ongoing effort. **The weights are research artifacts and should be treated as such.**\n\n[The CreativeML OpenRAIL M license](LICENSE) is an [Open RAIL M license](https://www.licenses.ai/blog/2022/8/18/naming-convention-of-responsible-ai-licenses), adapted from the work that [BigScience](https://bigscience.huggingface.co/) and [the RAIL Initiative](https://www.licenses.ai/) are jointly carrying in the area of responsible AI licensing. See also [the article about the BLOOM Open RAIL license](https://bigscience.huggingface.co/blog/the-bigscience-rail-license) on which our license is based.\n\n### Weights\n\nWe currently provide the following checkpoints:\n\n- `sd-v1-1.ckpt`: 237k steps at resolution `256x256` on [laion2B-en](https://huggingface.co/datasets/laion/laion2B-en).\n  194k steps at resolution `512x512` on [laion-high-resolution](https://huggingface.co/datasets/laion/laion-high-resolution) (170M examples from LAION-5B with resolution `>= 1024x1024`).\n- `sd-v1-2.ckpt`: Resumed from `sd-v1-1.ckpt`.\n  515k steps at resolution `512x512` on [laion-aesthetics v2 5+](https://laion.ai/blog/laion-aesthetics/) (a subset of laion2B-en with estimated aesthetics score `> 5.0`, and additionally\nfiltered to images with an original size `>= 512x512`, and an estimated watermark probability `< 0.5`. The watermark estimate is from the [LAION-5B](https://laion.ai/blog/laion-5b/) metadata, the aesthetics score is estimated using the [LAION-Aesthetics Predictor V2](https://github.com/christophschuhmann/improved-aesthetic-predictor)).\n- `sd-v1-3.ckpt`: Resumed from `sd-v1-2.ckpt`. 195k steps at resolution `512x512` on \"laion-aesthetics v2 5+\" and 10\\% dropping of the text-conditioning to improve [classifier-free guidance sampling](https://arxiv.org/abs/2207.12598).\n- `sd-v1-4.ckpt`: Resumed from `sd-v1-2.ckpt`. 225k steps at resolution `512x512` on \"laion-aesthetics v2 5+\" and 10\\% dropping of the text-conditioning to improve [classifier-free guidance sampling](https://arxiv.org/abs/2207.12598).\n\nEvaluations with different classifier-free guidance scales (1.5, 2.0, 3.0, 4.0,\n5.0, 6.0, 7.0, 8.0) and 50 PLMS sampling\nsteps show the relative improvements of the checkpoints:\n![sd evaluation results](assets/v1-variants-scores.jpg)\n\n\n\n### Text-to-Image with Stable Diffusion\n![txt2img-stable2](assets/stable-samples/txt2img/merged-0005.png)\n![txt2img-stable2](assets/stable-samples/txt2img/merged-0007.png)\n\nStable Diffusion is a latent diffusion model conditioned on the (non-pooled) text embeddings of a CLIP ViT-L/14 text encoder.\nWe provide a [reference script for sampling](#reference-sampling-script), but\nthere also exists a [diffusers integration](#diffusers-integration), which we\nexpect to see more active community development.\n\n#### Reference Sampling Script\n\nWe provide a reference sampling script, which incorporates\n\n- a [Safety Checker Module](https://github.com/CompVis/stable-diffusion/pull/36),\n  to reduce the probability of explicit outputs,\n- an [invisible watermarking](https://github.com/ShieldMnt/invisible-watermark)\n  of the outputs, to help viewers [identify the images as machine-generated](scripts/tests/test_watermark.py).\n\nAfter [obtaining the `stable-diffusion-v1-*-original` weights](#weights), link them\n```\nmkdir -p models/ldm/stable-diffusion-v1/\nln -s <path/to/model.ckpt> models/ldm/stable-diffusion-v1/model.ckpt \n```\nand sample with\n```\npython scripts/txt2img.py --prompt \"a photograph of an astronaut riding a horse\" --plms \n```\n\nBy default, this uses a guidance scale of `--scale 7.5`, [Katherine Crowson's implementation](https://github.com/CompVis/latent-diffusion/pull/51) of the [PLMS](https://arxiv.org/abs/2202.09778) sampler, \nand renders images of size 512x512 (which it was trained on) in 50 steps. All supported arguments are listed below (type `python scripts/txt2img.py --help`).\n\n\n```commandline\nusage: txt2img.py [-h] [--prompt [PROMPT]] [--outdir [OUTDIR]] [--skip_grid] [--skip_save] [--ddim_steps DDIM_STEPS] [--plms] [--laion400m] [--fixed_code] [--ddim_eta DDIM_ETA]\n                  [--n_iter N_ITER] [--H H] [--W W] [--C C] [--f F] [--n_samples N_SAMPLES] [--n_rows N_ROWS] [--scale SCALE] [--from-file FROM_FILE] [--config CONFIG] [--ckpt CKPT]\n                  [--seed SEED] [--precision {full,autocast}]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --prompt [PROMPT]     the prompt to render\n  --outdir [OUTDIR]     dir to write results to\n  --skip_grid           do not save a grid, only individual samples. Helpful when evaluating lots of samples\n  --skip_save           do not save individual samples. For speed measurements.\n  --ddim_steps DDIM_STEPS\n                        number of ddim sampling steps\n  --plms                use plms sampling\n  --laion400m           uses the LAION400M model\n  --fixed_code          if enabled, uses the same starting code across samples\n  --ddim_eta DDIM_ETA   ddim eta (eta=0.0 corresponds to deterministic sampling\n  --n_iter N_ITER       sample this often\n  --H H                 image height, in pixel space\n  --W W                 image width, in pixel space\n  --C C                 latent channels\n  --f F                 downsampling factor\n  --n_samples N_SAMPLES\n                        how many samples to produce for each given prompt. A.k.a. batch size\n  --n_rows N_ROWS       rows in the grid (default: n_samples)\n  --scale SCALE         unconditional guidance scale: eps = eps(x, empty) + scale * (eps(x, cond) - eps(x, empty))\n  --from-file FROM_FILE\n                        if specified, load prompts from this file\n  --config CONFIG       path to config which constructs model\n  --ckpt CKPT           path to checkpoint of model\n  --seed SEED           the seed (for reproducible sampling)\n  --precision {full,autocast}\n                        evaluate at this precision\n```\nNote: The inference config for all v1 versions is designed to be used with EMA-only checkpoints. \nFor this reason `use_ema=False` is set in the configuration, otherwise the code will try to switch from\nnon-EMA to EMA weights. If you want to examine the effect of EMA vs no EMA, we provide \"full\" checkpoints\nwhich contain both types of weights. For these, `use_ema=False` will load and use the non-EMA weights.\n\n\n#### Diffusers Integration\n\nA simple way to download and sample Stable Diffusion is by using the [diffusers library](https://github.com/huggingface/diffusers/tree/main#new--stable-diffusion-is-now-fully-compatible-with-diffusers):\n```py\n# make sure you're logged in with `huggingface-cli login`\nfrom torch import autocast\nfrom diffusers import StableDiffusionPipeline\n\npipe = StableDiffusionPipeline.from_pretrained(\n\t\"CompVis/stable-diffusion-v1-4\", \n\tuse_auth_token=True\n).to(\"cuda\")\n\nprompt = \"a photo of an astronaut riding a horse on mars\"\nwith autocast(\"cuda\"):\n    image = pipe(prompt)[\"sample\"][0]  \n    \nimage.save(\"astronaut_rides_horse.png\")\n```\n\n\n### Image Modification with Stable Diffusion\n\nBy using a diffusion-denoising mechanism as first proposed by [SDEdit](https://arxiv.org/abs/2108.01073), the model can be used for different \ntasks such as text-guided image-to-image translation and upscaling. Similar to the txt2img sampling script, \nwe provide a script to perform image modification with Stable Diffusion.  \n\nThe following describes an example where a rough sketch made in [Pinta](https://www.pinta-project.com/) is converted into a detailed artwork.\n```\npython scripts/img2img.py --prompt \"A fantasy landscape, trending on artstation\" --init-img <path-to-img.jpg> --strength 0.8\n```\nHere, strength is a value between 0.0 and 1.0, that controls the amount of noise that is added to the input image. \nValues that approach 1.0 allow for lots of variations but will also produce images that are not semantically consistent with the input. See the following example.\n\n**Input**\n\n![sketch-in](assets/stable-samples/img2img/sketch-mountains-input.jpg)\n\n**Outputs**\n\n![out3](assets/stable-samples/img2img/mountains-3.png)\n![out2](assets/stable-samples/img2img/mountains-2.png)\n\nThis procedure can, for example, also be used to upscale samples from the base model.\n\n\n## Comments \n\n- Our codebase for the diffusion models builds heavily on [OpenAI's ADM codebase](https://github.com/openai/guided-diffusion)\nand [https://github.com/lucidrains/denoising-diffusion-pytorch](https://github.com/lucidrains/denoising-diffusion-pytorch). \nThanks for open-sourcing!\n\n- The implementation of the transformer encoder is from [x-transformers](https://github.com/lucidrains/x-transformers) by [lucidrains](https://github.com/lucidrains?tab=repositories). \n\n\n## BibTeX\n\n```\n@misc{rombach2021highresolution,\n      title={High-Resolution Image Synthesis with Latent Diffusion Models}, \n      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Bj\u00f6rn Ommer},\n      year={2021},\n      eprint={2112.10752},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}\n```\n\n\n",
  "external_links_in_readme": [
    "https://huggingface.co/datasets/laion/laion-high-resolution",
    "https://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html",
    "https://arxiv.org/abs/2205.11487",
    "https://www.licenses.ai/",
    "https://github.com/christophschuhmann/improved-aesthetic-predictor",
    "https://github.com/openai/guided-diffusion",
    "https://github.com/pesser",
    "https://runwayml.com/",
    "https://github.com/CompVis/latent-diffusion/pull/51",
    "https://stability.ai/",
    "https://github.com/ShieldMnt/invisible-watermark",
    "https://laion.ai/blog/laion-aesthetics/",
    "https://github.com/CompVis/stable-diffusion/pull/36",
    "https://github.com/rromb",
    "https://www.pinta-project.com/",
    "https://conda.io/",
    "https://www.licenses.ai/blog/2022/8/18/naming-convention-of-responsible-ai-licenses",
    "https://github.com/lucidrains?tab=repositories",
    "https://ommer-lab.com/research/latent-diffusion-models/",
    "https://huggingface.co/CompVis/stable-diffusion",
    "https://arxiv.org/abs/2108.01073",
    "https://huggingface.co/CompVis",
    "https://bigscience.huggingface.co/",
    "https://huggingface.co/datasets/laion/laion2B-en",
    "https://github.com/ablattmann",
    "https://github.com/lucidrains/denoising-diffusion-pytorch](https://github.com/lucidrains/denoising-diffusion-pytorch",
    "https://github.com/qp-qp",
    "https://github.com/CompVis/latent-diffusion",
    "https://arxiv.org/abs/2202.09778",
    "https://github.com/huggingface/diffusers/tree/main#new--stable-diffusion-is-now-fully-compatible-with-diffusers",
    "https://arxiv.org/abs/2112.10752",
    "https://laion.ai/",
    "https://bigscience.huggingface.co/blog/the-bigscience-rail-license",
    "https://hci.iwr.uni-heidelberg.de/Staff/bommer",
    "https://laion.ai/blog/laion-5b/",
    "https://arxiv.org/abs/2207.12598",
    "https://github.com/lucidrains/x-transformers"
  ]
}
```

</details>


---

## Repository 5: AUTOMATIC1111/stable-diffusion-webui">AUTOMATIC1111<

# GitHub Data Extraction Error

Error: 404 {"message": "Not Found", "documentation_url": "https://docs.github.com/rest/repos/repos#get-a-repository", "status": "404"}

Repository: https://github.com/AUTOMATIC1111/stable-diffusion-webui">AUTOMATIC1111</a>,

---

## Repository 6: invoke-ai/InvokeAI">InvokeAI<

# GitHub Data Extraction Error

Error: 404 {"message": "Not Found", "documentation_url": "https://docs.github.com/rest/repos/repos#get-a-repository", "status": "404"}

Repository: https://github.com/invoke-ai/InvokeAI">InvokeAI</a></span>

---

## Repository 7: vladmandic/automatic">SD.Next<

# GitHub Data Extraction Error

Error: 404 {"message": "Not Found", "documentation_url": "https://docs.github.com/rest/repos/repos#get-a-repository", "status": "404"}

Repository: https://github.com/vladmandic/automatic">SD.Next</a>,

---

## Repository 8: huggingface/diffusers

# GitHub Repository Data

**Repository:** [huggingface/diffusers](https://github.com/huggingface/diffusers)

## Basic Information

- **Description:** 游뱅 Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch and FLAX.
- **Created:** 2022-05-30T16:04:02+00:00
- **Last Updated:** 2025-06-22T02:44:24+00:00
- **Last Pushed:** 2025-06-21T22:09:28+00:00
- **Default Branch:** main
- **Size:** 74451 KB

## Statistics

- **Stars:** 29,436
- **Forks:** 6,050
- **Watchers:** 29,436
- **Open Issues:** 700
- **Total Issues:** 0
- **Pull Requests:** 6,018

## License

- **Type:** Apache License 2.0
- **SPDX ID:** Apache-2.0
- **URL:** [License](https://github.com/huggingface/diffusers/blob/main/LICENSE)

## Languages

- **Python:** 21,990,626 bytes
- **Dockerfile:** 12,704 bytes
- **Makefile:** 2,782 bytes

## Topics

- `deep-learning`
- `diffusion`
- `image-generation`
- `pytorch`
- `score-based-generative-modeling`
- `image2image`
- `text2image`
- `stable-diffusion`
- `stable-diffusion-diffusers`
- `hacktoberfest`
- `flax`
- `jax`
- `latent-diffusion-models`
- `flux`
- `image2video`
- `text2video`
- `video2video`

## Top Contributors

1. **patrickvonplaten** - 1008 contributions
2. **sayakpaul** - 673 contributions
3. **patil-suraj** - 317 contributions
4. **DN6** - 268 contributions
5. **anton-l** - 253 contributions
6. **yiyixuxu** - 188 contributions
7. **a-r-r-o-w** - 161 contributions
8. **stevhliu** - 156 contributions
9. **pcuenca** - 151 contributions
10. **williamberman** - 123 contributions

## File Structure (Sample of 10 files)

Total files: 2,359

- `.github` (tree)
- `.github/ISSUE_TEMPLATE` (tree)
- `.github/ISSUE_TEMPLATE/bug-report.yml` (blob)
- `.github/ISSUE_TEMPLATE/config.yml` (blob)
- `.github/ISSUE_TEMPLATE/feature_request.md` (blob)
- `.github/ISSUE_TEMPLATE/feedback.md` (blob)
- `.github/ISSUE_TEMPLATE/new-model-addition.yml` (blob)
- `.github/ISSUE_TEMPLATE/remote-vae-pilot-feedback.yml` (blob)
- `.github/ISSUE_TEMPLATE/translate.md` (blob)
- `.github/PULL_REQUEST_TEMPLATE.md` (blob)

## Recent Issues

- 游릭 **#11765** Add `--lora_alpha` and metadata handling for `train_dreambooth_lora_hidream` (open)
- 游릭 **#11764** RepositoryNotFoundError on inpainting demo (open)
- 游릭 **#11763** Avoid creating tensor in CosmosAttnProcessor2_0 (#11761) (open)
- 游릭 **#11762** Could you help fix the backdoor vulnerability caused by two risky pre-trained models used in this repo? (open)
- 游릭 **#11761** Avoid creating tensor in CosmosAttnProcessor2_0 (open)

## Recent Pull Requests

- 游릭 **#11765** Add `--lora_alpha` and metadata handling for `train_dreambooth_lora_hidream` (open)
- 游릭 **#11763** Avoid creating tensor in CosmosAttnProcessor2_0 (#11761) (open)
- 游릭 **#11760** Follow up for Group Offload to Disk  (open)
- 游릭 **#11759** adjust to get CI test cases passed on XPU (open)
- 游릭 **#11758** [wip] enable FastPersist to (potentially) speed up disk saving in group offloading (open)

## Recent Commits

- **7fc53b5d** Fix dimensionalities in `apply_rotary_emb` functions' comments (#11717) - Tolga Cang칬z (2025-06-21T22:09:28+00:00)
- **0874dd04** [docs] LoRA scale scheduling (#11727) - Steven Liu (2025-06-20T17:15:29+00:00)
- **6184d8a4** [docs] device_map (#11711) - Steven Liu (2025-06-20T17:14:48+00:00)
- **5a6e3864** [docs] Quantization + torch.compile + offloading (#11703) - Steven Liu (2025-06-20T17:11:39+00:00)
- **42077e6c** Fix failing cpu offload test for LTX Latent Upscale (#11755) - Dhruv Nair (2025-06-20T04:07:34+00:00)
- **3d8d8485** fix invalid component handling behaviour in `PipelineQuantizationConfig` (#11750) - Sayak Paul (2025-06-20T02:24:12+00:00)
- **195926bb** Update Chroma Docs (#11753) - Dhruv Nair (2025-06-19T17:33:19+00:00)
- **85a916bb** make group offloading work with disk/nvme transfers (#11682) - Sayak Paul (2025-06-19T12:39:30+00:00)
- **3287ce28** Fix HiDream pipeline test module  (#11754) - Dhruv Nair (2025-06-19T11:36:14+00:00)
- **0c11c8c1** [CI] Fix SANA tests (#11756) - Dhruv Nair (2025-06-19T11:36:02+00:00)

## External Links Found in README

- https://github.com/huggingface/diffusers/issues
- https://huggingface.co/lllyasviel/sd-controlnet-canny">
- https://github.com/huggingface/diffusers}}
- https://github.com/huggingface/diffusers/releases"><img
- https://huggingface.co/docs/diffusers/api/schedulers/overview
- https://huggingface.co/docs/diffusers/training/overview
- https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22
- https://pepy.tech/project/diffusers"><img
- https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22New+pipeline%2Fmodel%22
- https://huggingface.co/models?library=diffusers&sort=downloads
- https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/image_variation">Stable
- https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/inpaint">Stable
- https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22New+scheduler%22
- https://huggingface.co/runwayml/stable-diffusion-inpainting">
- https://huggingface.co/docs/diffusers/api/pipelines/kandinsky">Kandinsky</a></td>
- https://huggingface.co/docs/diffusers/conceptual/philosophy#simple-over-easy
- https://github.com/microsoft/TaskMatrix
- https://github.com/Sanster/lama-cleaner
- https://github.com/deep-floyd/IF
- https://discord.gg/G7tWnz98XR"><img

## Raw Data

<details>
<summary>Click to expand raw JSON data</summary>

```json
{
  "id": 498011141,
  "name": "diffusers",
  "full_name": "huggingface/diffusers",
  "description": "\ud83e\udd17 Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch and FLAX.",
  "html_url": "https://github.com/huggingface/diffusers",
  "clone_url": "https://github.com/huggingface/diffusers.git",
  "ssh_url": "git@github.com:huggingface/diffusers.git",
  "homepage": "https://huggingface.co/docs/diffusers",
  "topics": [
    "deep-learning",
    "diffusion",
    "image-generation",
    "pytorch",
    "score-based-generative-modeling",
    "image2image",
    "text2image",
    "stable-diffusion",
    "stable-diffusion-diffusers",
    "hacktoberfest",
    "flax",
    "jax",
    "latent-diffusion-models",
    "flux",
    "image2video",
    "text2video",
    "video2video"
  ],
  "default_branch": "main",
  "created_at": "2022-05-30T16:04:02+00:00",
  "updated_at": "2025-06-22T02:44:24+00:00",
  "pushed_at": "2025-06-21T22:09:28+00:00",
  "size_kb": 74451,
  "watchers_count": 29436,
  "stargazers_count": 29436,
  "forks_count": 6050,
  "open_issues_count": 700,
  "license": {
    "key": "apache-2.0",
    "name": "Apache License 2.0",
    "spdx_id": "Apache-2.0",
    "url": "https://github.com/huggingface/diffusers/blob/main/LICENSE"
  },
  "languages": {
    "Python": 21990626,
    "Dockerfile": 12704,
    "Makefile": 2782
  },
  "top_contributors": [
    {
      "login": "patrickvonplaten",
      "contributions": 1008
    },
    {
      "login": "sayakpaul",
      "contributions": 673
    },
    {
      "login": "patil-suraj",
      "contributions": 317
    },
    {
      "login": "DN6",
      "contributions": 268
    },
    {
      "login": "anton-l",
      "contributions": 253
    },
    {
      "login": "yiyixuxu",
      "contributions": 188
    },
    {
      "login": "a-r-r-o-w",
      "contributions": 161
    },
    {
      "login": "stevhliu",
      "contributions": 156
    },
    {
      "login": "pcuenca",
      "contributions": 151
    },
    {
      "login": "williamberman",
      "contributions": 123
    },
    {
      "login": "hlky",
      "contributions": 110
    },
    {
      "login": "tolgacangoz",
      "contributions": 102
    },
    {
      "login": "linoytsaban",
      "contributions": 58
    },
    {
      "login": "kashif",
      "contributions": 51
    },
    {
      "login": "yao-matrix",
      "contributions": 30
    },
    {
      "login": "dg845",
      "contributions": 30
    },
    {
      "login": "asomoza",
      "contributions": 29
    },
    {
      "login": "apolinario",
      "contributions": 26
    },
    {
      "login": "younesbelkada",
      "contributions": 23
    },
    {
      "login": "Wauplin",
      "contributions": 23
    }
  ],
  "file_tree_count": 2359,
  "file_tree_sample": [
    {
      "path": ".github",
      "type": "tree"
    },
    {
      "path": ".github/ISSUE_TEMPLATE",
      "type": "tree"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/bug-report.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/config.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/feature_request.md",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/feedback.md",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/new-model-addition.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/remote-vae-pilot-feedback.yml",
      "type": "blob"
    },
    {
      "path": ".github/ISSUE_TEMPLATE/translate.md",
      "type": "blob"
    },
    {
      "path": ".github/PULL_REQUEST_TEMPLATE.md",
      "type": "blob"
    }
  ],
  "issues_count": 0,
  "pulls_count": 6018,
  "recent_issues": [
    {
      "number": 11765,
      "title": "Add `--lora_alpha` and metadata handling for `train_dreambooth_lora_hidream`",
      "state": "open"
    },
    {
      "number": 11764,
      "title": "RepositoryNotFoundError on inpainting demo",
      "state": "open"
    },
    {
      "number": 11763,
      "title": "Avoid creating tensor in CosmosAttnProcessor2_0 (#11761)",
      "state": "open"
    },
    {
      "number": 11762,
      "title": "Could you help fix the backdoor vulnerability caused by two risky pre-trained models used in this repo?",
      "state": "open"
    },
    {
      "number": 11761,
      "title": "Avoid creating tensor in CosmosAttnProcessor2_0",
      "state": "open"
    }
  ],
  "recent_pulls": [
    {
      "number": 11765,
      "title": "Add `--lora_alpha` and metadata handling for `train_dreambooth_lora_hidream`",
      "state": "open"
    },
    {
      "number": 11763,
      "title": "Avoid creating tensor in CosmosAttnProcessor2_0 (#11761)",
      "state": "open"
    },
    {
      "number": 11760,
      "title": "Follow up for Group Offload to Disk ",
      "state": "open"
    },
    {
      "number": 11759,
      "title": "adjust to get CI test cases passed on XPU",
      "state": "open"
    },
    {
      "number": 11758,
      "title": "[wip] enable FastPersist to (potentially) speed up disk saving in group offloading",
      "state": "open"
    }
  ],
  "recent_commits": [
    {
      "sha": "7fc53b5d66867f9e59398f5a14dd3dd9fbc700dd",
      "author": "Tolga Cang\u00f6z",
      "date": "2025-06-21T22:09:28+00:00",
      "message": "Fix dimensionalities in `apply_rotary_emb` functions' comments (#11717)"
    },
    {
      "sha": "0874dd04dc1bb359053935109dc95483218b086f",
      "author": "Steven Liu",
      "date": "2025-06-20T17:15:29+00:00",
      "message": "[docs] LoRA scale scheduling (#11727)"
    },
    {
      "sha": "6184d8a43357f3397c0848b5d0b716cf389d1f30",
      "author": "Steven Liu",
      "date": "2025-06-20T17:14:48+00:00",
      "message": "[docs] device_map (#11711)"
    },
    {
      "sha": "5a6e386464bf7c57fa93e359930366933b3ec337",
      "author": "Steven Liu",
      "date": "2025-06-20T17:11:39+00:00",
      "message": "[docs] Quantization + torch.compile + offloading (#11703)"
    },
    {
      "sha": "42077e6c734df2fc7bbed373abceab99635500ad",
      "author": "Dhruv Nair",
      "date": "2025-06-20T04:07:34+00:00",
      "message": "Fix failing cpu offload test for LTX Latent Upscale (#11755)"
    },
    {
      "sha": "3d8d8485fccc2c26f90efefb93d47e0d2b864472",
      "author": "Sayak Paul",
      "date": "2025-06-20T02:24:12+00:00",
      "message": "fix invalid component handling behaviour in `PipelineQuantizationConfig` (#11750)"
    },
    {
      "sha": "195926bbdc69d20d442179b2fe96023edc751212",
      "author": "Dhruv Nair",
      "date": "2025-06-19T17:33:19+00:00",
      "message": "Update Chroma Docs (#11753)"
    },
    {
      "sha": "85a916bb8b2260d94014e15f096614c1c9f44d04",
      "author": "Sayak Paul",
      "date": "2025-06-19T12:39:30+00:00",
      "message": "make group offloading work with disk/nvme transfers (#11682)"
    },
    {
      "sha": "3287ce2890caeff7d7c5279cde24564282f05441",
      "author": "Dhruv Nair",
      "date": "2025-06-19T11:36:14+00:00",
      "message": "Fix HiDream pipeline test module  (#11754)"
    },
    {
      "sha": "0c11c8c1ac4c3520fefaa3e36638634a5d69b790",
      "author": "Dhruv Nair",
      "date": "2025-06-19T11:36:02+00:00",
      "message": "[CI] Fix SANA tests (#11756)"
    },
    {
      "sha": "fc51583c8afc066a29641c23bfbe3ccb2f43853f",
      "author": "Dhruv Nair",
      "date": "2025-06-19T11:33:12+00:00",
      "message": "[CI] Fix WAN VACE tests (#11757)"
    },
    {
      "sha": "fb57c76aa1972a0ef372b5dc2b012bc66af6ac78",
      "author": "Sayak Paul",
      "date": "2025-06-19T07:36:25+00:00",
      "message": "[LoRA] refactor lora loading at the model-level (#11719)"
    },
    {
      "sha": "7251bb4fd0cdf7dfad405ff268ccfe2c7455fdaf",
      "author": "dependabot[bot]",
      "date": "2025-06-19T05:39:33+00:00",
      "message": "Bump urllib3 from 2.2.3 to 2.5.0 in /examples/server (#11748)"
    },
    {
      "sha": "3fba74e15305d86ce285e8616714156f43c8efd8",
      "author": "Aryan",
      "date": "2025-06-19T02:37:47+00:00",
      "message": "Add missing HiDream license (#11747)"
    },
    {
      "sha": "a4df8dbc40e170ff828f8d8f79c2c861c9f1748d",
      "author": "Aryan",
      "date": "2025-06-19T02:16:01+00:00",
      "message": "Update more licenses to 2025 (#11746)"
    },
    {
      "sha": "48eae6f4204dbdca26e6c1f0c8dc64caa0e48f08",
      "author": "Sayak Paul",
      "date": "2025-06-19T02:15:06+00:00",
      "message": "[Quantizers] add `is_compileable` property to quantizers. (#11736)"
    },
    {
      "sha": "66394bf6c798a93a1e9536dac4999f77b690174c",
      "author": "Dhruv Nair",
      "date": "2025-06-18T16:54:41+00:00",
      "message": "Chroma Follow Up  (#11725)"
    },
    {
      "sha": "62cce3045d6710e9cd68869ac8391867e326928b",
      "author": "Sayak Paul",
      "date": "2025-06-18T15:26:00+00:00",
      "message": "[chore] change to 2025 licensing for remaining (#11741)"
    },
    {
      "sha": "05e867784ddb873d909a9a5cce8ee0f32eb6840d",
      "author": "Sayak Paul",
      "date": "2025-06-18T05:22:06+00:00",
      "message": "[tests] device_map tests for all models. (#11708)"
    },
    {
      "sha": "d72184eba358b883d7186a0a96dedd8118fcb72a",
      "author": "Leo Jiang",
      "date": "2025-06-18T03:56:02+00:00",
      "message": "[training] add ds support to lora hidream (#11737)"
    }
  ],
  "readme_text": "<!---\nCopyright 2022 - The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n-->\n\n<p align=\"center\">\n    <br>\n    <img src=\"https://raw.githubusercontent.com/huggingface/diffusers/main/docs/source/en/imgs/diffusers_library.jpg\" width=\"400\"/>\n    <br>\n<p>\n<p align=\"center\">\n    <a href=\"https://github.com/huggingface/diffusers/blob/main/LICENSE\"><img alt=\"GitHub\" src=\"https://img.shields.io/github/license/huggingface/datasets.svg?color=blue\"></a>\n    <a href=\"https://github.com/huggingface/diffusers/releases\"><img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/huggingface/diffusers.svg\"></a>\n    <a href=\"https://pepy.tech/project/diffusers\"><img alt=\"GitHub release\" src=\"https://static.pepy.tech/badge/diffusers/month\"></a>\n    <a href=\"CODE_OF_CONDUCT.md\"><img alt=\"Contributor Covenant\" src=\"https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg\"></a>\n    <a href=\"https://twitter.com/diffuserslib\"><img alt=\"X account\" src=\"https://img.shields.io/twitter/url/https/twitter.com/diffuserslib.svg?style=social&label=Follow%20%40diffuserslib\"></a>\n</p>\n\n\ud83e\udd17 Diffusers is the go-to library for state-of-the-art pretrained diffusion models for generating images, audio, and even 3D structures of molecules. Whether you're looking for a simple inference solution or training your own diffusion models, \ud83e\udd17 Diffusers is a modular toolbox that supports both. Our library is designed with a focus on [usability over performance](https://huggingface.co/docs/diffusers/conceptual/philosophy#usability-over-performance), [simple over easy](https://huggingface.co/docs/diffusers/conceptual/philosophy#simple-over-easy), and [customizability over abstractions](https://huggingface.co/docs/diffusers/conceptual/philosophy#tweakable-contributorfriendly-over-abstraction).\n\n\ud83e\udd17 Diffusers offers three core components:\n\n- State-of-the-art [diffusion pipelines](https://huggingface.co/docs/diffusers/api/pipelines/overview) that can be run in inference with just a few lines of code.\n- Interchangeable noise [schedulers](https://huggingface.co/docs/diffusers/api/schedulers/overview) for different diffusion speeds and output quality.\n- Pretrained [models](https://huggingface.co/docs/diffusers/api/models/overview) that can be used as building blocks, and combined with schedulers, for creating your own end-to-end diffusion systems.\n\n## Installation\n\nWe recommend installing \ud83e\udd17 Diffusers in a virtual environment from PyPI or Conda. For more details about installing [PyTorch](https://pytorch.org/get-started/locally/) and [Flax](https://flax.readthedocs.io/en/latest/#installation), please refer to their official documentation.\n\n### PyTorch\n\nWith `pip` (official package):\n\n```bash\npip install --upgrade diffusers[torch]\n```\n\nWith `conda` (maintained by the community):\n\n```sh\nconda install -c conda-forge diffusers\n```\n\n### Flax\n\nWith `pip` (official package):\n\n```bash\npip install --upgrade diffusers[flax]\n```\n\n### Apple Silicon (M1/M2) support\n\nPlease refer to the [How to use Stable Diffusion in Apple Silicon](https://huggingface.co/docs/diffusers/optimization/mps) guide.\n\n## Quickstart\n\nGenerating outputs is super easy with \ud83e\udd17 Diffusers. To generate an image from text, use the `from_pretrained` method to load any pretrained diffusion model (browse the [Hub](https://huggingface.co/models?library=diffusers&sort=downloads) for 30,000+ checkpoints):\n\n```python\nfrom diffusers import DiffusionPipeline\nimport torch\n\npipeline = DiffusionPipeline.from_pretrained(\"stable-diffusion-v1-5/stable-diffusion-v1-5\", torch_dtype=torch.float16)\npipeline.to(\"cuda\")\npipeline(\"An image of a squirrel in Picasso style\").images[0]\n```\n\nYou can also dig into the models and schedulers toolbox to build your own diffusion system:\n\n```python\nfrom diffusers import DDPMScheduler, UNet2DModel\nfrom PIL import Image\nimport torch\n\nscheduler = DDPMScheduler.from_pretrained(\"google/ddpm-cat-256\")\nmodel = UNet2DModel.from_pretrained(\"google/ddpm-cat-256\").to(\"cuda\")\nscheduler.set_timesteps(50)\n\nsample_size = model.config.sample_size\nnoise = torch.randn((1, 3, sample_size, sample_size), device=\"cuda\")\ninput = noise\n\nfor t in scheduler.timesteps:\n    with torch.no_grad():\n        noisy_residual = model(input, t).sample\n        prev_noisy_sample = scheduler.step(noisy_residual, t, input).prev_sample\n        input = prev_noisy_sample\n\nimage = (input / 2 + 0.5).clamp(0, 1)\nimage = image.cpu().permute(0, 2, 3, 1).numpy()[0]\nimage = Image.fromarray((image * 255).round().astype(\"uint8\"))\nimage\n```\n\nCheck out the [Quickstart](https://huggingface.co/docs/diffusers/quicktour) to launch your diffusion journey today!\n\n## How to navigate the documentation\n\n| **Documentation**                                                   | **What can I learn?**                                                                                                                                                                           |\n|---------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [Tutorial](https://huggingface.co/docs/diffusers/tutorials/tutorial_overview)                                                            | A basic crash course for learning how to use the library's most important features like using models and schedulers to build your own diffusion system, and training your own diffusion model.  |\n| [Loading](https://huggingface.co/docs/diffusers/using-diffusers/loading)                                                             | Guides for how to load and configure all the components (pipelines, models, and schedulers) of the library, as well as how to use different schedulers.                                         |\n| [Pipelines for inference](https://huggingface.co/docs/diffusers/using-diffusers/overview_techniques)                                             | Guides for how to use pipelines for different inference tasks, batched generation, controlling generated outputs and randomness, and how to contribute a pipeline to the library.               |\n| [Optimization](https://huggingface.co/docs/diffusers/optimization/fp16)                                                        | Guides for how to optimize your diffusion model to run faster and consume less memory.                                                                                                          |\n| [Training](https://huggingface.co/docs/diffusers/training/overview) | Guides for how to train a diffusion model for different tasks with different training techniques.                                                                                               |\n## Contribution\n\nWe \u2764\ufe0f  contributions from the open-source community!\nIf you want to contribute to this library, please check out our [Contribution guide](https://github.com/huggingface/diffusers/blob/main/CONTRIBUTING.md).\nYou can look out for [issues](https://github.com/huggingface/diffusers/issues) you'd like to tackle to contribute to the library.\n- See [Good first issues](https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22) for general opportunities to contribute\n- See [New model/pipeline](https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22New+pipeline%2Fmodel%22) to contribute exciting new diffusion models / diffusion pipelines\n- See [New scheduler](https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22New+scheduler%22)\n\nAlso, say \ud83d\udc4b in our public Discord channel <a href=\"https://discord.gg/G7tWnz98XR\"><img alt=\"Join us on Discord\" src=\"https://img.shields.io/discord/823813159592001537?color=5865F2&logo=discord&logoColor=white\"></a>. We discuss the hottest trends about diffusion models, help each other with contributions, personal projects or just hang out \u2615.\n\n\n## Popular Tasks & Pipelines\n\n<table>\n  <tr>\n    <th>Task</th>\n    <th>Pipeline</th>\n    <th>\ud83e\udd17 Hub</th>\n  </tr>\n  <tr style=\"border-top: 2px solid black\">\n    <td>Unconditional Image Generation</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/ddpm\"> DDPM </a></td>\n    <td><a href=\"https://huggingface.co/google/ddpm-ema-church-256\"> google/ddpm-ema-church-256 </a></td>\n  </tr>\n  <tr style=\"border-top: 2px solid black\">\n    <td>Text-to-Image</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img\">Stable Diffusion Text-to-Image</a></td>\n      <td><a href=\"https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5\"> stable-diffusion-v1-5/stable-diffusion-v1-5 </a></td>\n  </tr>\n  <tr>\n    <td>Text-to-Image</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/unclip\">unCLIP</a></td>\n      <td><a href=\"https://huggingface.co/kakaobrain/karlo-v1-alpha\"> kakaobrain/karlo-v1-alpha </a></td>\n  </tr>\n  <tr>\n    <td>Text-to-Image</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/deepfloyd_if\">DeepFloyd IF</a></td>\n      <td><a href=\"https://huggingface.co/DeepFloyd/IF-I-XL-v1.0\"> DeepFloyd/IF-I-XL-v1.0 </a></td>\n  </tr>\n  <tr>\n    <td>Text-to-Image</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/kandinsky\">Kandinsky</a></td>\n      <td><a href=\"https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder\"> kandinsky-community/kandinsky-2-2-decoder </a></td>\n  </tr>\n  <tr style=\"border-top: 2px solid black\">\n    <td>Text-guided Image-to-Image</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/controlnet\">ControlNet</a></td>\n      <td><a href=\"https://huggingface.co/lllyasviel/sd-controlnet-canny\"> lllyasviel/sd-controlnet-canny </a></td>\n  </tr>\n  <tr>\n    <td>Text-guided Image-to-Image</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/pix2pix\">InstructPix2Pix</a></td>\n      <td><a href=\"https://huggingface.co/timbrooks/instruct-pix2pix\"> timbrooks/instruct-pix2pix </a></td>\n  </tr>\n  <tr>\n    <td>Text-guided Image-to-Image</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/img2img\">Stable Diffusion Image-to-Image</a></td>\n      <td><a href=\"https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5\"> stable-diffusion-v1-5/stable-diffusion-v1-5 </a></td>\n  </tr>\n  <tr style=\"border-top: 2px solid black\">\n    <td>Text-guided Image Inpainting</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/inpaint\">Stable Diffusion Inpainting</a></td>\n      <td><a href=\"https://huggingface.co/runwayml/stable-diffusion-inpainting\"> runwayml/stable-diffusion-inpainting </a></td>\n  </tr>\n  <tr style=\"border-top: 2px solid black\">\n    <td>Image Variation</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/image_variation\">Stable Diffusion Image Variation</a></td>\n      <td><a href=\"https://huggingface.co/lambdalabs/sd-image-variations-diffusers\"> lambdalabs/sd-image-variations-diffusers </a></td>\n  </tr>\n  <tr style=\"border-top: 2px solid black\">\n    <td>Super Resolution</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/upscale\">Stable Diffusion Upscale</a></td>\n      <td><a href=\"https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler\"> stabilityai/stable-diffusion-x4-upscaler </a></td>\n  </tr>\n  <tr>\n    <td>Super Resolution</td>\n    <td><a href=\"https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/latent_upscale\">Stable Diffusion Latent Upscale</a></td>\n      <td><a href=\"https://huggingface.co/stabilityai/sd-x2-latent-upscaler\"> stabilityai/sd-x2-latent-upscaler </a></td>\n  </tr>\n</table>\n\n## Popular libraries using \ud83e\udde8 Diffusers\n\n- https://github.com/microsoft/TaskMatrix\n- https://github.com/invoke-ai/InvokeAI\n- https://github.com/InstantID/InstantID\n- https://github.com/apple/ml-stable-diffusion\n- https://github.com/Sanster/lama-cleaner\n- https://github.com/IDEA-Research/Grounded-Segment-Anything\n- https://github.com/ashawkey/stable-dreamfusion\n- https://github.com/deep-floyd/IF\n- https://github.com/bentoml/BentoML\n- https://github.com/bmaltais/kohya_ss\n- +14,000 other amazing GitHub repositories \ud83d\udcaa\n\nThank you for using us \u2764\ufe0f.\n\n## Credits\n\nThis library concretizes previous work by many different authors and would not have been possible without their great research and implementations. We'd like to thank, in particular, the following implementations which have helped us in our development and without which the API could not have been as polished today:\n\n- @CompVis' latent diffusion models library, available [here](https://github.com/CompVis/latent-diffusion)\n- @hojonathanho original DDPM implementation, available [here](https://github.com/hojonathanho/diffusion) as well as the extremely useful translation into PyTorch by @pesser, available [here](https://github.com/pesser/pytorch_diffusion)\n- @ermongroup's DDIM implementation, available [here](https://github.com/ermongroup/ddim)\n- @yang-song's Score-VE and Score-VP implementations, available [here](https://github.com/yang-song/score_sde_pytorch)\n\nWe also want to thank @heejkoo for the very helpful overview of papers, code and resources on diffusion models, available [here](https://github.com/heejkoo/Awesome-Diffusion-Models) as well as @crowsonkb and @rromb for useful discussions and insights.\n\n## Citation\n\n```bibtex\n@misc{von-platen-etal-2022-diffusers,\n  author = {Patrick von Platen and Suraj Patil and Anton Lozhkov and Pedro Cuenca and Nathan Lambert and Kashif Rasul and Mishig Davaadorj and Dhruv Nair and Sayak Paul and William Berman and Yiyi Xu and Steven Liu and Thomas Wolf},\n  title = {Diffusers: State-of-the-art diffusion models},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/huggingface/diffusers}}\n}\n```\n",
  "external_links_in_readme": [
    "https://github.com/huggingface/diffusers/issues",
    "https://huggingface.co/lllyasviel/sd-controlnet-canny\">",
    "https://github.com/huggingface/diffusers}}",
    "https://github.com/huggingface/diffusers/releases\"><img",
    "https://huggingface.co/docs/diffusers/api/schedulers/overview",
    "https://huggingface.co/docs/diffusers/training/overview",
    "https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22",
    "https://pepy.tech/project/diffusers\"><img",
    "https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22New+pipeline%2Fmodel%22",
    "https://huggingface.co/models?library=diffusers&sort=downloads",
    "https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/image_variation\">Stable",
    "https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/inpaint\">Stable",
    "https://github.com/huggingface/diffusers/issues?q=is%3Aopen+is%3Aissue+label%3A%22New+scheduler%22",
    "https://huggingface.co/runwayml/stable-diffusion-inpainting\">",
    "https://huggingface.co/docs/diffusers/api/pipelines/kandinsky\">Kandinsky</a></td>",
    "https://huggingface.co/docs/diffusers/conceptual/philosophy#simple-over-easy",
    "https://github.com/microsoft/TaskMatrix",
    "https://github.com/Sanster/lama-cleaner",
    "https://github.com/deep-floyd/IF",
    "https://discord.gg/G7tWnz98XR\"><img",
    "https://github.com/pesser/pytorch_diffusion",
    "https://github.com/InstantID/InstantID",
    "https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img\">Stable",
    "https://huggingface.co/docs/diffusers/api/pipelines/controlnet\">ControlNet</a></td>",
    "https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler\">",
    "https://huggingface.co/docs/diffusers/api/pipelines/overview",
    "https://huggingface.co/docs/diffusers/conceptual/philosophy#usability-over-performance",
    "https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder\">",
    "https://github.com/invoke-ai/InvokeAI",
    "https://img.shields.io/github/release/huggingface/diffusers.svg\"></a>",
    "https://github.com/bentoml/BentoML",
    "https://huggingface.co/timbrooks/instruct-pix2pix\">",
    "https://huggingface.co/google/ddpm-ema-church-256\">",
    "https://github.com/IDEA-Research/Grounded-Segment-Anything",
    "https://github.com/heejkoo/Awesome-Diffusion-Models",
    "https://github.com/huggingface/diffusers/blob/main/CONTRIBUTING.md",
    "https://twitter.com/diffuserslib\"><img",
    "https://huggingface.co/DeepFloyd/IF-I-XL-v1.0\">",
    "https://static.pepy.tech/badge/diffusers/month\"></a>",
    "https://github.com/bmaltais/kohya_ss",
    "https://huggingface.co/kakaobrain/karlo-v1-alpha\">",
    "https://huggingface.co/docs/diffusers/using-diffusers/overview_techniques",
    "https://github.com/apple/ml-stable-diffusion",
    "https://huggingface.co/docs/diffusers/quicktour",
    "https://github.com/ashawkey/stable-dreamfusion",
    "https://raw.githubusercontent.com/huggingface/diffusers/main/docs/source/en/imgs/diffusers_library.jpg\"",
    "https://img.shields.io/discord/823813159592001537?color=5865F2&logo=discord&logoColor=white\"></a>.",
    "https://huggingface.co/docs/diffusers/optimization/fp16",
    "https://github.com/huggingface/diffusers/blob/main/LICENSE\"><img",
    "https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg\"></a>",
    "https://github.com/hojonathanho/diffusion",
    "https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/latent_upscale\">Stable",
    "https://huggingface.co/docs/diffusers/api/pipelines/deepfloyd_if\">DeepFloyd",
    "https://huggingface.co/docs/diffusers/using-diffusers/loading",
    "https://flax.readthedocs.io/en/latest/#installation",
    "https://huggingface.co/docs/diffusers/optimization/mps",
    "https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/upscale\">Stable",
    "https://github.com/ermongroup/ddim",
    "https://pytorch.org/get-started/locally/",
    "https://huggingface.co/docs/diffusers/api/models/overview",
    "https://huggingface.co/docs/diffusers/conceptual/philosophy#tweakable-contributorfriendly-over-abstraction",
    "https://huggingface.co/stabilityai/sd-x2-latent-upscaler\">",
    "https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/img2img\">Stable",
    "https://github.com/CompVis/latent-diffusion",
    "https://huggingface.co/docs/diffusers/api/pipelines/pix2pix\">InstructPix2Pix</a></td>",
    "https://huggingface.co/lambdalabs/sd-image-variations-diffusers\">",
    "https://huggingface.co/docs/diffusers/api/pipelines/ddpm\">",
    "http://www.apache.org/licenses/LICENSE-2.0",
    "https://img.shields.io/github/license/huggingface/datasets.svg?color=blue\"></a>",
    "https://img.shields.io/twitter/url/https/twitter.com/diffuserslib.svg?style=social&label=Follow%20%40diffuserslib\"></a>",
    "https://github.com/yang-song/score_sde_pytorch",
    "https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5\">",
    "https://huggingface.co/docs/diffusers/api/pipelines/unclip\">unCLIP</a></td>",
    "https://huggingface.co/docs/diffusers/tutorials/tutorial_overview"
  ]
}
```

</details>


---

## Repository 9: comfyanonymous/ComfyUI">ComfyUI<

# GitHub Data Extraction Error

Error: 404 {"message": "Not Found", "documentation_url": "https://docs.github.com/rest/repos/repos#get-a-repository", "status": "404"}

Repository: https://github.com/comfyanonymous/ComfyUI">ComfyUI</a>,

---

